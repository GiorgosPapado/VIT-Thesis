{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape of X_train: (2386, 327680)\n",
      "Shape of X_test: (1176, 327680)\n",
      "Cross-Validation Accuracy Scores: [0.25753769 0.22515723 0.24779874]\n",
      "Mean Cross-Validation Accuracy: 0.24349788776165945\n",
      "Test Set Accuracy: 0.2619047619047619\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import scipy.io as sio\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.model_selection import train_test_split, cross_val_score, StratifiedKFold\n",
    "from sklearn.metrics import accuracy_score\n",
    "import numpy as np\n",
    "import glob\n",
    "\n",
    "# Function to extract gesture label from the filename\n",
    "def extract_participant_from_filename(filepath):\n",
    "    filename = os.path.basename(filepath)\n",
    "    parts = filename.split('_')\n",
    "    for part in parts:\n",
    "        if 'participant' in part:\n",
    "            participant_id = part.replace('participant', '')\n",
    "            return int(participant_id)  # Convert to integer\n",
    "    return None  # If no participant ID found\n",
    "# Function to load and process a single .mat file\n",
    "def load_and_process_file(filepath, target_length):\n",
    "    mat_data = sio.loadmat(filepath)\n",
    "    data_emg = mat_data['data_emg']\n",
    "    \n",
    "    # Handle NaNs and Infinities\n",
    "    data_emg = np.nan_to_num(data_emg, nan=0.0, posinf=0.0, neginf=0.0)\n",
    "    \n",
    "    # Pad or truncate the data to the target length\n",
    "    if data_emg.shape[0] < target_length:\n",
    "        padded_data = np.pad(data_emg, ((0, target_length - data_emg.shape[0]), (0, 0)), 'constant', constant_values=0)\n",
    "    else:\n",
    "        padded_data = data_emg[:target_length]\n",
    "    \n",
    "    # Flatten the data for SVM input\n",
    "    return padded_data.flatten()\n",
    "\n",
    "# Process a list of files and return processed data and labels\n",
    "def process_files(file_list, target_length):\n",
    "    X = []\n",
    "    y = []\n",
    "    \n",
    "    for filepath in file_list:\n",
    "        X.append(load_and_process_file(filepath, target_length))\n",
    "        y.append(extract_participant_from_filename(filepath))\n",
    "    \n",
    "    return np.array(X), np.array(y)\n",
    "\n",
    "# Path to the root folder where all .mat files are stored\n",
    "root_folder = 's1_s2_s3_matfiles_10part'  # Update with your folder path\n",
    "\n",
    "# Find all .mat files in the folder\n",
    "all_mat_files = glob.glob(os.path.join(root_folder, '*.mat'))\n",
    "\n",
    "# Collect all corresponding labels\n",
    "all_labels = [extract_participant_from_filename(mat_file) for mat_file in all_mat_files]\n",
    "\n",
    "# Target length for EMG signals (adjust based on your data)\n",
    "target_length = 10240  # Modify this as needed\n",
    "\n",
    "# Split the dataset into train and test sets\n",
    "train_files, test_files, train_labels, test_labels = train_test_split(all_mat_files, all_labels, test_size=0.33, random_state=42)\n",
    "\n",
    "# Process training and test data\n",
    "X_train, y_train = process_files(train_files, target_length)\n",
    "X_test, y_test = process_files(test_files, target_length)\n",
    "print(f\"Shape of X_train: {X_train.shape}\")\n",
    "print(f\"Shape of X_test: {X_test.shape}\")\n",
    "# Initialize PCA for dimensionality reduction\n",
    "pca = PCA(n_components=100)  # Adjust the number of components as needed\n",
    "\n",
    "# Apply PCA to the training and test sets\n",
    "X_train_pca = pca.fit_transform(X_train)\n",
    "X_test_pca = pca.transform(X_test)\n",
    "\n",
    "svm = SVC(kernel='linear', C=1, gamma='scale')\n",
    "\n",
    "# Set up 5-fold cross-validation on the training set\n",
    "cv = StratifiedKFold(n_splits=3, shuffle=True, random_state=42)\n",
    "\n",
    "# Perform cross-validation\n",
    "cross_val_scores = cross_val_score(svm, X_train, y_train, cv=cv, scoring='accuracy')\n",
    "\n",
    "# Fit the model on the entire training set after cross-validation\n",
    "svm.fit(X_train, y_train)\n",
    "\n",
    "# Make predictions on the test set\n",
    "y_pred = svm.predict(X_test)\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "\n",
    "# Output cross-validation results and final accuracy\n",
    "print(\"Cross-Validation Accuracy Scores:\", cross_val_scores)\n",
    "print(\"Mean Cross-Validation Accuracy:\", np.mean(cross_val_scores))\n",
    "print(\"Test Set Accuracy:\", accuracy)\n",
    "\n",
    "# # --- Hyperparameter Tuning with GridSearchCV ---\n",
    "\n",
    "# from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "# param_grid = {\n",
    "#     'C': [0.01, 0.1, 1, 10, 100],\n",
    "#     'gamma': ['scale', 'auto', 0.01, 0.001, 0.0001],\n",
    "#     'kernel': ['rbf']\n",
    "# }\n",
    "\n",
    "# grid = GridSearchCV(SVC(), param_grid, refit=True, verbose=2, cv=5)\n",
    "# grid.fit(X_train, y_train)\n",
    "\n",
    "# print(\"Best parameters:\", grid.best_params_)\n",
    "# y_pred = grid.predict(X_test)\n",
    "# accuracy = accuracy_score(y_test, y_pred)\n",
    "# print(\"Optimized Accuracy:\", accuracy)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
