{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape of X_train: (1193, 327680)\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import scipy.io as sio\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.model_selection import train_test_split, cross_val_score, StratifiedKFold\n",
    "from sklearn.metrics import accuracy_score\n",
    "import numpy as np\n",
    "import glob\n",
    "\n",
    "# Function to extract gesture label from the filename\n",
    "def extract_participant_from_filename(filepath):\n",
    "    filename = os.path.basename(filepath)\n",
    "    parts = filename.split('_')\n",
    "    for part in parts:\n",
    "        if 'participant' in part:\n",
    "            participant_id = part.replace('participant', '')\n",
    "            return int(participant_id)  # Convert to integer\n",
    "    return None  # If no participant ID found\n",
    "# Function to load and process a single .mat file\n",
    "def load_and_process_file(filepath, target_length):\n",
    "    mat_data = sio.loadmat(filepath)\n",
    "    data_emg = mat_data['data_emg']\n",
    "    \n",
    "    # Handle NaNs and Infinities\n",
    "    data_emg = np.nan_to_num(data_emg, nan=0.0, posinf=0.0, neginf=0.0)\n",
    "    \n",
    "    # Pad or truncate the data to the target length\n",
    "    if data_emg.shape[0] < target_length:\n",
    "        padded_data = np.pad(data_emg, ((0, target_length - data_emg.shape[0]), (0, 0)), 'constant', constant_values=0)\n",
    "    else:\n",
    "        padded_data = data_emg[:target_length]\n",
    "    \n",
    "    # Flatten the data for SVM input\n",
    "    return padded_data.flatten()\n",
    "\n",
    "# Process a list of files and return processed data and labels\n",
    "def process_files(file_list, target_length):\n",
    "    X = []\n",
    "    y = []\n",
    "    \n",
    "    for filepath in file_list:\n",
    "        X.append(load_and_process_file(filepath, target_length))\n",
    "        y.append(extract_participant_from_filename(filepath))\n",
    "    \n",
    "    return np.array(X), np.array(y)\n",
    "\n",
    "# Path to the root folder where all .mat files are stored\n",
    "root_folder = 's1_s2_s3_matfiles_5part'  # Update with your folder path\n",
    "\n",
    "# Find all .mat files in the folder\n",
    "all_mat_files = glob.glob(os.path.join(root_folder, '*.mat'))\n",
    "\n",
    "# Collect all corresponding labels\n",
    "all_labels = [extract_participant_from_filename(mat_file) for mat_file in all_mat_files]\n",
    "\n",
    "# Target length for EMG signals (adjust based on your data)\n",
    "target_length = 10240  # Modify this as needed\n",
    "\n",
    "# Split the dataset into train and test sets\n",
    "train_files, test_files, train_labels, test_labels = train_test_split(all_mat_files, all_labels, test_size=0.33, random_state=42)\n",
    "\n",
    "# Process training and test data\n",
    "X_train, y_train = process_files(train_files, target_length)\n",
    "#X_test, y_test = process_files(test_files, target_length)\n",
    "print(f\"Shape of X_train: {X_train.shape}\")\n",
    "#print(f\"Shape of X_test: {X_test.shape}\")\n",
    "# Initialize PCA for dimensionality reduction\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of components to retain 90% variance: 366\n"
     ]
    }
   ],
   "source": [
    "from sklearn.decomposition import PCA\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "import numpy as np\n",
    "scaler = StandardScaler()\n",
    "X_scaled = scaler.fit_transform(X_train)\n",
    "\n",
    "# Step 2: Apply PCA to keep 95% of the variance\n",
    "pca = PCA(n_components=0.70)  # 95% of variance\n",
    "#X_pca = pca.fit_transform(X_scaled)\n",
    "pca.fit(X_scaled)\n",
    "# Step 3: Get the number of components that explain 95% variance\n",
    "n_components = pca.n_components_\n",
    "\n",
    "print(f\"Number of components to retain 90% variance: {n_components}\") # Adjust the number of components as needed"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
