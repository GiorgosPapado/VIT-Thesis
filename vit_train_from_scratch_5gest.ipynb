{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "# Apply Gaussian noise\n",
    "def add_noise(emg_data, noise_factor=0.05):\n",
    "    noise = np.random.randn(*emg_data.shape) * noise_factor\n",
    "    augmented_data = emg_data + noise\n",
    "    return augmented_data\n",
    "\n",
    "# Time warping: Stretch or compress the time axis slightly\n",
    "def time_warp(emg_data, time_warp_factor=0.1):\n",
    "    stretch_factor = np.random.uniform(1 - time_warp_factor, 1 + time_warp_factor)\n",
    "    indices = np.round(np.linspace(0, emg_data.shape[0] - 1, int(emg_data.shape[0] * stretch_factor))).astype(int)\n",
    "    augmented_data = emg_data[indices % emg_data.shape[0]]\n",
    "    return augmented_data\n",
    "\n",
    "# Signal scaling: Multiply by a random factor\n",
    "def scale_signal(emg_data, scale_factor=0.1):\n",
    "    scaling_factor = np.random.uniform(1 - scale_factor, 1 + scale_factor)\n",
    "    return emg_data * scaling_factor\n",
    "\n",
    "# Random cropping and padding\n",
    "def random_crop_pad(emg_data, target_length):\n",
    "    if emg_data.shape[0] < target_length:\n",
    "        # Pad\n",
    "        pad_size = target_length - emg_data.shape[0]\n",
    "        pad_before = np.random.randint(0, pad_size)\n",
    "        pad_after = pad_size - pad_before\n",
    "        augmented_data = np.pad(emg_data, ((pad_before, pad_after), (0, 0)), 'constant')\n",
    "    else:\n",
    "        # Crop\n",
    "        crop_start = np.random.randint(0, emg_data.shape[0] - target_length)\n",
    "        augmented_data = emg_data[crop_start:crop_start + target_length]\n",
    "    \n",
    "    return augmented_data\n",
    "\n",
    "# Random horizontal or vertical flip\n",
    "def flip(emg_data):\n",
    "    if np.random.rand() > 0.5:\n",
    "        return np.flip(emg_data, axis=0)  # Flip along time axis\n",
    "    return emg_data\n",
    "\n",
    "# Data augmentation pipeline\n",
    "def augment_data(emg_data, target_length):\n",
    "    # Apply augmentations\n",
    "    emg_data = add_noise(emg_data)\n",
    "    #emg_data = time_warp(emg_data)\n",
    "    emg_data = scale_signal(emg_data)\n",
    "    #emg_data = random_crop_pad(emg_data, target_length)\n",
    "    #emg_data = flip(emg_data)\n",
    "    \n",
    "    return emg_data\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 15/15 [01:10<00:00,  4.73s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 445/500, Loss: 0.2721, Accuracy: 0.9046\n",
      "Validation Loss: 1.0659, Validation Accuracy: 0.7295\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024/09/20 23:41:06 WARNING mlflow.models.model: Model logged without a signature and input example. Please set `input_example` parameter when logging the model to auto infer the model signature.\n",
      "100%|██████████| 15/15 [01:09<00:00,  4.62s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 446/500, Loss: 0.2906, Accuracy: 0.8921\n",
      "Validation Loss: 1.0691, Validation Accuracy: 0.7228\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024/09/20 23:42:33 WARNING mlflow.models.model: Model logged without a signature and input example. Please set `input_example` parameter when logging the model to auto infer the model signature.\n",
      "100%|██████████| 15/15 [01:09<00:00,  4.66s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 447/500, Loss: 0.2697, Accuracy: 0.9087\n",
      "Validation Loss: 0.9601, Validation Accuracy: 0.7583\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024/09/20 23:44:01 WARNING mlflow.models.model: Model logged without a signature and input example. Please set `input_example` parameter when logging the model to auto infer the model signature.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "New best model saved with accuracy: 0.7583\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024/09/20 23:44:06 WARNING mlflow.models.model: Model logged without a signature and input example. Please set `input_example` parameter when logging the model to auto infer the model signature.\n",
      "100%|██████████| 15/15 [01:09<00:00,  4.62s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 448/500, Loss: 0.3078, Accuracy: 0.8877\n",
      "Validation Loss: 1.0821, Validation Accuracy: 0.7228\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024/09/20 23:45:33 WARNING mlflow.models.model: Model logged without a signature and input example. Please set `input_example` parameter when logging the model to auto infer the model signature.\n",
      "100%|██████████| 15/15 [01:09<00:00,  4.64s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 449/500, Loss: 0.2960, Accuracy: 0.8899\n",
      "Validation Loss: 1.0338, Validation Accuracy: 0.7395\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024/09/20 23:47:00 WARNING mlflow.models.model: Model logged without a signature and input example. Please set `input_example` parameter when logging the model to auto infer the model signature.\n",
      "100%|██████████| 15/15 [01:09<00:00,  4.63s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 450/500, Loss: 0.3267, Accuracy: 0.8882\n",
      "Validation Loss: 0.9626, Validation Accuracy: 0.7517\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024/09/20 23:48:28 WARNING mlflow.models.model: Model logged without a signature and input example. Please set `input_example` parameter when logging the model to auto infer the model signature.\n",
      "100%|██████████| 15/15 [01:09<00:00,  4.61s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 451/500, Loss: 0.3013, Accuracy: 0.8932\n",
      "Validation Loss: 1.0483, Validation Accuracy: 0.7206\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024/09/20 23:49:55 WARNING mlflow.models.model: Model logged without a signature and input example. Please set `input_example` parameter when logging the model to auto infer the model signature.\n",
      "100%|██████████| 15/15 [01:09<00:00,  4.63s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 452/500, Loss: 0.2987, Accuracy: 0.8996\n",
      "Validation Loss: 1.0119, Validation Accuracy: 0.7384\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024/09/20 23:51:22 WARNING mlflow.models.model: Model logged without a signature and input example. Please set `input_example` parameter when logging the model to auto infer the model signature.\n",
      "100%|██████████| 15/15 [01:09<00:00,  4.64s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 453/500, Loss: 0.2709, Accuracy: 0.9024\n",
      "Validation Loss: 1.0422, Validation Accuracy: 0.7350\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024/09/20 23:52:50 WARNING mlflow.models.model: Model logged without a signature and input example. Please set `input_example` parameter when logging the model to auto infer the model signature.\n",
      "100%|██████████| 15/15 [01:09<00:00,  4.63s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 454/500, Loss: 0.2957, Accuracy: 0.8888\n",
      "Validation Loss: 1.1866, Validation Accuracy: 0.6907\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024/09/20 23:54:18 WARNING mlflow.models.model: Model logged without a signature and input example. Please set `input_example` parameter when logging the model to auto infer the model signature.\n",
      "100%|██████████| 15/15 [01:08<00:00,  4.59s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 455/500, Loss: 0.3493, Accuracy: 0.8852\n",
      "Validation Loss: 1.2772, Validation Accuracy: 0.6785\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024/09/20 23:55:45 WARNING mlflow.models.model: Model logged without a signature and input example. Please set `input_example` parameter when logging the model to auto infer the model signature.\n",
      "100%|██████████| 15/15 [01:09<00:00,  4.60s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 456/500, Loss: 0.3161, Accuracy: 0.8818\n",
      "Validation Loss: 1.1284, Validation Accuracy: 0.6973\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024/09/20 23:57:12 WARNING mlflow.models.model: Model logged without a signature and input example. Please set `input_example` parameter when logging the model to auto infer the model signature.\n",
      "100%|██████████| 15/15 [01:08<00:00,  4.60s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 457/500, Loss: 0.2829, Accuracy: 0.8943\n",
      "Validation Loss: 1.1274, Validation Accuracy: 0.7095\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024/09/20 23:58:39 WARNING mlflow.models.model: Model logged without a signature and input example. Please set `input_example` parameter when logging the model to auto infer the model signature.\n",
      "100%|██████████| 15/15 [01:09<00:00,  4.64s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 458/500, Loss: 0.3587, Accuracy: 0.8749\n",
      "Validation Loss: 1.1019, Validation Accuracy: 0.7151\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024/09/21 00:00:06 WARNING mlflow.models.model: Model logged without a signature and input example. Please set `input_example` parameter when logging the model to auto infer the model signature.\n",
      "100%|██████████| 15/15 [01:09<00:00,  4.60s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 459/500, Loss: 0.2850, Accuracy: 0.8979\n",
      "Validation Loss: 1.1995, Validation Accuracy: 0.6929\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024/09/21 00:01:34 WARNING mlflow.models.model: Model logged without a signature and input example. Please set `input_example` parameter when logging the model to auto infer the model signature.\n",
      "100%|██████████| 15/15 [01:09<00:00,  4.63s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 460/500, Loss: 0.3329, Accuracy: 0.8774\n",
      "Validation Loss: 1.2021, Validation Accuracy: 0.6918\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024/09/21 00:03:01 WARNING mlflow.models.model: Model logged without a signature and input example. Please set `input_example` parameter when logging the model to auto infer the model signature.\n",
      "100%|██████████| 15/15 [01:09<00:00,  4.61s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 461/500, Loss: 0.3684, Accuracy: 0.8705\n",
      "Validation Loss: 1.1296, Validation Accuracy: 0.7118\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024/09/21 00:04:28 WARNING mlflow.models.model: Model logged without a signature and input example. Please set `input_example` parameter when logging the model to auto infer the model signature.\n",
      "100%|██████████| 15/15 [01:08<00:00,  4.58s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 462/500, Loss: 0.3907, Accuracy: 0.8594\n",
      "Validation Loss: 1.2328, Validation Accuracy: 0.6818\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024/09/21 00:05:55 WARNING mlflow.models.model: Model logged without a signature and input example. Please set `input_example` parameter when logging the model to auto infer the model signature.\n",
      "100%|██████████| 15/15 [01:09<00:00,  4.63s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 463/500, Loss: 0.2856, Accuracy: 0.8904\n",
      "Validation Loss: 1.1815, Validation Accuracy: 0.6885\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024/09/21 00:07:23 WARNING mlflow.models.model: Model logged without a signature and input example. Please set `input_example` parameter when logging the model to auto infer the model signature.\n",
      "100%|██████████| 15/15 [01:09<00:00,  4.62s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 464/500, Loss: 0.3109, Accuracy: 0.8943\n",
      "Validation Loss: 1.0553, Validation Accuracy: 0.7195\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024/09/21 00:08:50 WARNING mlflow.models.model: Model logged without a signature and input example. Please set `input_example` parameter when logging the model to auto infer the model signature.\n",
      "100%|██████████| 15/15 [01:09<00:00,  4.60s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 465/500, Loss: 0.2869, Accuracy: 0.8949\n",
      "Validation Loss: 1.1275, Validation Accuracy: 0.7228\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024/09/21 00:10:17 WARNING mlflow.models.model: Model logged without a signature and input example. Please set `input_example` parameter when logging the model to auto infer the model signature.\n",
      "100%|██████████| 15/15 [01:08<00:00,  4.59s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 466/500, Loss: 0.3157, Accuracy: 0.8854\n",
      "Validation Loss: 1.1557, Validation Accuracy: 0.6973\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024/09/21 00:11:44 WARNING mlflow.models.model: Model logged without a signature and input example. Please set `input_example` parameter when logging the model to auto infer the model signature.\n",
      "100%|██████████| 15/15 [01:09<00:00,  4.63s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 467/500, Loss: 0.2992, Accuracy: 0.8910\n",
      "Validation Loss: 1.0793, Validation Accuracy: 0.7217\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024/09/21 00:13:12 WARNING mlflow.models.model: Model logged without a signature and input example. Please set `input_example` parameter when logging the model to auto infer the model signature.\n",
      "100%|██████████| 15/15 [01:09<00:00,  4.60s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 468/500, Loss: 0.2925, Accuracy: 0.8857\n",
      "Validation Loss: 1.0093, Validation Accuracy: 0.7384\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024/09/21 00:14:39 WARNING mlflow.models.model: Model logged without a signature and input example. Please set `input_example` parameter when logging the model to auto infer the model signature.\n",
      "100%|██████████| 15/15 [01:09<00:00,  4.61s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 469/500, Loss: 0.3099, Accuracy: 0.8960\n",
      "Validation Loss: 1.0498, Validation Accuracy: 0.7361\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024/09/21 00:16:06 WARNING mlflow.models.model: Model logged without a signature and input example. Please set `input_example` parameter when logging the model to auto infer the model signature.\n",
      "100%|██████████| 15/15 [01:09<00:00,  4.61s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 470/500, Loss: 0.3077, Accuracy: 0.8860\n",
      "Validation Loss: 1.1066, Validation Accuracy: 0.7018\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024/09/21 00:17:33 WARNING mlflow.models.model: Model logged without a signature and input example. Please set `input_example` parameter when logging the model to auto infer the model signature.\n",
      "100%|██████████| 15/15 [01:09<00:00,  4.64s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 471/500, Loss: 0.2944, Accuracy: 0.8924\n",
      "Validation Loss: 1.0662, Validation Accuracy: 0.7206\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024/09/21 00:19:01 WARNING mlflow.models.model: Model logged without a signature and input example. Please set `input_example` parameter when logging the model to auto infer the model signature.\n",
      "100%|██████████| 15/15 [01:09<00:00,  4.61s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 472/500, Loss: 0.2603, Accuracy: 0.9051\n",
      "Validation Loss: 1.0336, Validation Accuracy: 0.7306\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024/09/21 00:20:28 WARNING mlflow.models.model: Model logged without a signature and input example. Please set `input_example` parameter when logging the model to auto infer the model signature.\n",
      "100%|██████████| 15/15 [01:09<00:00,  4.64s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 473/500, Loss: 0.2673, Accuracy: 0.9112\n",
      "Validation Loss: 1.2425, Validation Accuracy: 0.6940\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024/09/21 00:21:56 WARNING mlflow.models.model: Model logged without a signature and input example. Please set `input_example` parameter when logging the model to auto infer the model signature.\n",
      "100%|██████████| 15/15 [01:09<00:00,  4.63s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 474/500, Loss: 0.2629, Accuracy: 0.9057\n",
      "Validation Loss: 0.9973, Validation Accuracy: 0.7461\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024/09/21 00:23:23 WARNING mlflow.models.model: Model logged without a signature and input example. Please set `input_example` parameter when logging the model to auto infer the model signature.\n",
      "100%|██████████| 15/15 [01:09<00:00,  4.62s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 475/500, Loss: 0.2459, Accuracy: 0.9148\n",
      "Validation Loss: 1.0161, Validation Accuracy: 0.7339\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024/09/21 00:24:50 WARNING mlflow.models.model: Model logged without a signature and input example. Please set `input_example` parameter when logging the model to auto infer the model signature.\n",
      "100%|██████████| 15/15 [01:09<00:00,  4.64s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 476/500, Loss: 0.2461, Accuracy: 0.9060\n",
      "Validation Loss: 1.1167, Validation Accuracy: 0.7217\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024/09/21 00:26:17 WARNING mlflow.models.model: Model logged without a signature and input example. Please set `input_example` parameter when logging the model to auto infer the model signature.\n",
      "100%|██████████| 15/15 [01:09<00:00,  4.62s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 477/500, Loss: 0.2578, Accuracy: 0.9076\n",
      "Validation Loss: 1.0018, Validation Accuracy: 0.7517\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024/09/21 00:27:45 WARNING mlflow.models.model: Model logged without a signature and input example. Please set `input_example` parameter when logging the model to auto infer the model signature.\n",
      "100%|██████████| 15/15 [01:08<00:00,  4.60s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 478/500, Loss: 0.2605, Accuracy: 0.9132\n",
      "Validation Loss: 1.1020, Validation Accuracy: 0.7328\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024/09/21 00:29:12 WARNING mlflow.models.model: Model logged without a signature and input example. Please set `input_example` parameter when logging the model to auto infer the model signature.\n",
      "100%|██████████| 15/15 [01:08<00:00,  4.59s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 479/500, Loss: 0.2787, Accuracy: 0.9046\n",
      "Validation Loss: 1.0232, Validation Accuracy: 0.7450\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024/09/21 00:30:39 WARNING mlflow.models.model: Model logged without a signature and input example. Please set `input_example` parameter when logging the model to auto infer the model signature.\n",
      "100%|██████████| 15/15 [01:09<00:00,  4.61s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 480/500, Loss: 0.2587, Accuracy: 0.9207\n",
      "Validation Loss: 1.1259, Validation Accuracy: 0.7228\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024/09/21 00:32:06 WARNING mlflow.models.model: Model logged without a signature and input example. Please set `input_example` parameter when logging the model to auto infer the model signature.\n",
      "100%|██████████| 15/15 [01:09<00:00,  4.63s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 481/500, Loss: 0.2490, Accuracy: 0.9190\n",
      "Validation Loss: 1.0917, Validation Accuracy: 0.7295\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024/09/21 00:33:33 WARNING mlflow.models.model: Model logged without a signature and input example. Please set `input_example` parameter when logging the model to auto infer the model signature.\n",
      "100%|██████████| 15/15 [01:09<00:00,  4.62s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 482/500, Loss: 0.2158, Accuracy: 0.9229\n",
      "Validation Loss: 1.1962, Validation Accuracy: 0.7040\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024/09/21 00:35:01 WARNING mlflow.models.model: Model logged without a signature and input example. Please set `input_example` parameter when logging the model to auto infer the model signature.\n",
      "100%|██████████| 15/15 [01:09<00:00,  4.60s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 483/500, Loss: 0.2689, Accuracy: 0.9043\n",
      "Validation Loss: 1.0689, Validation Accuracy: 0.7328\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024/09/21 00:36:28 WARNING mlflow.models.model: Model logged without a signature and input example. Please set `input_example` parameter when logging the model to auto infer the model signature.\n",
      "100%|██████████| 15/15 [01:09<00:00,  4.64s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 484/500, Loss: 0.2200, Accuracy: 0.9193\n",
      "Validation Loss: 1.0527, Validation Accuracy: 0.7328\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024/09/21 00:37:55 WARNING mlflow.models.model: Model logged without a signature and input example. Please set `input_example` parameter when logging the model to auto infer the model signature.\n",
      "100%|██████████| 15/15 [01:09<00:00,  4.61s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 485/500, Loss: 0.2082, Accuracy: 0.9337\n",
      "Validation Loss: 1.0237, Validation Accuracy: 0.7461\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024/09/21 00:39:22 WARNING mlflow.models.model: Model logged without a signature and input example. Please set `input_example` parameter when logging the model to auto infer the model signature.\n",
      "100%|██████████| 15/15 [01:08<00:00,  4.58s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 486/500, Loss: 0.2029, Accuracy: 0.9290\n",
      "Validation Loss: 1.0668, Validation Accuracy: 0.7384\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024/09/21 00:40:49 WARNING mlflow.models.model: Model logged without a signature and input example. Please set `input_example` parameter when logging the model to auto infer the model signature.\n",
      "100%|██████████| 15/15 [01:09<00:00,  4.61s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 487/500, Loss: 0.2012, Accuracy: 0.9334\n",
      "Validation Loss: 1.0568, Validation Accuracy: 0.7428\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024/09/21 00:42:16 WARNING mlflow.models.model: Model logged without a signature and input example. Please set `input_example` parameter when logging the model to auto infer the model signature.\n",
      "100%|██████████| 15/15 [01:08<00:00,  4.59s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 488/500, Loss: 0.2067, Accuracy: 0.9301\n",
      "Validation Loss: 1.0942, Validation Accuracy: 0.7361\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024/09/21 00:43:43 WARNING mlflow.models.model: Model logged without a signature and input example. Please set `input_example` parameter when logging the model to auto infer the model signature.\n",
      "100%|██████████| 15/15 [01:08<00:00,  4.59s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 489/500, Loss: 0.1954, Accuracy: 0.9262\n",
      "Validation Loss: 1.0746, Validation Accuracy: 0.7417\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024/09/21 00:45:10 WARNING mlflow.models.model: Model logged without a signature and input example. Please set `input_example` parameter when logging the model to auto infer the model signature.\n",
      "100%|██████████| 15/15 [01:09<00:00,  4.62s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 490/500, Loss: 0.2029, Accuracy: 0.9348\n",
      "Validation Loss: 1.0812, Validation Accuracy: 0.7328\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024/09/21 00:46:37 WARNING mlflow.models.model: Model logged without a signature and input example. Please set `input_example` parameter when logging the model to auto infer the model signature.\n",
      "100%|██████████| 15/15 [01:09<00:00,  4.61s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 491/500, Loss: 0.2074, Accuracy: 0.9417\n",
      "Validation Loss: 1.0867, Validation Accuracy: 0.7295\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024/09/21 00:48:04 WARNING mlflow.models.model: Model logged without a signature and input example. Please set `input_example` parameter when logging the model to auto infer the model signature.\n",
      "100%|██████████| 15/15 [01:09<00:00,  4.62s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 492/500, Loss: 0.1984, Accuracy: 0.9295\n",
      "Validation Loss: 1.1100, Validation Accuracy: 0.7306\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024/09/21 00:49:31 WARNING mlflow.models.model: Model logged without a signature and input example. Please set `input_example` parameter when logging the model to auto infer the model signature.\n",
      "100%|██████████| 15/15 [01:08<00:00,  4.59s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 493/500, Loss: 0.1934, Accuracy: 0.9337\n",
      "Validation Loss: 1.0741, Validation Accuracy: 0.7406\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024/09/21 00:50:58 WARNING mlflow.models.model: Model logged without a signature and input example. Please set `input_example` parameter when logging the model to auto infer the model signature.\n",
      "100%|██████████| 15/15 [01:09<00:00,  4.63s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 494/500, Loss: 0.1775, Accuracy: 0.9345\n",
      "Validation Loss: 1.0769, Validation Accuracy: 0.7406\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024/09/21 00:52:26 WARNING mlflow.models.model: Model logged without a signature and input example. Please set `input_example` parameter when logging the model to auto infer the model signature.\n",
      "100%|██████████| 15/15 [01:09<00:00,  4.61s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 495/500, Loss: 0.1875, Accuracy: 0.9329\n",
      "Validation Loss: 1.0795, Validation Accuracy: 0.7395\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024/09/21 00:53:53 WARNING mlflow.models.model: Model logged without a signature and input example. Please set `input_example` parameter when logging the model to auto infer the model signature.\n",
      "100%|██████████| 15/15 [01:09<00:00,  4.62s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 496/500, Loss: 0.1784, Accuracy: 0.9359\n",
      "Validation Loss: 1.0797, Validation Accuracy: 0.7395\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024/09/21 00:55:20 WARNING mlflow.models.model: Model logged without a signature and input example. Please set `input_example` parameter when logging the model to auto infer the model signature.\n",
      "100%|██████████| 15/15 [01:09<00:00,  4.64s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 497/500, Loss: 0.1831, Accuracy: 0.9406\n",
      "Validation Loss: 1.0879, Validation Accuracy: 0.7350\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024/09/21 00:56:48 WARNING mlflow.models.model: Model logged without a signature and input example. Please set `input_example` parameter when logging the model to auto infer the model signature.\n",
      "100%|██████████| 15/15 [01:08<00:00,  4.59s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 498/500, Loss: 0.1859, Accuracy: 0.9348\n",
      "Validation Loss: 1.0927, Validation Accuracy: 0.7350\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024/09/21 00:58:15 WARNING mlflow.models.model: Model logged without a signature and input example. Please set `input_example` parameter when logging the model to auto infer the model signature.\n",
      "100%|██████████| 15/15 [01:08<00:00,  4.60s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 499/500, Loss: 0.1834, Accuracy: 0.9356\n",
      "Validation Loss: 1.0724, Validation Accuracy: 0.7439\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024/09/21 00:59:42 WARNING mlflow.models.model: Model logged without a signature and input example. Please set `input_example` parameter when logging the model to auto infer the model signature.\n",
      "100%|██████████| 15/15 [01:09<00:00,  4.61s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 500/500, Loss: 0.1895, Accuracy: 0.9393\n",
      "Validation Loss: 1.0957, Validation Accuracy: 0.7328\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024/09/21 01:01:09 WARNING mlflow.models.model: Model logged without a signature and input example. Please set `input_example` parameter when logging the model to auto infer the model signature.\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import scipy.io as sio\n",
    "from sklearn.model_selection import train_test_split\n",
    "import torch\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from transformers import ViTForImageClassification, ViTConfig, AdamW\n",
    "from tqdm import tqdm\n",
    "import glob\n",
    "from torch.optim.lr_scheduler import CosineAnnealingLR\n",
    "from torch.nn import DataParallel\n",
    "import mlflow\n",
    "import mlflow.pytorch\n",
    "\n",
    "root_folder = 's1_s2_s3_matfiles_5gest'  # Update with your folder path\n",
    "num_epochs = 500\n",
    "\n",
    "# Track experiment with MLflow\n",
    "def start_mlflow_experiment(experiment_name):\n",
    "    mlflow.set_experiment(experiment_name)\n",
    "    mlflow.start_run()\n",
    "\n",
    "def end_mlflow_experiment():\n",
    "    mlflow.end_run()\n",
    "\n",
    "# Define the name of the experiment based on the input file or another identifier\n",
    "def get_experiment_name_from_file(filepath):\n",
    "    experiment_name = os.path.basename(filepath).split('.')[0]  # Extract filename without extension\n",
    "    return experiment_name\n",
    "\n",
    "# Initialize MLflow experiment (This can be placed at the start of your main function)\n",
    "experiment_name = get_experiment_name_from_file(root_folder)  # Using folder as experiment name\n",
    "start_mlflow_experiment(experiment_name)\n",
    "\n",
    "# def extract_participant_from_filename(filepath):\n",
    "#     filename = os.path.basename(filepath)\n",
    "#     parts = filename.split('_')\n",
    "    \n",
    "#     for part in parts:\n",
    "#         if 'participant' in part:\n",
    "#             participant_number = part.replace('participant', '')\n",
    "#             return int(participant_number)  # Convert to integer\n",
    "#     return None  # If no participant label found\n",
    "\n",
    "def extract_label_from_filename(filepath):\n",
    "    filename = os.path.basename(filepath)\n",
    "    parts = filename.split('_')\n",
    "    for part in parts:\n",
    "        if 'gesture' in part:\n",
    "            return int(part.replace('gesture', ''))\n",
    "    return None\n",
    "\n",
    "class EMGDataset(Dataset):\n",
    "    def __init__(self, file_list, target_length, labels, augment=False):\n",
    "        self.file_list = file_list\n",
    "        self.target_length = target_length\n",
    "        self.labels = labels\n",
    "        self.augment = augment\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.file_list)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        file_path = self.file_list[idx]\n",
    "        label = self.labels[idx]\n",
    "        \n",
    "        # Load and process the EMG data\n",
    "        emg_image = load_and_process_file(file_path, self.target_length)\n",
    "        \n",
    "        # Apply augmentation if enabled\n",
    "        if self.augment:\n",
    "            emg_image = augment_data(emg_image, self.target_length)\n",
    "        \n",
    "        # Check if the EMG image has the correct shape\n",
    "        if emg_image.shape != (3, 224, 224):\n",
    "            raise ValueError(f\"EMG data has shape {emg_image.shape} but expected (3, 224, 224)\")\n",
    "\n",
    "        return emg_image, label\n",
    "\n",
    "\n",
    "\n",
    "# Function to load and process a single .mat file\n",
    "def load_and_process_file(filepath, target_length):\n",
    "    mat_data = sio.loadmat(filepath)\n",
    "    data_emg = mat_data['data_emg']\n",
    "    \n",
    "    # Handle NaNs and Infinities\n",
    "    data_emg = np.nan_to_num(data_emg, nan=0.0, posinf=0.0, neginf=0.0)\n",
    "    \n",
    "    # Pad or truncate the data to the target length\n",
    "    if data_emg.shape[0] < target_length:\n",
    "        padded_data = np.pad(data_emg, ((0, target_length - data_emg.shape[0]), (0, 0)), 'constant', constant_values=0)\n",
    "    else:\n",
    "        padded_data = data_emg[:target_length]\n",
    "\n",
    "    # Reshape to 224x224x3 required by ViT (ensure the size is consistent)\n",
    "    padded_data = padded_data.flatten()  # Flatten before reshaping\n",
    "    num_pixels = 3 * 224 * 224 \n",
    "    \n",
    "    # If we don't have enough data, we can pad with zeros; otherwise, truncate\n",
    "    if padded_data.size < num_pixels:\n",
    "        reshaped_data = np.pad(padded_data, (0, num_pixels - padded_data.size), 'constant', constant_values=0)\n",
    "    else:\n",
    "        reshaped_data = padded_data[:num_pixels]\n",
    "    \n",
    "    # Reshape to (3, 224, 224) as required by ViT\n",
    "    reshaped_data = np.reshape(reshaped_data, (3, 224, 224))\n",
    "    \n",
    "    # Normalize data to range [0, 1]\n",
    "    reshaped_data = (reshaped_data - reshaped_data.min()) / (reshaped_data.max() - reshaped_data.min())\n",
    "\n",
    "    return reshaped_data\n",
    "\n",
    "# Path to the root folder where all .mat files are stored\n",
    "\n",
    "# Find all .mat files in the folder\n",
    "all_mat_files = glob.glob(os.path.join(root_folder, '*.mat'))\n",
    "\n",
    "# Collect all corresponding labels\n",
    "labels = [extract_label_from_filename(mat_file) for mat_file in all_mat_files]\n",
    "\n",
    "# Original unique labels\n",
    "unique_labels = np.unique(labels)\n",
    "\n",
    "# Create a mapping from the original labels to the new range 0-4\n",
    "label_mapping = {original_label: new_label for new_label, original_label in enumerate(unique_labels)}\n",
    "\n",
    "# Convert the original labels to the new range using the mapping\n",
    "converted_labels = np.array([label_mapping[label] for label in labels])\n",
    "\n",
    "labels = converted_labels\n",
    "# Target length for EMG signals (adjust based on your data)\n",
    "target_length = 10240  # Modify this as needed\n",
    "\n",
    "# Split the dataset into train and test sets\n",
    "train_files, test_files, train_labels, test_labels = train_test_split(all_mat_files, labels, test_size=0.2, random_state=42, stratify=labels)\n",
    "\n",
    "# Create datasets and dataloaders\n",
    "train_dataset = EMGDataset(train_files, target_length, train_labels, augment=True)  # Apply augmentation during training\n",
    "test_dataset = EMGDataset(test_files, target_length, test_labels, augment=False)    # No augmentation during testing\n",
    "\n",
    "train_loader = DataLoader(train_dataset, batch_size=256, shuffle=True)\n",
    "test_loader = DataLoader(test_dataset, batch_size=256, shuffle=False)\n",
    "\n",
    "# Model configuration for ViT\n",
    "config = ViTConfig(\n",
    "    hidden_size=128,  # Reduced hidden size for smaller dataset\n",
    "    num_attention_heads=4,  # Reduced attention heads\n",
    "    num_hidden_layers=4,  # Reduced number of transformer layers\n",
    "    image_size=224,\n",
    "    patch_size=8,\n",
    "    num_labels=len(unique_labels),\n",
    "    hidden_dropout_prob=0.3,  # Increased dropout for regularization\n",
    "    attention_probs_dropout_prob=0.3\n",
    ")\n",
    "\n",
    "# Instantiate the ViT model\n",
    "model = ViTForImageClassification(config)\n",
    "model = DataParallel(model)\n",
    "# Use AdamW optimizer with weight decay\n",
    "optimizer = AdamW(model.parameters(), lr=1e-4, weight_decay=1e-4)\n",
    "\n",
    "class WarmupCosineAnnealingScheduler(torch.optim.lr_scheduler._LRScheduler):\n",
    "    def __init__(self, optimizer, warmup_epochs, max_epochs, eta_min=0, last_epoch=-1):\n",
    "        self.warmup_epochs = warmup_epochs\n",
    "        self.max_epochs = max_epochs\n",
    "        self.eta_min = eta_min\n",
    "        super().__init__(optimizer, last_epoch)\n",
    "    \n",
    "    def get_lr(self):\n",
    "        if self.last_epoch < self.warmup_epochs:\n",
    "            # Linear warm-up\n",
    "            return [(self.last_epoch + 1) / self.warmup_epochs * base_lr for base_lr in self.base_lrs]\n",
    "        else:\n",
    "            # Cosine annealing\n",
    "            cosine_decay = 0.5 * (1 + torch.cos(torch.tensor(self.last_epoch - self.warmup_epochs) * torch.pi / (self.max_epochs - self.warmup_epochs)))\n",
    "            return [self.eta_min + (base_lr - self.eta_min) * cosine_decay for base_lr in self.base_lrs]\n",
    "\n",
    "warmup_epochs = 5\n",
    "scheduler = WarmupCosineAnnealingScheduler(optimizer, warmup_epochs=warmup_epochs, max_epochs=num_epochs)\n",
    "# Loss function            \n",
    "# Cosine Annealing Learning Rate Scheduler\n",
    "#scheduler = CosineAnnealingLR(optimizer, T_max=10)\n",
    "\n",
    "# Loss function\n",
    "criterion = torch.nn.CrossEntropyLoss()\n",
    "\n",
    "# Move model to GPU if available\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(device)\n",
    "model.to(device)\n",
    "\n",
    "# Training loop\n",
    "\n",
    "clip_value = 1.0  # For gradient clipping\n",
    "best_val_acc = 0.0  # To track the best validation accuracy\n",
    "best_model_path = 'best_model_5gest.pth'\n",
    "last_model_path = 'last_model_5gest.pth'\n",
    "\n",
    "for epoch in range(num_epochs):\n",
    "    model.train()\n",
    "    running_loss = 0.0\n",
    "    correct = 0\n",
    "    total = 0\n",
    "    for inputs, labels in tqdm(train_loader):\n",
    "        inputs, labels = inputs.to(device), labels.to(device)\n",
    "        \n",
    "        optimizer.zero_grad()\n",
    "        outputs = model(inputs).logits\n",
    "        loss = criterion(outputs, labels)\n",
    "        loss.backward()\n",
    "\n",
    "        # Gradient clipping\n",
    "        torch.nn.utils.clip_grad_norm_(model.parameters(), clip_value)\n",
    "\n",
    "        optimizer.step()\n",
    "        scheduler.step()\n",
    "        \n",
    "        running_loss += loss.item()\n",
    "        _, predicted = torch.max(outputs, 1)\n",
    "        total += labels.size(0)\n",
    "        correct += (predicted == labels).sum().item()\n",
    "\n",
    "    epoch_loss = running_loss / len(train_loader)\n",
    "    epoch_acc = correct / total\n",
    "    print(f'Epoch {epoch+1}/{num_epochs}, Loss: {epoch_loss:.4f}, Accuracy: {epoch_acc:.4f}')\n",
    "\n",
    "    mlflow.log_metric(\"train_loss\", epoch_loss, step=epoch)\n",
    "    mlflow.log_metric(\"train_accuracy\", epoch_acc, step=epoch)\n",
    "\n",
    "    # Validation loop\n",
    "    model.eval()\n",
    "    correct = 0\n",
    "    total = 0\n",
    "    val_loss = 0.0\n",
    "    with torch.no_grad():\n",
    "        for inputs, labels in test_loader:\n",
    "            inputs, labels = inputs.to(device), labels.to(device)\n",
    "            outputs = model(inputs).logits\n",
    "            loss = criterion(outputs, labels)\n",
    "            val_loss += loss.item()\n",
    "            _, predicted = torch.max(outputs, 1)\n",
    "            total += labels.size(0)\n",
    "            correct += (predicted == labels).sum().item()\n",
    "\n",
    "    val_loss = val_loss / len(test_loader)\n",
    "    val_acc = correct / total\n",
    "    print(f'Validation Loss: {val_loss:.4f}, Validation Accuracy: {val_acc:.4f}')\n",
    "\n",
    "    mlflow.log_metric(\"val_loss\", val_loss, step=epoch)\n",
    "    mlflow.log_metric(\"val_accuracy\", val_acc, step=epoch)\n",
    "\n",
    "    torch.save(model.state_dict(), last_model_path)\n",
    "    mlflow.pytorch.log_model(model, \"models/last_model\")\n",
    "    # Save the best model based on validation accuracy\n",
    "    if val_acc > best_val_acc:\n",
    "        best_val_acc = val_acc\n",
    "        torch.save(model.state_dict(), best_model_path)\n",
    "        print(f'New best model saved with accuracy: {best_val_acc:.4f}')\n",
    "        mlflow.pytorch.log_model(model, \"models/best_model\")\n",
    "\n",
    "end_mlflow_experiment()        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.7583148558758315\n"
     ]
    },
    {
     "ename": "NameError",
     "evalue": "name 'sds' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[3], line 2\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;28mprint\u001b[39m(best_val_acc)\n\u001b[0;32m----> 2\u001b[0m \u001b[43msds\u001b[49m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'sds' is not defined"
     ]
    }
   ],
   "source": [
    "print(best_val_acc)\n",
    "sds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "# Apply Gaussian noise\n",
    "def add_noise(emg_data, noise_factor=0.05):\n",
    "    noise = np.random.randn(*emg_data.shape) * noise_factor\n",
    "    augmented_data = emg_data + noise\n",
    "    return augmented_data\n",
    "\n",
    "# Time warping: Stretch or compress the time axis slightly\n",
    "def time_warp(emg_data, time_warp_factor=0.1):\n",
    "    stretch_factor = np.random.uniform(1 - time_warp_factor, 1 + time_warp_factor)\n",
    "    indices = np.round(np.linspace(0, emg_data.shape[0] - 1, int(emg_data.shape[0] * stretch_factor))).astype(int)\n",
    "    augmented_data = emg_data[indices % emg_data.shape[0]]\n",
    "    return augmented_data\n",
    "\n",
    "# Signal scaling: Multiply by a random factor\n",
    "def scale_signal(emg_data, scale_factor=0.1):\n",
    "    scaling_factor = np.random.uniform(1 - scale_factor, 1 + scale_factor)\n",
    "    return emg_data * scaling_factor\n",
    "\n",
    "# Random cropping and padding\n",
    "def random_crop_pad(emg_data, target_length):\n",
    "    if emg_data.shape[0] < target_length:\n",
    "        # Pad\n",
    "        pad_size = target_length - emg_data.shape[0]\n",
    "        pad_before = np.random.randint(0, pad_size)\n",
    "        pad_after = pad_size - pad_before\n",
    "        augmented_data = np.pad(emg_data, ((pad_before, pad_after), (0, 0)), 'constant')\n",
    "    else:\n",
    "        # Crop\n",
    "        crop_start = np.random.randint(0, emg_data.shape[0] - target_length)\n",
    "        augmented_data = emg_data[crop_start:crop_start + target_length]\n",
    "    \n",
    "    return augmented_data\n",
    "\n",
    "# Random horizontal or vertical flip\n",
    "def flip(emg_data):\n",
    "    if np.random.rand() > 0.5:\n",
    "        return np.flip(emg_data, axis=0)  # Flip along time axis\n",
    "    return emg_data\n",
    "\n",
    "# Data augmentation pipeline\n",
    "def augment_data(emg_data, target_length):\n",
    "    # Apply augmentations\n",
    "    emg_data = add_noise(emg_data)\n",
    "    #emg_data = time_warp(emg_data)\n",
    "    emg_data = scale_signal(emg_data)\n",
    "    #emg_data = random_crop_pad(emg_data, target_length)\n",
    "    #emg_data = flip(emg_data)\n",
    "    \n",
    "    return emg_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 15/15 [01:05<00:00,  4.36s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 278/500, Loss: 0.6421, Accuracy: 0.7662\n",
      "Validation Loss: 1.0330, Validation Accuracy: 0.6741\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 15/15 [01:05<00:00,  4.35s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 279/500, Loss: 0.6037, Accuracy: 0.7764\n",
      "Validation Loss: 1.0538, Validation Accuracy: 0.6608\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 15/15 [01:05<00:00,  4.34s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 280/500, Loss: 0.6451, Accuracy: 0.7603\n",
      "Validation Loss: 1.0149, Validation Accuracy: 0.6574\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 15/15 [01:05<00:00,  4.37s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 281/500, Loss: 0.6593, Accuracy: 0.7548\n",
      "Validation Loss: 0.9941, Validation Accuracy: 0.6840\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 15/15 [01:05<00:00,  4.34s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 282/500, Loss: 0.6090, Accuracy: 0.7753\n",
      "Validation Loss: 1.0158, Validation Accuracy: 0.6630\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 15/15 [01:05<00:00,  4.34s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 283/500, Loss: 0.6885, Accuracy: 0.7537\n",
      "Validation Loss: 1.0696, Validation Accuracy: 0.6707\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 15/15 [01:05<00:00,  4.37s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 284/500, Loss: 0.6055, Accuracy: 0.7825\n",
      "Validation Loss: 0.9852, Validation Accuracy: 0.6929\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 15/15 [01:05<00:00,  4.34s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 285/500, Loss: 0.6229, Accuracy: 0.7664\n",
      "Validation Loss: 0.9284, Validation Accuracy: 0.6951\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 15/15 [01:05<00:00,  4.37s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 286/500, Loss: 0.5820, Accuracy: 0.7850\n",
      "Validation Loss: 1.0500, Validation Accuracy: 0.6663\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 15/15 [01:05<00:00,  4.35s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 287/500, Loss: 0.6361, Accuracy: 0.7795\n",
      "Validation Loss: 0.9601, Validation Accuracy: 0.6885\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 15/15 [01:05<00:00,  4.35s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 288/500, Loss: 0.5757, Accuracy: 0.7881\n",
      "Validation Loss: 1.0131, Validation Accuracy: 0.6763\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 15/15 [01:05<00:00,  4.36s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 289/500, Loss: 0.5954, Accuracy: 0.7856\n",
      "Validation Loss: 1.0185, Validation Accuracy: 0.6696\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 15/15 [01:05<00:00,  4.36s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 290/500, Loss: 0.5702, Accuracy: 0.7889\n",
      "Validation Loss: 0.9901, Validation Accuracy: 0.6707\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 15/15 [01:06<00:00,  4.40s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 291/500, Loss: 0.5562, Accuracy: 0.7897\n",
      "Validation Loss: 0.9422, Validation Accuracy: 0.6929\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 15/15 [01:05<00:00,  4.36s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 292/500, Loss: 0.5682, Accuracy: 0.7922\n",
      "Validation Loss: 0.9785, Validation Accuracy: 0.6874\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 15/15 [01:05<00:00,  4.34s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 293/500, Loss: 0.5553, Accuracy: 0.8003\n",
      "Validation Loss: 0.9732, Validation Accuracy: 0.6829\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 15/15 [01:05<00:00,  4.35s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 294/500, Loss: 0.5781, Accuracy: 0.7911\n",
      "Validation Loss: 0.9512, Validation Accuracy: 0.6918\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 15/15 [01:05<00:00,  4.35s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 295/500, Loss: 0.5501, Accuracy: 0.7900\n",
      "Validation Loss: 0.9597, Validation Accuracy: 0.6885\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 15/15 [01:05<00:00,  4.34s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 296/500, Loss: 0.5603, Accuracy: 0.8042\n",
      "Validation Loss: 0.9578, Validation Accuracy: 0.6874\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 15/15 [01:05<00:00,  4.34s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 297/500, Loss: 0.5427, Accuracy: 0.8006\n",
      "Validation Loss: 0.9602, Validation Accuracy: 0.6863\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 15/15 [01:05<00:00,  4.35s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 298/500, Loss: 0.5365, Accuracy: 0.8011\n",
      "Validation Loss: 0.9609, Validation Accuracy: 0.6863\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 15/15 [01:05<00:00,  4.36s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 299/500, Loss: 0.5539, Accuracy: 0.8017\n",
      "Validation Loss: 0.9648, Validation Accuracy: 0.6863\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 15/15 [01:05<00:00,  4.38s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 300/500, Loss: 0.5677, Accuracy: 0.7953\n",
      "Validation Loss: 0.9685, Validation Accuracy: 0.6840\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 15/15 [01:05<00:00,  4.34s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 301/500, Loss: 0.5467, Accuracy: 0.8055\n",
      "Validation Loss: 0.9610, Validation Accuracy: 0.6874\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 15/15 [01:04<00:00,  4.33s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 302/500, Loss: 0.5436, Accuracy: 0.7994\n",
      "Validation Loss: 0.9713, Validation Accuracy: 0.6885\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 15/15 [01:05<00:00,  4.37s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 303/500, Loss: 0.5493, Accuracy: 0.7964\n",
      "Validation Loss: 0.9654, Validation Accuracy: 0.6851\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 15/15 [01:05<00:00,  4.36s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 304/500, Loss: 0.5648, Accuracy: 0.7895\n",
      "Validation Loss: 0.9514, Validation Accuracy: 0.6929\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 15/15 [01:05<00:00,  4.39s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 305/500, Loss: 0.5612, Accuracy: 0.7920\n",
      "Validation Loss: 0.9887, Validation Accuracy: 0.6896\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 15/15 [01:05<00:00,  4.39s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 306/500, Loss: 0.5816, Accuracy: 0.7914\n",
      "Validation Loss: 1.0256, Validation Accuracy: 0.6674\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 15/15 [01:05<00:00,  4.34s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 307/500, Loss: 0.5790, Accuracy: 0.7842\n",
      "Validation Loss: 0.9958, Validation Accuracy: 0.6829\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 15/15 [01:05<00:00,  4.36s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 308/500, Loss: 0.5813, Accuracy: 0.7881\n",
      "Validation Loss: 0.9539, Validation Accuracy: 0.6863\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 15/15 [01:05<00:00,  4.34s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 309/500, Loss: 0.5816, Accuracy: 0.7770\n",
      "Validation Loss: 0.9258, Validation Accuracy: 0.6940\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 15/15 [01:04<00:00,  4.33s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 310/500, Loss: 0.5826, Accuracy: 0.7911\n",
      "Validation Loss: 1.0000, Validation Accuracy: 0.6840\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 15/15 [01:05<00:00,  4.35s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 311/500, Loss: 0.5764, Accuracy: 0.7789\n",
      "Validation Loss: 0.9554, Validation Accuracy: 0.7029\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 15/15 [01:05<00:00,  4.34s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 312/500, Loss: 0.5701, Accuracy: 0.7917\n",
      "Validation Loss: 1.0934, Validation Accuracy: 0.6408\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 15/15 [01:04<00:00,  4.33s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 313/500, Loss: 0.5690, Accuracy: 0.7856\n",
      "Validation Loss: 1.0158, Validation Accuracy: 0.6663\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 15/15 [01:04<00:00,  4.31s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 314/500, Loss: 0.5684, Accuracy: 0.7928\n",
      "Validation Loss: 0.9842, Validation Accuracy: 0.7007\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 15/15 [01:05<00:00,  4.33s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 315/500, Loss: 0.5982, Accuracy: 0.7834\n",
      "Validation Loss: 1.0732, Validation Accuracy: 0.6541\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 15/15 [01:04<00:00,  4.33s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 316/500, Loss: 0.6270, Accuracy: 0.7584\n",
      "Validation Loss: 1.0704, Validation Accuracy: 0.6663\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 15/15 [01:05<00:00,  4.35s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 317/500, Loss: 0.6690, Accuracy: 0.7576\n",
      "Validation Loss: 1.0595, Validation Accuracy: 0.6630\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 15/15 [01:05<00:00,  4.34s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 318/500, Loss: 0.5873, Accuracy: 0.7800\n",
      "Validation Loss: 0.9232, Validation Accuracy: 0.7106\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 15/15 [01:04<00:00,  4.32s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 319/500, Loss: 0.5818, Accuracy: 0.7828\n",
      "Validation Loss: 1.0632, Validation Accuracy: 0.6619\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 15/15 [01:04<00:00,  4.33s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 320/500, Loss: 0.6251, Accuracy: 0.7767\n",
      "Validation Loss: 0.9722, Validation Accuracy: 0.6951\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 15/15 [01:05<00:00,  4.34s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 321/500, Loss: 0.6184, Accuracy: 0.7742\n",
      "Validation Loss: 1.1004, Validation Accuracy: 0.6508\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 15/15 [01:05<00:00,  4.36s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 322/500, Loss: 0.6132, Accuracy: 0.7620\n",
      "Validation Loss: 1.1867, Validation Accuracy: 0.6186\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 15/15 [01:05<00:00,  4.34s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 323/500, Loss: 0.7224, Accuracy: 0.7273\n",
      "Validation Loss: 1.1493, Validation Accuracy: 0.6253\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 15/15 [01:04<00:00,  4.33s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 324/500, Loss: 0.6466, Accuracy: 0.7531\n",
      "Validation Loss: 1.1600, Validation Accuracy: 0.6475\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 15/15 [01:05<00:00,  4.34s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 325/500, Loss: 0.6250, Accuracy: 0.7614\n",
      "Validation Loss: 1.1456, Validation Accuracy: 0.6397\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 15/15 [01:05<00:00,  4.36s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 326/500, Loss: 0.6350, Accuracy: 0.7559\n",
      "Validation Loss: 1.2452, Validation Accuracy: 0.6253\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 15/15 [01:05<00:00,  4.34s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 327/500, Loss: 0.6594, Accuracy: 0.7612\n",
      "Validation Loss: 1.1485, Validation Accuracy: 0.6330\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 15/15 [01:04<00:00,  4.31s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 328/500, Loss: 0.6116, Accuracy: 0.7645\n",
      "Validation Loss: 1.2825, Validation Accuracy: 0.5920\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 15/15 [01:04<00:00,  4.33s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 329/500, Loss: 0.6929, Accuracy: 0.7393\n",
      "Validation Loss: 1.0733, Validation Accuracy: 0.6585\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 15/15 [01:04<00:00,  4.33s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 330/500, Loss: 0.6075, Accuracy: 0.7798\n",
      "Validation Loss: 1.0931, Validation Accuracy: 0.6541\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 15/15 [01:05<00:00,  4.34s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 331/500, Loss: 0.6957, Accuracy: 0.7462\n",
      "Validation Loss: 1.2646, Validation Accuracy: 0.6109\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 15/15 [01:04<00:00,  4.31s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 332/500, Loss: 0.6104, Accuracy: 0.7717\n",
      "Validation Loss: 0.9995, Validation Accuracy: 0.6818\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 15/15 [01:05<00:00,  4.35s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 333/500, Loss: 0.5957, Accuracy: 0.7739\n",
      "Validation Loss: 1.2191, Validation Accuracy: 0.6208\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 15/15 [01:04<00:00,  4.30s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 334/500, Loss: 0.6813, Accuracy: 0.7393\n",
      "Validation Loss: 0.9754, Validation Accuracy: 0.6752\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 15/15 [01:04<00:00,  4.33s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 335/500, Loss: 0.6101, Accuracy: 0.7667\n",
      "Validation Loss: 1.0846, Validation Accuracy: 0.6519\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 15/15 [01:04<00:00,  4.31s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 336/500, Loss: 0.6234, Accuracy: 0.7756\n",
      "Validation Loss: 1.0542, Validation Accuracy: 0.6696\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 15/15 [01:04<00:00,  4.33s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 337/500, Loss: 0.6142, Accuracy: 0.7767\n",
      "Validation Loss: 1.1417, Validation Accuracy: 0.6353\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 15/15 [01:05<00:00,  4.33s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 338/500, Loss: 0.6108, Accuracy: 0.7642\n",
      "Validation Loss: 1.0438, Validation Accuracy: 0.6707\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 15/15 [01:04<00:00,  4.33s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 339/500, Loss: 0.5628, Accuracy: 0.7989\n",
      "Validation Loss: 1.0142, Validation Accuracy: 0.6796\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 15/15 [01:05<00:00,  4.36s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 340/500, Loss: 0.5760, Accuracy: 0.7892\n",
      "Validation Loss: 0.9477, Validation Accuracy: 0.6984\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 15/15 [01:04<00:00,  4.33s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 341/500, Loss: 0.5437, Accuracy: 0.7983\n",
      "Validation Loss: 1.0614, Validation Accuracy: 0.6563\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 15/15 [01:05<00:00,  4.35s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 342/500, Loss: 0.5750, Accuracy: 0.7809\n",
      "Validation Loss: 1.0472, Validation Accuracy: 0.6896\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 15/15 [01:05<00:00,  4.34s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 343/500, Loss: 0.5560, Accuracy: 0.7961\n",
      "Validation Loss: 1.0215, Validation Accuracy: 0.6874\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 15/15 [01:05<00:00,  4.35s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 344/500, Loss: 0.5689, Accuracy: 0.7859\n",
      "Validation Loss: 0.9539, Validation Accuracy: 0.7051\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 15/15 [01:05<00:00,  4.34s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 345/500, Loss: 0.5354, Accuracy: 0.8050\n",
      "Validation Loss: 0.9558, Validation Accuracy: 0.6929\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 15/15 [01:04<00:00,  4.31s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 346/500, Loss: 0.5518, Accuracy: 0.7953\n",
      "Validation Loss: 1.0490, Validation Accuracy: 0.6785\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 15/15 [01:04<00:00,  4.32s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 347/500, Loss: 0.6113, Accuracy: 0.7845\n",
      "Validation Loss: 1.0031, Validation Accuracy: 0.6829\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 15/15 [01:05<00:00,  4.36s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 348/500, Loss: 0.5355, Accuracy: 0.8022\n",
      "Validation Loss: 1.1117, Validation Accuracy: 0.6608\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 15/15 [01:05<00:00,  4.34s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 349/500, Loss: 0.5599, Accuracy: 0.7856\n",
      "Validation Loss: 1.0184, Validation Accuracy: 0.6707\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 15/15 [01:05<00:00,  4.34s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 350/500, Loss: 0.5348, Accuracy: 0.8044\n",
      "Validation Loss: 1.0083, Validation Accuracy: 0.7007\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 15/15 [01:05<00:00,  4.35s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 351/500, Loss: 0.5140, Accuracy: 0.8125\n",
      "Validation Loss: 0.9718, Validation Accuracy: 0.7029\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 15/15 [01:05<00:00,  4.37s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 352/500, Loss: 0.5073, Accuracy: 0.8222\n",
      "Validation Loss: 1.0777, Validation Accuracy: 0.6707\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 15/15 [01:05<00:00,  4.37s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 353/500, Loss: 0.5265, Accuracy: 0.8133\n",
      "Validation Loss: 1.0583, Validation Accuracy: 0.6829\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 15/15 [01:05<00:00,  4.35s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 354/500, Loss: 0.4995, Accuracy: 0.8219\n",
      "Validation Loss: 1.0423, Validation Accuracy: 0.6851\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 15/15 [01:05<00:00,  4.34s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 355/500, Loss: 0.4655, Accuracy: 0.8275\n",
      "Validation Loss: 1.0483, Validation Accuracy: 0.6896\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 15/15 [01:05<00:00,  4.39s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 356/500, Loss: 0.4865, Accuracy: 0.8158\n",
      "Validation Loss: 1.0049, Validation Accuracy: 0.6962\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 15/15 [01:05<00:00,  4.38s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 357/500, Loss: 0.4798, Accuracy: 0.8286\n",
      "Validation Loss: 0.9860, Validation Accuracy: 0.7062\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 15/15 [01:05<00:00,  4.39s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 358/500, Loss: 0.4652, Accuracy: 0.8330\n",
      "Validation Loss: 1.0168, Validation Accuracy: 0.7007\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 15/15 [01:05<00:00,  4.37s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 359/500, Loss: 0.4870, Accuracy: 0.8277\n",
      "Validation Loss: 1.0061, Validation Accuracy: 0.6984\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 15/15 [01:05<00:00,  4.38s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 360/500, Loss: 0.4751, Accuracy: 0.8325\n",
      "Validation Loss: 1.0219, Validation Accuracy: 0.6896\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 15/15 [01:05<00:00,  4.34s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 361/500, Loss: 0.4770, Accuracy: 0.8297\n",
      "Validation Loss: 1.0109, Validation Accuracy: 0.6940\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 15/15 [01:05<00:00,  4.37s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 362/500, Loss: 0.4709, Accuracy: 0.8355\n",
      "Validation Loss: 1.0042, Validation Accuracy: 0.6962\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 15/15 [01:05<00:00,  4.36s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 363/500, Loss: 0.4666, Accuracy: 0.8350\n",
      "Validation Loss: 1.0023, Validation Accuracy: 0.6973\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 15/15 [01:05<00:00,  4.37s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 364/500, Loss: 0.4621, Accuracy: 0.8300\n",
      "Validation Loss: 1.0026, Validation Accuracy: 0.6973\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 15/15 [01:05<00:00,  4.37s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 365/500, Loss: 0.4820, Accuracy: 0.8294\n",
      "Validation Loss: 1.0053, Validation Accuracy: 0.6962\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 15/15 [01:05<00:00,  4.36s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 366/500, Loss: 0.4677, Accuracy: 0.8336\n",
      "Validation Loss: 1.0125, Validation Accuracy: 0.6951\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 15/15 [01:05<00:00,  4.35s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 367/500, Loss: 0.4674, Accuracy: 0.8388\n",
      "Validation Loss: 0.9897, Validation Accuracy: 0.7007\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 15/15 [01:04<00:00,  4.33s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 368/500, Loss: 0.4670, Accuracy: 0.8358\n",
      "Validation Loss: 0.9998, Validation Accuracy: 0.6962\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 15/15 [01:05<00:00,  4.34s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 369/500, Loss: 0.4966, Accuracy: 0.8219\n",
      "Validation Loss: 1.0442, Validation Accuracy: 0.6807\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 15/15 [01:05<00:00,  4.37s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 370/500, Loss: 0.4748, Accuracy: 0.8305\n",
      "Validation Loss: 1.0147, Validation Accuracy: 0.6885\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 15/15 [01:05<00:00,  4.36s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 371/500, Loss: 0.4801, Accuracy: 0.8311\n",
      "Validation Loss: 1.0069, Validation Accuracy: 0.6840\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 15/15 [01:04<00:00,  4.32s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 372/500, Loss: 0.4644, Accuracy: 0.8291\n",
      "Validation Loss: 1.0278, Validation Accuracy: 0.6896\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 15/15 [01:05<00:00,  4.38s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 373/500, Loss: 0.4606, Accuracy: 0.8269\n",
      "Validation Loss: 0.9764, Validation Accuracy: 0.7162\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 15/15 [01:05<00:00,  4.38s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 374/500, Loss: 0.4884, Accuracy: 0.8236\n",
      "Validation Loss: 0.9829, Validation Accuracy: 0.7162\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 15/15 [01:05<00:00,  4.38s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 375/500, Loss: 0.4793, Accuracy: 0.8291\n",
      "Validation Loss: 1.1167, Validation Accuracy: 0.6796\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 15/15 [01:05<00:00,  4.34s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 376/500, Loss: 0.5063, Accuracy: 0.8161\n",
      "Validation Loss: 0.9816, Validation Accuracy: 0.7084\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 15/15 [01:05<00:00,  4.35s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 377/500, Loss: 0.5278, Accuracy: 0.8147\n",
      "Validation Loss: 1.0747, Validation Accuracy: 0.6863\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 15/15 [01:05<00:00,  4.36s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 378/500, Loss: 0.5041, Accuracy: 0.8266\n",
      "Validation Loss: 0.9643, Validation Accuracy: 0.7173\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 15/15 [01:04<00:00,  4.33s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 379/500, Loss: 0.4864, Accuracy: 0.8219\n",
      "Validation Loss: 0.9487, Validation Accuracy: 0.7217\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 15/15 [01:05<00:00,  4.38s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 380/500, Loss: 0.4774, Accuracy: 0.8247\n",
      "Validation Loss: 1.1115, Validation Accuracy: 0.6718\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 15/15 [01:05<00:00,  4.34s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 381/500, Loss: 0.5239, Accuracy: 0.8117\n",
      "Validation Loss: 0.9470, Validation Accuracy: 0.6984\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 15/15 [01:05<00:00,  4.37s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 382/500, Loss: 0.5276, Accuracy: 0.8067\n",
      "Validation Loss: 1.1443, Validation Accuracy: 0.6519\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 15/15 [01:05<00:00,  4.34s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 383/500, Loss: 0.4880, Accuracy: 0.8164\n",
      "Validation Loss: 1.0264, Validation Accuracy: 0.6829\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 15/15 [01:05<00:00,  4.36s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 384/500, Loss: 0.5233, Accuracy: 0.8128\n",
      "Validation Loss: 1.0827, Validation Accuracy: 0.6663\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 15/15 [01:05<00:00,  4.35s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 385/500, Loss: 0.5139, Accuracy: 0.8139\n",
      "Validation Loss: 1.0124, Validation Accuracy: 0.6907\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 15/15 [01:05<00:00,  4.37s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 386/500, Loss: 0.5276, Accuracy: 0.8153\n",
      "Validation Loss: 1.0090, Validation Accuracy: 0.6918\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 15/15 [01:05<00:00,  4.34s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 387/500, Loss: 0.5330, Accuracy: 0.8086\n",
      "Validation Loss: 0.9660, Validation Accuracy: 0.7173\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 15/15 [01:05<00:00,  4.36s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 388/500, Loss: 0.5322, Accuracy: 0.8108\n",
      "Validation Loss: 1.0480, Validation Accuracy: 0.6729\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 15/15 [01:05<00:00,  4.34s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 389/500, Loss: 0.5306, Accuracy: 0.8028\n",
      "Validation Loss: 0.9906, Validation Accuracy: 0.6962\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 15/15 [01:05<00:00,  4.36s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 390/500, Loss: 0.5255, Accuracy: 0.8075\n",
      "Validation Loss: 1.1327, Validation Accuracy: 0.6741\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 15/15 [01:05<00:00,  4.35s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 391/500, Loss: 0.5346, Accuracy: 0.8061\n",
      "Validation Loss: 0.9248, Validation Accuracy: 0.7118\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 15/15 [01:05<00:00,  4.34s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 392/500, Loss: 0.5351, Accuracy: 0.8086\n",
      "Validation Loss: 1.0641, Validation Accuracy: 0.6785\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 15/15 [01:05<00:00,  4.38s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 393/500, Loss: 0.5494, Accuracy: 0.8000\n",
      "Validation Loss: 1.0653, Validation Accuracy: 0.6818\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 15/15 [01:05<00:00,  4.35s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 394/500, Loss: 0.5421, Accuracy: 0.8083\n",
      "Validation Loss: 1.1518, Validation Accuracy: 0.6364\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 15/15 [01:05<00:00,  4.37s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 395/500, Loss: 0.5281, Accuracy: 0.7992\n",
      "Validation Loss: 1.1777, Validation Accuracy: 0.6630\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 15/15 [01:05<00:00,  4.36s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 396/500, Loss: 0.6077, Accuracy: 0.7623\n",
      "Validation Loss: 0.9762, Validation Accuracy: 0.7062\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 15/15 [01:05<00:00,  4.38s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 397/500, Loss: 0.5568, Accuracy: 0.8075\n",
      "Validation Loss: 0.9974, Validation Accuracy: 0.7040\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 15/15 [01:05<00:00,  4.37s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 398/500, Loss: 0.5542, Accuracy: 0.7947\n",
      "Validation Loss: 1.0370, Validation Accuracy: 0.6763\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 15/15 [01:04<00:00,  4.33s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 399/500, Loss: 0.5844, Accuracy: 0.7939\n",
      "Validation Loss: 0.9407, Validation Accuracy: 0.7129\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 15/15 [01:05<00:00,  4.38s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 400/500, Loss: 0.5015, Accuracy: 0.8031\n",
      "Validation Loss: 1.0167, Validation Accuracy: 0.6896\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 15/15 [01:06<00:00,  4.40s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 401/500, Loss: 0.5196, Accuracy: 0.8064\n",
      "Validation Loss: 1.0167, Validation Accuracy: 0.6996\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 15/15 [01:04<00:00,  4.31s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 402/500, Loss: 0.4875, Accuracy: 0.8277\n",
      "Validation Loss: 0.9658, Validation Accuracy: 0.6973\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 15/15 [01:05<00:00,  4.37s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 403/500, Loss: 0.5000, Accuracy: 0.8164\n",
      "Validation Loss: 1.0324, Validation Accuracy: 0.6874\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 15/15 [01:05<00:00,  4.37s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 404/500, Loss: 0.5171, Accuracy: 0.8092\n",
      "Validation Loss: 1.2213, Validation Accuracy: 0.6552\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 15/15 [01:05<00:00,  4.39s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 405/500, Loss: 0.5101, Accuracy: 0.8053\n",
      "Validation Loss: 1.1166, Validation Accuracy: 0.6452\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 15/15 [01:05<00:00,  4.37s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 406/500, Loss: 0.5039, Accuracy: 0.8117\n",
      "Validation Loss: 1.0961, Validation Accuracy: 0.6696\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 15/15 [01:05<00:00,  4.34s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 407/500, Loss: 0.4931, Accuracy: 0.8211\n",
      "Validation Loss: 0.9566, Validation Accuracy: 0.7029\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 67%|██████▋   | 10/15 [00:46<00:23,  4.67s/it]\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[2], line 171\u001b[0m\n\u001b[1;32m    169\u001b[0m correct \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m0\u001b[39m\n\u001b[1;32m    170\u001b[0m total \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m0\u001b[39m\n\u001b[0;32m--> 171\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m inputs, labels \u001b[38;5;129;01min\u001b[39;00m tqdm(train_loader):\n\u001b[1;32m    172\u001b[0m     inputs, labels \u001b[38;5;241m=\u001b[39m inputs\u001b[38;5;241m.\u001b[39mto(device), labels\u001b[38;5;241m.\u001b[39mto(device)\n\u001b[1;32m    174\u001b[0m     optimizer\u001b[38;5;241m.\u001b[39mzero_grad()\n",
      "File \u001b[0;32m/data1/George Pap/grabmyo/ptixiaki/.venv/lib/python3.10/site-packages/tqdm/std.py:1181\u001b[0m, in \u001b[0;36mtqdm.__iter__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1178\u001b[0m time \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_time\n\u001b[1;32m   1180\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m-> 1181\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m obj \u001b[38;5;129;01min\u001b[39;00m iterable:\n\u001b[1;32m   1182\u001b[0m         \u001b[38;5;28;01myield\u001b[39;00m obj\n\u001b[1;32m   1183\u001b[0m         \u001b[38;5;66;03m# Update and possibly print the progressbar.\u001b[39;00m\n\u001b[1;32m   1184\u001b[0m         \u001b[38;5;66;03m# Note: does not call self.update(1) for speed optimisation.\u001b[39;00m\n",
      "File \u001b[0;32m/data1/George Pap/grabmyo/ptixiaki/.venv/lib/python3.10/site-packages/torch/utils/data/dataloader.py:630\u001b[0m, in \u001b[0;36m_BaseDataLoaderIter.__next__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    627\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_sampler_iter \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m    628\u001b[0m     \u001b[38;5;66;03m# TODO(https://github.com/pytorch/pytorch/issues/76750)\u001b[39;00m\n\u001b[1;32m    629\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_reset()  \u001b[38;5;66;03m# type: ignore[call-arg]\u001b[39;00m\n\u001b[0;32m--> 630\u001b[0m data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_next_data\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    631\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_num_yielded \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m\n\u001b[1;32m    632\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_dataset_kind \u001b[38;5;241m==\u001b[39m _DatasetKind\u001b[38;5;241m.\u001b[39mIterable \u001b[38;5;129;01mand\u001b[39;00m \\\n\u001b[1;32m    633\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_IterableDataset_len_called \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m \\\n\u001b[1;32m    634\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_num_yielded \u001b[38;5;241m>\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_IterableDataset_len_called:\n",
      "File \u001b[0;32m/data1/George Pap/grabmyo/ptixiaki/.venv/lib/python3.10/site-packages/torch/utils/data/dataloader.py:673\u001b[0m, in \u001b[0;36m_SingleProcessDataLoaderIter._next_data\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    671\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_next_data\u001b[39m(\u001b[38;5;28mself\u001b[39m):\n\u001b[1;32m    672\u001b[0m     index \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_next_index()  \u001b[38;5;66;03m# may raise StopIteration\u001b[39;00m\n\u001b[0;32m--> 673\u001b[0m     data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_dataset_fetcher\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfetch\u001b[49m\u001b[43m(\u001b[49m\u001b[43mindex\u001b[49m\u001b[43m)\u001b[49m  \u001b[38;5;66;03m# may raise StopIteration\u001b[39;00m\n\u001b[1;32m    674\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_pin_memory:\n\u001b[1;32m    675\u001b[0m         data \u001b[38;5;241m=\u001b[39m _utils\u001b[38;5;241m.\u001b[39mpin_memory\u001b[38;5;241m.\u001b[39mpin_memory(data, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_pin_memory_device)\n",
      "File \u001b[0;32m/data1/George Pap/grabmyo/ptixiaki/.venv/lib/python3.10/site-packages/torch/utils/data/_utils/fetch.py:52\u001b[0m, in \u001b[0;36m_MapDatasetFetcher.fetch\u001b[0;34m(self, possibly_batched_index)\u001b[0m\n\u001b[1;32m     50\u001b[0m         data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdataset\u001b[38;5;241m.\u001b[39m__getitems__(possibly_batched_index)\n\u001b[1;32m     51\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m---> 52\u001b[0m         data \u001b[38;5;241m=\u001b[39m [\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdataset[idx] \u001b[38;5;28;01mfor\u001b[39;00m idx \u001b[38;5;129;01min\u001b[39;00m possibly_batched_index]\n\u001b[1;32m     53\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m     54\u001b[0m     data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdataset[possibly_batched_index]\n",
      "File \u001b[0;32m/data1/George Pap/grabmyo/ptixiaki/.venv/lib/python3.10/site-packages/torch/utils/data/_utils/fetch.py:52\u001b[0m, in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m     50\u001b[0m         data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdataset\u001b[38;5;241m.\u001b[39m__getitems__(possibly_batched_index)\n\u001b[1;32m     51\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m---> 52\u001b[0m         data \u001b[38;5;241m=\u001b[39m [\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdataset\u001b[49m\u001b[43m[\u001b[49m\u001b[43midx\u001b[49m\u001b[43m]\u001b[49m \u001b[38;5;28;01mfor\u001b[39;00m idx \u001b[38;5;129;01min\u001b[39;00m possibly_batched_index]\n\u001b[1;32m     53\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m     54\u001b[0m     data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdataset[possibly_batched_index]\n",
      "Cell \u001b[0;32mIn[2], line 36\u001b[0m, in \u001b[0;36mEMGDataset.__getitem__\u001b[0;34m(self, idx)\u001b[0m\n\u001b[1;32m     33\u001b[0m label \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mlabels[idx]\n\u001b[1;32m     35\u001b[0m \u001b[38;5;66;03m# Load and process the EMG data\u001b[39;00m\n\u001b[0;32m---> 36\u001b[0m emg_image \u001b[38;5;241m=\u001b[39m \u001b[43mload_and_process_file\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfile_path\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtarget_length\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     38\u001b[0m \u001b[38;5;66;03m# Apply augmentation if enabled\u001b[39;00m\n\u001b[1;32m     39\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39maugment:\n",
      "Cell \u001b[0;32mIn[2], line 52\u001b[0m, in \u001b[0;36mload_and_process_file\u001b[0;34m(filepath, target_length)\u001b[0m\n\u001b[1;32m     51\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mload_and_process_file\u001b[39m(filepath, target_length):\n\u001b[0;32m---> 52\u001b[0m     mat_data \u001b[38;5;241m=\u001b[39m \u001b[43msio\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mloadmat\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfilepath\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     53\u001b[0m     data_emg \u001b[38;5;241m=\u001b[39m mat_data[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mdata_emg\u001b[39m\u001b[38;5;124m'\u001b[39m]\n\u001b[1;32m     55\u001b[0m     \u001b[38;5;66;03m# Handle NaNs and Infinities\u001b[39;00m\n",
      "File \u001b[0;32m/data1/George Pap/grabmyo/ptixiaki/.venv/lib/python3.10/site-packages/scipy/io/matlab/_mio.py:227\u001b[0m, in \u001b[0;36mloadmat\u001b[0;34m(file_name, mdict, appendmat, **kwargs)\u001b[0m\n\u001b[1;32m    225\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m _open_file_context(file_name, appendmat) \u001b[38;5;28;01mas\u001b[39;00m f:\n\u001b[1;32m    226\u001b[0m     MR, _ \u001b[38;5;241m=\u001b[39m mat_reader_factory(f, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m--> 227\u001b[0m     matfile_dict \u001b[38;5;241m=\u001b[39m \u001b[43mMR\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget_variables\u001b[49m\u001b[43m(\u001b[49m\u001b[43mvariable_names\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    229\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m mdict \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m    230\u001b[0m     mdict\u001b[38;5;241m.\u001b[39mupdate(matfile_dict)\n",
      "File \u001b[0;32m/data1/George Pap/grabmyo/ptixiaki/.venv/lib/python3.10/site-packages/scipy/io/matlab/_mio5.py:333\u001b[0m, in \u001b[0;36mMatFile5Reader.get_variables\u001b[0;34m(self, variable_names)\u001b[0m\n\u001b[1;32m    331\u001b[0m     \u001b[38;5;28;01mcontinue\u001b[39;00m\n\u001b[1;32m    332\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 333\u001b[0m     res \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mread_var_array\u001b[49m\u001b[43m(\u001b[49m\u001b[43mhdr\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mprocess\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    334\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m MatReadError \u001b[38;5;28;01mas\u001b[39;00m err:\n\u001b[1;32m    335\u001b[0m     warnings\u001b[38;5;241m.\u001b[39mwarn(\n\u001b[1;32m    336\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mUnreadable variable \u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mname\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m, because \u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00merr\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m'\u001b[39m,\n\u001b[1;32m    337\u001b[0m         \u001b[38;5;167;01mWarning\u001b[39;00m, stacklevel\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m2\u001b[39m)\n",
      "File \u001b[0;32m/data1/George Pap/grabmyo/ptixiaki/.venv/lib/python3.10/site-packages/scipy/io/matlab/_mio5.py:291\u001b[0m, in \u001b[0;36mMatFile5Reader.read_var_array\u001b[0;34m(self, header, process)\u001b[0m\n\u001b[1;32m    274\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mread_var_array\u001b[39m(\u001b[38;5;28mself\u001b[39m, header, process\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m):\n\u001b[1;32m    275\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m''' Read array, given `header`\u001b[39;00m\n\u001b[1;32m    276\u001b[0m \n\u001b[1;32m    277\u001b[0m \u001b[38;5;124;03m    Parameters\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    289\u001b[0m \u001b[38;5;124;03m       `process`.\u001b[39;00m\n\u001b[1;32m    290\u001b[0m \u001b[38;5;124;03m    '''\u001b[39;00m\n\u001b[0;32m--> 291\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_matrix_reader\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43marray_from_header\u001b[49m\u001b[43m(\u001b[49m\u001b[43mheader\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mprocess\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import scipy.io as sio\n",
    "from sklearn.model_selection import train_test_split\n",
    "import torch\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from transformers import ViTForImageClassification, ViTConfig, AdamW\n",
    "from tqdm import tqdm\n",
    "import glob\n",
    "from torch.optim.lr_scheduler import CosineAnnealingLR\n",
    "from torch.nn import DataParallel\n",
    "\n",
    "def extract_label_from_filename(filepath):\n",
    "    filename = os.path.basename(filepath)\n",
    "    parts = filename.split('_')\n",
    "    for part in parts:\n",
    "        if 'gesture' in part:\n",
    "            return int(part.replace('gesture', ''))\n",
    "    return None\n",
    "# Custom dataset for the EMG data\n",
    "class EMGDataset(Dataset):\n",
    "    def __init__(self, file_list, target_length, labels, augment=False):\n",
    "        self.file_list = file_list\n",
    "        self.target_length = target_length\n",
    "        self.labels = labels\n",
    "        self.augment = augment\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.file_list)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        file_path = self.file_list[idx]\n",
    "        label = self.labels[idx]\n",
    "        \n",
    "        # Load and process the EMG data\n",
    "        emg_image = load_and_process_file(file_path, self.target_length)\n",
    "        \n",
    "        # Apply augmentation if enabled\n",
    "        if self.augment:\n",
    "            emg_image = augment_data(emg_image, self.target_length)\n",
    "        \n",
    "        # Check if the EMG image has the correct shape\n",
    "        if emg_image.shape != (3, 224, 224):\n",
    "            raise ValueError(f\"EMG data has shape {emg_image.shape} but expected (3, 224, 224)\")\n",
    "\n",
    "        return emg_image, label\n",
    "\n",
    "\n",
    "\n",
    "# Function to load and process a single .mat file\n",
    "def load_and_process_file(filepath, target_length):\n",
    "    mat_data = sio.loadmat(filepath)\n",
    "    data_emg = mat_data['data_emg']\n",
    "    \n",
    "    # Handle NaNs and Infinities\n",
    "    data_emg = np.nan_to_num(data_emg, nan=0.0, posinf=0.0, neginf=0.0)\n",
    "    \n",
    "    # Pad or truncate the data to the target length\n",
    "    if data_emg.shape[0] < target_length:\n",
    "        padded_data = np.pad(data_emg, ((0, target_length - data_emg.shape[0]), (0, 0)), 'constant', constant_values=0)\n",
    "    else:\n",
    "        padded_data = data_emg[:target_length]\n",
    "\n",
    "    # Reshape to 224x224x3 required by ViT (ensure the size is consistent)\n",
    "    padded_data = padded_data.flatten()  # Flatten before reshaping\n",
    "    num_pixels = 3 * 224 * 224 \n",
    "    \n",
    "    # If we don't have enough data, we can pad with zeros; otherwise, truncate\n",
    "    if padded_data.size < num_pixels:\n",
    "        reshaped_data = np.pad(padded_data, (0, num_pixels - padded_data.size), 'constant', constant_values=0)\n",
    "    else:\n",
    "        reshaped_data = padded_data[:num_pixels]\n",
    "    \n",
    "    # Reshape to (3, 224, 224) as required by ViT\n",
    "    reshaped_data = np.reshape(reshaped_data, (3, 224, 224))\n",
    "    \n",
    "    # Normalize data to range [0, 1]\n",
    "    reshaped_data = (reshaped_data - reshaped_data.min()) / (reshaped_data.max() - reshaped_data.min())\n",
    "\n",
    "    return reshaped_data\n",
    "\n",
    "# Path to the root folder where all .mat files are stored\n",
    "root_folder = 's1_s2_s3_matfiles_5gest'  # Update with your folder path\n",
    "num_epochs = 500\n",
    "# Find all .mat files in the folder\n",
    "all_mat_files = glob.glob(os.path.join(root_folder, '*.mat'))\n",
    "\n",
    "# Collect all corresponding labels\n",
    "labels = [extract_label_from_filename(mat_file) for mat_file in all_mat_files]\n",
    "\n",
    "# Original unique labels\n",
    "unique_labels = np.unique(labels)\n",
    "\n",
    "# Create a mapping from the original labels to the new range 0-4\n",
    "label_mapping = {original_label: new_label for new_label, original_label in enumerate(unique_labels)}\n",
    "\n",
    "# Convert the original labels to the new range using the mapping\n",
    "converted_labels = np.array([label_mapping[label] for label in labels])\n",
    "\n",
    "labels = converted_labels\n",
    "# Target length for EMG signals (adjust based on your data)\n",
    "target_length = 10240  # Modify this as needed\n",
    "\n",
    "# Split the dataset into train and test sets\n",
    "train_files, test_files, train_labels, test_labels = train_test_split(all_mat_files, labels, test_size=0.2, random_state=42, stratify=labels)\n",
    "\n",
    "# Create datasets and dataloaders\n",
    "train_dataset = EMGDataset(train_files, target_length, train_labels, augment=True)  # Apply augmentation during training\n",
    "test_dataset = EMGDataset(test_files, target_length, test_labels, augment=False)    # No augmentation during testing\n",
    "\n",
    "train_loader = DataLoader(train_dataset, batch_size=256, shuffle=True)\n",
    "test_loader = DataLoader(test_dataset, batch_size=256, shuffle=False)\n",
    "\n",
    "# Model configuration for ViT\n",
    "config = ViTConfig(\n",
    "    hidden_size=128,  # Reduced hidden size for smaller dataset\n",
    "    num_attention_heads=4,  # Reduced attention heads\n",
    "    num_hidden_layers=4,  # Reduced number of transformer layers\n",
    "    image_size=224,\n",
    "    patch_size=16,\n",
    "    num_labels=len(unique_labels),\n",
    "    hidden_dropout_prob=0.3,  # Increased dropout for regularization\n",
    "    attention_probs_dropout_prob=0.3\n",
    ")\n",
    "\n",
    "# Instantiate the ViT model\n",
    "model = ViTForImageClassification(config)\n",
    "model = DataParallel(model)\n",
    "# Use AdamW optimizer with weight decay\n",
    "optimizer = AdamW(model.parameters(), lr=1e-4, weight_decay=1e-4)\n",
    "\n",
    "class WarmupCosineAnnealingScheduler(torch.optim.lr_scheduler._LRScheduler):\n",
    "    def __init__(self, optimizer, warmup_epochs, max_epochs, eta_min=0, last_epoch=-1):\n",
    "        self.warmup_epochs = warmup_epochs\n",
    "        self.max_epochs = max_epochs\n",
    "        self.eta_min = eta_min\n",
    "        super().__init__(optimizer, last_epoch)\n",
    "    \n",
    "    def get_lr(self):\n",
    "        if self.last_epoch < self.warmup_epochs:\n",
    "            # Linear warm-up\n",
    "            return [(self.last_epoch + 1) / self.warmup_epochs * base_lr for base_lr in self.base_lrs]\n",
    "        else:\n",
    "            # Cosine annealing\n",
    "            cosine_decay = 0.5 * (1 + torch.cos(torch.tensor(self.last_epoch - self.warmup_epochs) * torch.pi / (self.max_epochs - self.warmup_epochs)))\n",
    "            return [self.eta_min + (base_lr - self.eta_min) * cosine_decay for base_lr in self.base_lrs]\n",
    "\n",
    "warmup_epochs = 5\n",
    "scheduler = WarmupCosineAnnealingScheduler(optimizer, warmup_epochs=warmup_epochs, max_epochs=num_epochs)\n",
    "# Loss function            \n",
    "# Cosine Annealing Learning Rate Scheduler\n",
    "#scheduler = CosineAnnealingLR(optimizer, T_max=10)\n",
    "\n",
    "# Loss function\n",
    "criterion = torch.nn.CrossEntropyLoss()\n",
    "\n",
    "# Move model to GPU if available\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(device)\n",
    "model.to(device)\n",
    "\n",
    "# Training loop\n",
    "\n",
    "clip_value = 1.0  # For gradient clipping\n",
    "\n",
    "for epoch in range(num_epochs):\n",
    "    model.train()\n",
    "    running_loss = 0.0\n",
    "    correct = 0\n",
    "    total = 0\n",
    "    for inputs, labels in tqdm(train_loader):\n",
    "        inputs, labels = inputs.to(device), labels.to(device)\n",
    "        \n",
    "        optimizer.zero_grad()\n",
    "        outputs = model(inputs).logits\n",
    "        loss = criterion(outputs, labels)\n",
    "        loss.backward()\n",
    "\n",
    "        # Gradient clipping\n",
    "        torch.nn.utils.clip_grad_norm_(model.parameters(), clip_value)\n",
    "\n",
    "        optimizer.step()\n",
    "        scheduler.step()\n",
    "        \n",
    "        running_loss += loss.item()\n",
    "        _, predicted = torch.max(outputs, 1)\n",
    "        total += labels.size(0)\n",
    "        correct += (predicted == labels).sum().item()\n",
    "\n",
    "    epoch_loss = running_loss / len(train_loader)\n",
    "    epoch_acc = correct / total\n",
    "    print(f'Epoch {epoch+1}/{num_epochs}, Loss: {epoch_loss:.4f}, Accuracy: {epoch_acc:.4f}')\n",
    "\n",
    "    # Validation loop\n",
    "    model.eval()\n",
    "    correct = 0\n",
    "    total = 0\n",
    "    val_loss = 0.0\n",
    "    with torch.no_grad():\n",
    "        for inputs, labels in test_loader:\n",
    "            inputs, labels = inputs.to(device), labels.to(device)\n",
    "            outputs = model(inputs).logits\n",
    "            loss = criterion(outputs, labels)\n",
    "            val_loss += loss.item()\n",
    "            _, predicted = torch.max(outputs, 1)\n",
    "            total += labels.size(0)\n",
    "            correct += (predicted == labels).sum().item()\n",
    "\n",
    "    val_loss = val_loss / len(test_loader)\n",
    "    val_acc = correct / total\n",
    "    print(f'Validation Loss: {val_loss:.4f}, Validation Accuracy: {val_acc:.4f}')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.save(model.state_dict(), \"best_model_5gest\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import scipy.io as sio\n",
    "from sklearn.model_selection import train_test_split\n",
    "import torch\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from transformers import ViTForImageClassification, ViTFeatureExtractor\n",
    "from tqdm import tqdm\n",
    "import glob\n",
    "\n",
    "# Function to extract the participant ID from the filename\n",
    "# def extract_participant_from_filename(filepath):\n",
    "#     filename = os.path.basename(filepath)\n",
    "#     parts = filename.split('_')\n",
    "#     for part in parts:\n",
    "#         if 'participant' in part:\n",
    "#             participant_id = part.replace('participant', '')\n",
    "#             return int(participant_id)  # Convert to integer\n",
    "#     return None  # If no participant ID found\n",
    "\n",
    "# # Function to extract gesture label from the filename\n",
    "def extract_label_from_filename(filepath):\n",
    "    filename = os.path.basename(filepath)\n",
    "    parts = filename.split('_')\n",
    "    for part in parts:\n",
    "        if 'gesture' in part:\n",
    "            return int(part.replace('gesture', ''))\n",
    "    return None\n",
    "\n",
    "# Function to load and process a single .mat file\n",
    "def load_and_process_file(filepath, target_length):\n",
    "    mat_data = sio.loadmat(filepath)\n",
    "    data_emg = mat_data['data_emg']\n",
    "    \n",
    "    # Handle NaNs and Infinities\n",
    "    data_emg = np.nan_to_num(data_emg, nan=0.0, posinf=0.0, neginf=0.0)\n",
    "    \n",
    "    # Pad or truncate the data to the target length\n",
    "    if data_emg.shape[0] < target_length:\n",
    "        padded_data = np.pad(data_emg, ((0, target_length - data_emg.shape[0]), (0, 0)), 'constant', constant_values=0)\n",
    "    else:\n",
    "        padded_data = data_emg[:target_length]\n",
    "\n",
    "    # Reshape to 224x224x3 required by ViT (ensure the size is consistent)\n",
    "    padded_data = padded_data.flatten()  # Flatten before reshaping\n",
    "    num_pixels = 3 * 224 * 224 \n",
    "    \n",
    "    # If we don't have enough data, we can pad with zeros; otherwise, truncate\n",
    "    if padded_data.size < num_pixels:\n",
    "        reshaped_data = np.pad(padded_data, (0, num_pixels - padded_data.size), 'constant', constant_values=0)\n",
    "    else:\n",
    "        reshaped_data = padded_data[:num_pixels]\n",
    "    \n",
    "    # Reshape to (224, 224, 3) as required by ViT\n",
    "    reshaped_data = np.reshape(reshaped_data, (3, 224, 224))\n",
    "    \n",
    "    # Normalize data to range [0, 1]\n",
    "    reshaped_data = (reshaped_data - reshaped_data.min()) / (reshaped_data.max() - reshaped_data.min())\n",
    "\n",
    "    return reshaped_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "# Custom dataset for the EMG data\n",
    "class EMGDataset(Dataset):\n",
    "    def __init__(self, file_list, target_length, labels):\n",
    "        self.file_list = file_list\n",
    "        self.target_length = target_length\n",
    "        self.labels = labels\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.file_list)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        file_path = self.file_list[idx]\n",
    "        label = self.labels[idx]\n",
    "        emg_image = load_and_process_file(file_path, self.target_length)\n",
    "        return emg_image, label\n",
    "\n",
    "# Path to the root folder where all .mat files are stored\n",
    "root_folder = 's1_s2_s3_matfiles_10gest'  # Update with your folder path\n",
    "\n",
    "# Find all .mat files in the folder\n",
    "all_mat_files = glob.glob(os.path.join(root_folder, '*.mat'))\n",
    "\n",
    "# Collect all corresponding labels\n",
    "labels = [extract_label_from_filename(mat_file) for mat_file in all_mat_files]\n",
    "\n",
    "# Original unique labels\n",
    "unique_labels = np.unique(labels)\n",
    "\n",
    "# Create a mapping from the original labels to the new range 0-4\n",
    "label_mapping = {original_label: new_label for new_label, original_label in enumerate(unique_labels)}\n",
    "\n",
    "# Convert the original labels to the new range using the mapping\n",
    "converted_labels = np.array([label_mapping[label] for label in labels])\n",
    "\n",
    "labels = converted_labels\n",
    "# Target length for EMG signals (adjust based on your data)\n",
    "target_length = 10240  # Modify this as needed\n",
    "\n",
    "# Split the dataset into train and test sets\n",
    "train_files, test_files, train_labels, test_labels = train_test_split(all_mat_files, labels, test_size=0.3, random_state=42)\n",
    "\n",
    "# Create datasets and dataloaders\n",
    "train_dataset = EMGDataset(train_files, target_length, train_labels)\n",
    "test_dataset = EMGDataset(test_files, target_length, test_labels)\n",
    "\n",
    "train_loader = DataLoader(train_dataset, batch_size=64, shuffle=True)\n",
    "test_loader = DataLoader(test_dataset, batch_size=64, shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 99/99 [01:39<00:00,  1.01s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [1/30], Loss: 2.3801\n",
      "Test Accuracy after epoch 1: 9.61%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 99/99 [01:39<00:00,  1.00s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [2/30], Loss: 2.3265\n",
      "Test Accuracy after epoch 2: 13.09%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 99/99 [01:39<00:00,  1.00s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [3/30], Loss: 2.3073\n",
      "Test Accuracy after epoch 3: 14.05%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 99/99 [01:39<00:00,  1.00s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [4/30], Loss: 2.2720\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[5], line 66\u001b[0m\n\u001b[1;32m     64\u001b[0m total \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m0\u001b[39m\n\u001b[1;32m     65\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m torch\u001b[38;5;241m.\u001b[39mno_grad():\n\u001b[0;32m---> 66\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m images, labels \u001b[38;5;129;01min\u001b[39;00m test_loader:\n\u001b[1;32m     67\u001b[0m         images, labels \u001b[38;5;241m=\u001b[39m images\u001b[38;5;241m.\u001b[39mto(device), labels\u001b[38;5;241m.\u001b[39mto(device)\n\u001b[1;32m     68\u001b[0m         outputs \u001b[38;5;241m=\u001b[39m model(images)\u001b[38;5;241m.\u001b[39mlogits\n",
      "File \u001b[0;32m/data1/George Pap/grabmyo/ptixiaki/.venv/lib/python3.10/site-packages/torch/utils/data/dataloader.py:630\u001b[0m, in \u001b[0;36m_BaseDataLoaderIter.__next__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    627\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_sampler_iter \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m    628\u001b[0m     \u001b[38;5;66;03m# TODO(https://github.com/pytorch/pytorch/issues/76750)\u001b[39;00m\n\u001b[1;32m    629\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_reset()  \u001b[38;5;66;03m# type: ignore[call-arg]\u001b[39;00m\n\u001b[0;32m--> 630\u001b[0m data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_next_data\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    631\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_num_yielded \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m\n\u001b[1;32m    632\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_dataset_kind \u001b[38;5;241m==\u001b[39m _DatasetKind\u001b[38;5;241m.\u001b[39mIterable \u001b[38;5;129;01mand\u001b[39;00m \\\n\u001b[1;32m    633\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_IterableDataset_len_called \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m \\\n\u001b[1;32m    634\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_num_yielded \u001b[38;5;241m>\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_IterableDataset_len_called:\n",
      "File \u001b[0;32m/data1/George Pap/grabmyo/ptixiaki/.venv/lib/python3.10/site-packages/torch/utils/data/dataloader.py:673\u001b[0m, in \u001b[0;36m_SingleProcessDataLoaderIter._next_data\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    671\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_next_data\u001b[39m(\u001b[38;5;28mself\u001b[39m):\n\u001b[1;32m    672\u001b[0m     index \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_next_index()  \u001b[38;5;66;03m# may raise StopIteration\u001b[39;00m\n\u001b[0;32m--> 673\u001b[0m     data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_dataset_fetcher\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfetch\u001b[49m\u001b[43m(\u001b[49m\u001b[43mindex\u001b[49m\u001b[43m)\u001b[49m  \u001b[38;5;66;03m# may raise StopIteration\u001b[39;00m\n\u001b[1;32m    674\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_pin_memory:\n\u001b[1;32m    675\u001b[0m         data \u001b[38;5;241m=\u001b[39m _utils\u001b[38;5;241m.\u001b[39mpin_memory\u001b[38;5;241m.\u001b[39mpin_memory(data, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_pin_memory_device)\n",
      "File \u001b[0;32m/data1/George Pap/grabmyo/ptixiaki/.venv/lib/python3.10/site-packages/torch/utils/data/_utils/fetch.py:52\u001b[0m, in \u001b[0;36m_MapDatasetFetcher.fetch\u001b[0;34m(self, possibly_batched_index)\u001b[0m\n\u001b[1;32m     50\u001b[0m         data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdataset\u001b[38;5;241m.\u001b[39m__getitems__(possibly_batched_index)\n\u001b[1;32m     51\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m---> 52\u001b[0m         data \u001b[38;5;241m=\u001b[39m [\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdataset[idx] \u001b[38;5;28;01mfor\u001b[39;00m idx \u001b[38;5;129;01min\u001b[39;00m possibly_batched_index]\n\u001b[1;32m     53\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m     54\u001b[0m     data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdataset[possibly_batched_index]\n",
      "File \u001b[0;32m/data1/George Pap/grabmyo/ptixiaki/.venv/lib/python3.10/site-packages/torch/utils/data/_utils/fetch.py:52\u001b[0m, in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m     50\u001b[0m         data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdataset\u001b[38;5;241m.\u001b[39m__getitems__(possibly_batched_index)\n\u001b[1;32m     51\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m---> 52\u001b[0m         data \u001b[38;5;241m=\u001b[39m [\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdataset\u001b[49m\u001b[43m[\u001b[49m\u001b[43midx\u001b[49m\u001b[43m]\u001b[49m \u001b[38;5;28;01mfor\u001b[39;00m idx \u001b[38;5;129;01min\u001b[39;00m possibly_batched_index]\n\u001b[1;32m     53\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m     54\u001b[0m     data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdataset[possibly_batched_index]\n",
      "Cell \u001b[0;32mIn[4], line 14\u001b[0m, in \u001b[0;36mEMGDataset.__getitem__\u001b[0;34m(self, idx)\u001b[0m\n\u001b[1;32m     12\u001b[0m file_path \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mfile_list[idx]\n\u001b[1;32m     13\u001b[0m label \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mlabels[idx]\n\u001b[0;32m---> 14\u001b[0m emg_image \u001b[38;5;241m=\u001b[39m \u001b[43mload_and_process_file\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfile_path\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtarget_length\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     15\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m emg_image, label\n",
      "Cell \u001b[0;32mIn[3], line 32\u001b[0m, in \u001b[0;36mload_and_process_file\u001b[0;34m(filepath, target_length)\u001b[0m\n\u001b[1;32m     31\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mload_and_process_file\u001b[39m(filepath, target_length):\n\u001b[0;32m---> 32\u001b[0m     mat_data \u001b[38;5;241m=\u001b[39m \u001b[43msio\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mloadmat\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfilepath\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     33\u001b[0m     data_emg \u001b[38;5;241m=\u001b[39m mat_data[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mdata_emg\u001b[39m\u001b[38;5;124m'\u001b[39m]\n\u001b[1;32m     35\u001b[0m     \u001b[38;5;66;03m# Handle NaNs and Infinities\u001b[39;00m\n",
      "File \u001b[0;32m/data1/George Pap/grabmyo/ptixiaki/.venv/lib/python3.10/site-packages/scipy/io/matlab/_mio.py:227\u001b[0m, in \u001b[0;36mloadmat\u001b[0;34m(file_name, mdict, appendmat, **kwargs)\u001b[0m\n\u001b[1;32m    225\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m _open_file_context(file_name, appendmat) \u001b[38;5;28;01mas\u001b[39;00m f:\n\u001b[1;32m    226\u001b[0m     MR, _ \u001b[38;5;241m=\u001b[39m mat_reader_factory(f, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m--> 227\u001b[0m     matfile_dict \u001b[38;5;241m=\u001b[39m \u001b[43mMR\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget_variables\u001b[49m\u001b[43m(\u001b[49m\u001b[43mvariable_names\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    229\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m mdict \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m    230\u001b[0m     mdict\u001b[38;5;241m.\u001b[39mupdate(matfile_dict)\n",
      "File \u001b[0;32m/data1/George Pap/grabmyo/ptixiaki/.venv/lib/python3.10/site-packages/scipy/io/matlab/_mio5.py:333\u001b[0m, in \u001b[0;36mMatFile5Reader.get_variables\u001b[0;34m(self, variable_names)\u001b[0m\n\u001b[1;32m    331\u001b[0m     \u001b[38;5;28;01mcontinue\u001b[39;00m\n\u001b[1;32m    332\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 333\u001b[0m     res \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mread_var_array\u001b[49m\u001b[43m(\u001b[49m\u001b[43mhdr\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mprocess\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    334\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m MatReadError \u001b[38;5;28;01mas\u001b[39;00m err:\n\u001b[1;32m    335\u001b[0m     warnings\u001b[38;5;241m.\u001b[39mwarn(\n\u001b[1;32m    336\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mUnreadable variable \u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mname\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m, because \u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00merr\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m'\u001b[39m,\n\u001b[1;32m    337\u001b[0m         \u001b[38;5;167;01mWarning\u001b[39;00m, stacklevel\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m2\u001b[39m)\n",
      "File \u001b[0;32m/data1/George Pap/grabmyo/ptixiaki/.venv/lib/python3.10/site-packages/scipy/io/matlab/_mio5.py:291\u001b[0m, in \u001b[0;36mMatFile5Reader.read_var_array\u001b[0;34m(self, header, process)\u001b[0m\n\u001b[1;32m    274\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mread_var_array\u001b[39m(\u001b[38;5;28mself\u001b[39m, header, process\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m):\n\u001b[1;32m    275\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m''' Read array, given `header`\u001b[39;00m\n\u001b[1;32m    276\u001b[0m \n\u001b[1;32m    277\u001b[0m \u001b[38;5;124;03m    Parameters\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    289\u001b[0m \u001b[38;5;124;03m       `process`.\u001b[39;00m\n\u001b[1;32m    290\u001b[0m \u001b[38;5;124;03m    '''\u001b[39;00m\n\u001b[0;32m--> 291\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_matrix_reader\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43marray_from_header\u001b[49m\u001b[43m(\u001b[49m\u001b[43mheader\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mprocess\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m_mio5_utils.pyx:665\u001b[0m, in \u001b[0;36mscipy.io.matlab._mio5_utils.VarReader5.array_from_header\u001b[0;34m()\u001b[0m\n",
      "File \u001b[0;32m_mio5_utils.pyx:712\u001b[0m, in \u001b[0;36mscipy.io.matlab._mio5_utils.VarReader5.array_from_header\u001b[0;34m()\u001b[0m\n",
      "File \u001b[0;32m_mio5_utils.pyx:956\u001b[0m, in \u001b[0;36mscipy.io.matlab._mio5_utils.VarReader5.read_struct\u001b[0;34m()\u001b[0m\n",
      "File \u001b[0;32m_mio5_utils.pyx:663\u001b[0m, in \u001b[0;36mscipy.io.matlab._mio5_utils.VarReader5.read_mi_matrix\u001b[0;34m()\u001b[0m\n",
      "File \u001b[0;32m_mio5_utils.pyx:706\u001b[0m, in \u001b[0;36mscipy.io.matlab._mio5_utils.VarReader5.array_from_header\u001b[0;34m()\u001b[0m\n",
      "File \u001b[0;32m_mio5_utils.pyx:867\u001b[0m, in \u001b[0;36mscipy.io.matlab._mio5_utils.VarReader5.read_char\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from transformers import ViTForImageClassification, ViTConfig\n",
    "from tqdm import tqdm\n",
    "\n",
    "# Define the number of classes (in this case, the number of participants)\n",
    "num_classes = len(np.unique(labels))\n",
    "\n",
    "config = ViTConfig(\n",
    "    num_hidden_layers=6,  # Reduced number of layers\n",
    "    hidden_size=512,      # Smaller hidden size\n",
    "    num_attention_heads=4,  # Fewer attention heads\n",
    "    patch_size=16,        # Smaller patch size\n",
    "    intermediate_size=1024,  # Reduced intermediate layer size\n",
    "    image_size=224,       # Input image size\n",
    "    num_labels=num_classes,         # Number of output classes\n",
    "    hidden_dropout_prob=0.3,  # Adding dropout to regularize\n",
    "    attention_probs_dropout_prob=0.3\n",
    ")\n",
    "\n",
    "# Initialize ViT model from scratch with this config\n",
    "model = ViTForImageClassification(config)\n",
    "\n",
    "# Define optimizer with weight decay\n",
    "optimizer = torch.optim.AdamW(model.parameters(), lr=3e-4, weight_decay=1e-4)\n",
    "\n",
    "# Move model to GPU if available\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "model.to(device)\n",
    "\n",
    "# Define loss function and optimizer\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "\n",
    "# Training loop\n",
    "num_epochs = 30  # Set the number of epochs\n",
    "\n",
    "for epoch in range(num_epochs):\n",
    "    model.train()\n",
    "    running_loss = 0.0\n",
    "\n",
    "    for images, labels in tqdm(train_loader):\n",
    "        # Move data to the same device as the model\n",
    "        images, labels = images.to(device), labels.to(device)\n",
    "\n",
    "        # Zero the parameter gradients\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        # Forward pass\n",
    "        outputs = model(images).logits\n",
    "        loss = criterion(outputs, labels)\n",
    "\n",
    "        # Backward pass and optimization\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        running_loss += loss.item()\n",
    "\n",
    "    print(f\"Epoch [{epoch+1}/{num_epochs}], Loss: {running_loss/len(train_loader):.4f}\")\n",
    "\n",
    "    # Evaluation after every epoch (optional)\n",
    "    model.eval()\n",
    "    correct = 0\n",
    "    total = 0\n",
    "    with torch.no_grad():\n",
    "        for images, labels in test_loader:\n",
    "            images, labels = images.to(device), labels.to(device)\n",
    "            outputs = model(images).logits\n",
    "            _, predicted = torch.max(outputs, 1)\n",
    "            total += labels.size(0)\n",
    "            correct += (predicted == labels).sum().item()\n",
    "\n",
    "    accuracy = 100 * correct / total\n",
    "    print(f\"Test Accuracy after epoch {epoch+1}: {accuracy:.2f}%\")\n",
    "\n",
    "# Save the trained model\n",
    "torch.save(model.state_dict(), 'vit_emg_model.pth')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model output classes: 10\n",
      "Unique labels in dataset: [0 1 2 3 4 5 6 7 8 9]\n"
     ]
    }
   ],
   "source": [
    "print(f\"Model output classes: {model.config.num_labels}\")\n",
    "print(f\"Unique labels in dataset: {np.unique(train_labels)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 1/50: 100%|██████████| 90/90 [01:11<00:00,  1.26it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1, Loss: 2.2416, Accuracy: 0.1794\n",
      "Test accuracy: 0.2553\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 2/50: 100%|██████████| 90/90 [01:12<00:00,  1.25it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2, Loss: 1.8933, Accuracy: 0.3556\n",
      "Test accuracy: 0.3955\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 3/50: 100%|██████████| 90/90 [01:11<00:00,  1.25it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 3, Loss: 1.6035, Accuracy: 0.4693\n",
      "Test accuracy: 0.4320\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 4/50: 100%|██████████| 90/90 [01:11<00:00,  1.26it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 4, Loss: 1.3069, Accuracy: 0.5781\n",
      "Test accuracy: 0.4600\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 5/50: 100%|██████████| 90/90 [01:11<00:00,  1.26it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 5, Loss: 1.0768, Accuracy: 0.6511\n",
      "Test accuracy: 0.5470\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 6/50: 100%|██████████| 90/90 [01:11<00:00,  1.26it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 6, Loss: 0.6955, Accuracy: 0.7943\n",
      "Test accuracy: 0.5330\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 7/50: 100%|██████████| 90/90 [01:11<00:00,  1.26it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 7, Loss: 0.4704, Accuracy: 0.8635\n",
      "Test accuracy: 0.5259\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 8/50: 100%|██████████| 90/90 [01:11<00:00,  1.25it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 8, Loss: 0.3046, Accuracy: 0.9210\n",
      "Test accuracy: 0.5498\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 9/50: 100%|██████████| 90/90 [01:11<00:00,  1.26it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 9, Loss: 0.2185, Accuracy: 0.9438\n",
      "Test accuracy: 0.5512\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 10/50: 100%|██████████| 90/90 [01:11<00:00,  1.26it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 10, Loss: 0.1618, Accuracy: 0.9582\n",
      "Test accuracy: 0.4867\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 11/50: 100%|██████████| 90/90 [01:11<00:00,  1.26it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 11, Loss: 0.1546, Accuracy: 0.9596\n",
      "Test accuracy: 0.5456\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 12/50: 100%|██████████| 90/90 [01:11<00:00,  1.26it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 12, Loss: 0.1435, Accuracy: 0.9603\n",
      "Test accuracy: 0.5652\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 13/50: 100%|██████████| 90/90 [01:11<00:00,  1.26it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 13, Loss: 0.0731, Accuracy: 0.9849\n",
      "Test accuracy: 0.4923\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 14/50: 100%|██████████| 90/90 [01:11<00:00,  1.26it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 14, Loss: 0.1267, Accuracy: 0.9645\n",
      "Test accuracy: 0.4979\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 15/50: 100%|██████████| 90/90 [01:11<00:00,  1.26it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 15, Loss: 0.0674, Accuracy: 0.9835\n",
      "Test accuracy: 0.5302\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 16/50: 100%|██████████| 90/90 [01:11<00:00,  1.26it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 16, Loss: 0.0767, Accuracy: 0.9796\n",
      "Test accuracy: 0.5666\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 17/50: 100%|██████████| 90/90 [01:11<00:00,  1.25it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 17, Loss: 0.0595, Accuracy: 0.9849\n",
      "Test accuracy: 0.5891\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 18/50: 100%|██████████| 90/90 [01:11<00:00,  1.26it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 18, Loss: 0.0322, Accuracy: 0.9940\n",
      "Test accuracy: 0.5428\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 19/50: 100%|██████████| 90/90 [01:11<00:00,  1.26it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 19, Loss: 0.0548, Accuracy: 0.9839\n",
      "Test accuracy: 0.5680\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 20/50: 100%|██████████| 90/90 [01:11<00:00,  1.26it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 20, Loss: 0.0505, Accuracy: 0.9856\n",
      "Test accuracy: 0.5666\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 21/50: 100%|██████████| 90/90 [01:11<00:00,  1.26it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 21, Loss: 0.0864, Accuracy: 0.9744\n",
      "Test accuracy: 0.5722\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 22/50: 100%|██████████| 90/90 [01:11<00:00,  1.26it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 22, Loss: 0.1016, Accuracy: 0.9698\n",
      "Test accuracy: 0.4769\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 23/50: 100%|██████████| 90/90 [01:11<00:00,  1.26it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 23, Loss: 0.0759, Accuracy: 0.9772\n",
      "Test accuracy: 0.5330\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 24/50: 100%|██████████| 90/90 [01:11<00:00,  1.26it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 24, Loss: 0.0339, Accuracy: 0.9933\n",
      "Test accuracy: 0.5498\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 25/50: 100%|██████████| 90/90 [01:11<00:00,  1.26it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 25, Loss: 0.1114, Accuracy: 0.9705\n",
      "Test accuracy: 0.5652\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 26/50: 100%|██████████| 90/90 [01:11<00:00,  1.27it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 26, Loss: 0.0147, Accuracy: 0.9972\n",
      "Test accuracy: 0.5863\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 27/50: 100%|██████████| 90/90 [01:11<00:00,  1.26it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 27, Loss: 0.0083, Accuracy: 0.9993\n",
      "Test accuracy: 0.5806\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 28/50: 100%|██████████| 90/90 [01:11<00:00,  1.26it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 28, Loss: 0.0066, Accuracy: 0.9993\n",
      "Test accuracy: 0.5849\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 29/50: 100%|██████████| 90/90 [01:11<00:00,  1.26it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 29, Loss: 0.0051, Accuracy: 0.9996\n",
      "Test accuracy: 0.5849\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 30/50: 100%|██████████| 90/90 [01:11<00:00,  1.26it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 30, Loss: 0.0035, Accuracy: 1.0000\n",
      "Test accuracy: 0.5877\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 31/50: 100%|██████████| 90/90 [01:11<00:00,  1.26it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 31, Loss: 0.0031, Accuracy: 1.0000\n",
      "Test accuracy: 0.5891\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 32/50: 100%|██████████| 90/90 [01:11<00:00,  1.26it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 32, Loss: 0.0028, Accuracy: 1.0000\n",
      "Test accuracy: 0.5891\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 33/50: 100%|██████████| 90/90 [01:11<00:00,  1.26it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 33, Loss: 0.0026, Accuracy: 1.0000\n",
      "Test accuracy: 0.5877\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 34/50: 100%|██████████| 90/90 [01:11<00:00,  1.26it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 34, Loss: 0.0024, Accuracy: 1.0000\n",
      "Test accuracy: 0.5877\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 35/50: 100%|██████████| 90/90 [01:11<00:00,  1.26it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 35, Loss: 0.0022, Accuracy: 1.0000\n",
      "Test accuracy: 0.5891\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 36/50: 100%|██████████| 90/90 [01:11<00:00,  1.26it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 36, Loss: 0.0021, Accuracy: 1.0000\n",
      "Test accuracy: 0.5905\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 37/50: 100%|██████████| 90/90 [01:11<00:00,  1.26it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 37, Loss: 0.0019, Accuracy: 1.0000\n",
      "Test accuracy: 0.5905\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 38/50: 100%|██████████| 90/90 [01:11<00:00,  1.26it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 38, Loss: 0.0018, Accuracy: 1.0000\n",
      "Test accuracy: 0.5919\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 39/50: 100%|██████████| 90/90 [01:11<00:00,  1.25it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 39, Loss: 0.0017, Accuracy: 1.0000\n",
      "Test accuracy: 0.5905\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 40/50: 100%|██████████| 90/90 [01:11<00:00,  1.26it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 40, Loss: 0.0016, Accuracy: 1.0000\n",
      "Test accuracy: 0.5905\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 41/50: 100%|██████████| 90/90 [01:11<00:00,  1.26it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 41, Loss: 0.0015, Accuracy: 1.0000\n",
      "Test accuracy: 0.5919\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 42/50: 100%|██████████| 90/90 [01:11<00:00,  1.26it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 42, Loss: 0.0014, Accuracy: 1.0000\n",
      "Test accuracy: 0.5933\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 43/50: 100%|██████████| 90/90 [01:11<00:00,  1.26it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 43, Loss: 0.0013, Accuracy: 1.0000\n",
      "Test accuracy: 0.5947\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 44/50: 100%|██████████| 90/90 [01:11<00:00,  1.25it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 44, Loss: 0.0012, Accuracy: 1.0000\n",
      "Test accuracy: 0.5947\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 45/50: 100%|██████████| 90/90 [01:11<00:00,  1.26it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 45, Loss: 0.0012, Accuracy: 1.0000\n",
      "Test accuracy: 0.5961\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 46/50: 100%|██████████| 90/90 [01:11<00:00,  1.26it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 46, Loss: 0.0011, Accuracy: 1.0000\n",
      "Test accuracy: 0.5947\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 47/50: 100%|██████████| 90/90 [01:11<00:00,  1.26it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 47, Loss: 0.0010, Accuracy: 1.0000\n",
      "Test accuracy: 0.5961\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 48/50: 100%|██████████| 90/90 [01:11<00:00,  1.26it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 48, Loss: 0.0010, Accuracy: 1.0000\n",
      "Test accuracy: 0.5961\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 49/50: 100%|██████████| 90/90 [01:11<00:00,  1.26it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 49, Loss: 0.0009, Accuracy: 1.0000\n",
      "Test accuracy: 0.5961\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 50/50: 100%|██████████| 90/90 [01:11<00:00,  1.26it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 50, Loss: 0.0009, Accuracy: 1.0000\n",
      "Test accuracy: 0.5975\n"
     ]
    }
   ],
   "source": [
    "# --- Training loop for 50 epochs ---\n",
    "num_epochs = 50\n",
    "\n",
    "for epoch in range(num_epochs):\n",
    "    model.train()\n",
    "    total_loss = 0\n",
    "    correct = 0\n",
    "    total = 0\n",
    "\n",
    "    for emg_data, labels in tqdm(train_loader, desc=f'Epoch {epoch+1}/{num_epochs}'):\n",
    "        # emg_data = torch.tensor(emg_data).float().to(device)  # Convert to PyTorch tensor and move to device\n",
    "        # labels = torch.tensor(labels).long().to(device)  # Convert labels to tensor and move to device\n",
    "        emg_data = emg_data.to(device)  # Convert to PyTorch tensor and move to device\n",
    "        labels = labels.to(device)  # Convert labels to tensor and move to device\n",
    "        # Prepare input for ViT by treating EMG data as image-like input\n",
    "        inputs = feature_extractor(emg_data, return_tensors=\"pt\", do_rescale=False)['pixel_values'].to(device)\n",
    "\n",
    "        \n",
    "        # Forward pass\n",
    "        outputs = model(pixel_values=inputs)\n",
    "        loss = criterion(outputs.logits, labels)\n",
    "        \n",
    "        # Backward pass\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        \n",
    "        # Compute accuracy\n",
    "        _, predicted = torch.max(outputs.logits, 1)\n",
    "        total += labels.size(0)\n",
    "        correct += (predicted == labels).sum().item()\n",
    "        total_loss += loss.item()\n",
    "\n",
    "    print(f'Epoch {epoch+1}, Loss: {total_loss/len(train_loader):.4f}, Accuracy: {correct/total:.4f}')\n",
    "\n",
    "    # --- Testing loop ---\n",
    "    model.eval()\n",
    "    correct = 0\n",
    "    total = 0\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for emg_data, labels in test_loader:\n",
    "            emg_data = emg_data.to(device)  # Convert to PyTorch tensor and move to device\n",
    "            labels = labels.to(device)  # Convert labels to tensor and move to device\n",
    "\n",
    "            inputs = feature_extractor(emg_data, return_tensors=\"pt\", do_rescale=False)['pixel_values'].to(device)\n",
    "            outputs = model(pixel_values=inputs)\n",
    "            _, predicted = torch.max(outputs.logits, 1)\n",
    "\n",
    "            total += labels.size(0)\n",
    "            correct += (predicted == labels).sum().item()\n",
    "        test_accuracy = correct / total\n",
    "        print(f'Test accuracy: {test_accuracy:.4f}')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "# Custom dataset for the EMG data\n",
    "class EMGDataset(Dataset):\n",
    "    def __init__(self, file_list, target_length, labels):\n",
    "        self.file_list = file_list\n",
    "        self.target_length = target_length\n",
    "        self.labels = labels\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.file_list)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        file_path = self.file_list[idx]\n",
    "        label = self.labels[idx]\n",
    "        emg_image = load_and_process_file(file_path, self.target_length)\n",
    "        return emg_image, label\n",
    "\n",
    "# Path to the root folder where all .mat files are stored\n",
    "root_folder = 's1_s2_s3_matfiles_5part'  # Update with your folder path\n",
    "\n",
    "# Find all .mat files in the folder\n",
    "all_mat_files = glob.glob(os.path.join(root_folder, '*.mat'))\n",
    "\n",
    "# Collect all corresponding labels\n",
    "labels = [extract_participant_from_filename(mat_file) for mat_file in all_mat_files]\n",
    "\n",
    "# Original unique labels\n",
    "unique_labels = np.unique(labels)\n",
    "\n",
    "# Create a mapping from the original labels to the new range 0-4\n",
    "label_mapping = {original_label: new_label for new_label, original_label in enumerate(unique_labels)}\n",
    "\n",
    "# Convert the original labels to the new range using the mapping\n",
    "converted_labels = np.array([label_mapping[label] for label in labels])\n",
    "\n",
    "labels = converted_labels\n",
    "# Target length for EMG signals (adjust based on your data)\n",
    "target_length = 10240  # Modify this as needed\n",
    "\n",
    "# Split the dataset into train and test sets\n",
    "train_files, test_files, train_labels, test_labels = train_test_split(all_mat_files, labels, test_size=0.2, random_state=42)\n",
    "\n",
    "# Create datasets and dataloaders\n",
    "train_dataset = EMGDataset(train_files, target_length, train_labels)\n",
    "test_dataset = EMGDataset(test_files, target_length, test_labels)\n",
    "\n",
    "train_loader = DataLoader(train_dataset, batch_size=32, shuffle=True)\n",
    "test_loader = DataLoader(test_dataset, batch_size=32, shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of ViTForImageClassification were not initialized from the model checkpoint at google/vit-base-patch16-224-in21k and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    }
   ],
   "source": [
    "# Load a pre-trained ViT model from Hugging Face\n",
    "feature_extractor = ViTFeatureExtractor.from_pretrained('google/vit-base-patch16-224-in21k')\n",
    "model = ViTForImageClassification.from_pretrained('google/vit-base-patch16-224-in21k', num_labels=5)  # Adjust num_labels as needed\n",
    "\n",
    "# Move model to GPU if available\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "model.to(device)\n",
    "\n",
    "# Define optimizer and loss function\n",
    "optimizer = torch.optim.AdamW(model.parameters(), lr=1e-4)\n",
    "criterion = torch.nn.CrossEntropyLoss()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 1/20: 100%|██████████| 45/45 [00:36<00:00,  1.25it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1, Loss: 1.4741, Accuracy: 0.3455\n",
      "Test accuracy: 0.4566\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 2/20: 100%|██████████| 45/45 [00:35<00:00,  1.27it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2, Loss: 1.1747, Accuracy: 0.5407\n",
      "Test accuracy: 0.5770\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 3/20: 100%|██████████| 45/45 [00:35<00:00,  1.27it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 3, Loss: 0.8848, Accuracy: 0.6713\n",
      "Test accuracy: 0.6751\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 4/20: 100%|██████████| 45/45 [00:35<00:00,  1.27it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 4, Loss: 0.6088, Accuracy: 0.8062\n",
      "Test accuracy: 0.7171\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 5/20: 100%|██████████| 45/45 [00:35<00:00,  1.27it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 5, Loss: 0.4332, Accuracy: 0.8581\n",
      "Test accuracy: 0.6303\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 6/20: 100%|██████████| 45/45 [00:35<00:00,  1.28it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 6, Loss: 0.2952, Accuracy: 0.9094\n",
      "Test accuracy: 0.7423\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 7/20: 100%|██████████| 45/45 [00:35<00:00,  1.28it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 7, Loss: 0.1660, Accuracy: 0.9565\n",
      "Test accuracy: 0.7171\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 8/20: 100%|██████████| 45/45 [00:35<00:00,  1.27it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 8, Loss: 0.1073, Accuracy: 0.9719\n",
      "Test accuracy: 0.7003\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 9/20: 100%|██████████| 45/45 [00:35<00:00,  1.28it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 9, Loss: 0.1327, Accuracy: 0.9621\n",
      "Test accuracy: 0.7283\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 10/20: 100%|██████████| 45/45 [00:35<00:00,  1.27it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 10, Loss: 0.0993, Accuracy: 0.9747\n",
      "Test accuracy: 0.7563\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 11/20: 100%|██████████| 45/45 [00:35<00:00,  1.26it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 11, Loss: 0.0724, Accuracy: 0.9831\n",
      "Test accuracy: 0.6947\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 12/20: 100%|██████████| 45/45 [00:35<00:00,  1.27it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 12, Loss: 0.0463, Accuracy: 0.9902\n",
      "Test accuracy: 0.7115\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 13/20: 100%|██████████| 45/45 [00:35<00:00,  1.27it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 13, Loss: 0.0474, Accuracy: 0.9881\n",
      "Test accuracy: 0.7283\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 14/20: 100%|██████████| 45/45 [00:35<00:00,  1.27it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 14, Loss: 0.0936, Accuracy: 0.9747\n",
      "Test accuracy: 0.7115\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 15/20: 100%|██████████| 45/45 [00:35<00:00,  1.27it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 15, Loss: 0.1236, Accuracy: 0.9621\n",
      "Test accuracy: 0.6499\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 16/20: 100%|██████████| 45/45 [00:35<00:00,  1.26it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 16, Loss: 0.1496, Accuracy: 0.9537\n",
      "Test accuracy: 0.6779\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 17/20: 100%|██████████| 45/45 [00:35<00:00,  1.27it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 17, Loss: 0.0414, Accuracy: 0.9909\n",
      "Test accuracy: 0.7619\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 18/20: 100%|██████████| 45/45 [00:35<00:00,  1.26it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 18, Loss: 0.0188, Accuracy: 0.9965\n",
      "Test accuracy: 0.7759\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 19/20: 100%|██████████| 45/45 [00:35<00:00,  1.26it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 19, Loss: 0.0172, Accuracy: 0.9986\n",
      "Test accuracy: 0.7731\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 20/20: 100%|██████████| 45/45 [00:35<00:00,  1.27it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 20, Loss: 0.0108, Accuracy: 0.9993\n",
      "Test accuracy: 0.7675\n"
     ]
    }
   ],
   "source": [
    "# --- Training loop for 20 epochs ---\n",
    "num_epochs = 20\n",
    "\n",
    "for epoch in range(num_epochs):\n",
    "    model.train()\n",
    "    total_loss = 0\n",
    "    correct = 0\n",
    "    total = 0\n",
    "\n",
    "    for emg_data, labels in tqdm(train_loader, desc=f'Epoch {epoch+1}/{num_epochs}'):\n",
    "        # emg_data = torch.tensor(emg_data).float().to(device)  # Convert to PyTorch tensor and move to device\n",
    "        # labels = torch.tensor(labels).long().to(device)  # Convert labels to tensor and move to device\n",
    "        emg_data = emg_data.to(device)  # Convert to PyTorch tensor and move to device\n",
    "        labels = labels.to(device)  # Convert labels to tensor and move to device\n",
    "        # Prepare input for ViT by treating EMG data as image-like input\n",
    "        inputs = feature_extractor(emg_data, return_tensors=\"pt\", do_rescale=False)['pixel_values'].to(device)\n",
    "\n",
    "        \n",
    "        # Forward pass\n",
    "        outputs = model(pixel_values=inputs)\n",
    "        loss = criterion(outputs.logits, labels)\n",
    "        \n",
    "        # Backward pass\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        \n",
    "        # Compute accuracy\n",
    "        _, predicted = torch.max(outputs.logits, 1)\n",
    "        total += labels.size(0)\n",
    "        correct += (predicted == labels).sum().item()\n",
    "        total_loss += loss.item()\n",
    "\n",
    "    print(f'Epoch {epoch+1}, Loss: {total_loss/len(train_loader):.4f}, Accuracy: {correct/total:.4f}')\n",
    "\n",
    "    # --- Testing loop ---\n",
    "    model.eval()\n",
    "    correct = 0\n",
    "    total = 0\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for emg_data, labels in test_loader:\n",
    "            emg_data = emg_data.to(device)  # Convert to PyTorch tensor and move to device\n",
    "            labels = labels.to(device)  # Convert labels to tensor and move to device\n",
    "\n",
    "            inputs = feature_extractor(emg_data, return_tensors=\"pt\", do_rescale=False)['pixel_values'].to(device)\n",
    "            outputs = model(pixel_values=inputs)\n",
    "            _, predicted = torch.max(outputs.logits, 1)\n",
    "\n",
    "            total += labels.size(0)\n",
    "            correct += (predicted == labels).sum().item()\n",
    "        test_accuracy = correct / total\n",
    "        print(f'Test accuracy: {test_accuracy:.4f}')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_label_from_filename(filepath):\n",
    "    filename = os.path.basename(filepath)\n",
    "    parts = filename.split('_')\n",
    "    for part in parts:\n",
    "        if 'gesture' in part:\n",
    "            return int(part.replace('gesture', ''))\n",
    "    return None\n",
    "\n",
    "def load_and_process_file(filepath, target_length):\n",
    "    mat_data = sio.loadmat(filepath)\n",
    "    data_emg = mat_data['data_emg']\n",
    "    \n",
    "    # Handle NaNs and Infinities\n",
    "    data_emg = np.nan_to_num(data_emg, nan=0.0, posinf=0.0, neginf=0.0)\n",
    "    \n",
    "    # Pad or truncate the data to the target length\n",
    "    if data_emg.shape[0] < target_length:\n",
    "        padded_data = np.pad(data_emg, ((0, target_length - data_emg.shape[0]), (0, 0)), 'constant', constant_values=0)\n",
    "    else:\n",
    "        padded_data = data_emg[:target_length]\n",
    "\n",
    "    # Reshape to 224x224x3 required by ViT (ensure the size is consistent)\n",
    "    padded_data = padded_data.flatten()  # Flatten before reshaping\n",
    "    num_pixels = 3 * 224 * 224 \n",
    "    \n",
    "    # If we don't have enough data, we can pad with zeros; otherwise, truncate\n",
    "    if padded_data.size < num_pixels:\n",
    "        reshaped_data = np.pad(padded_data, (0, num_pixels - padded_data.size), 'constant', constant_values=0)\n",
    "    else:\n",
    "        reshaped_data = padded_data[:num_pixels]\n",
    "    \n",
    "    # Reshape to (224, 224, 3) as required by ViT\n",
    "    reshaped_data = np.reshape(reshaped_data, (3, 224, 224))\n",
    "    \n",
    "    # Normalize data to range [0, 1]\n",
    "    reshaped_data = (reshaped_data - reshaped_data.min()) / (reshaped_data.max() - reshaped_data.min())\n",
    "\n",
    "    return reshaped_data    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/data1/George Pap/grabmyo/ptixiaki/.venv/lib/python3.10/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import scipy.io as sio\n",
    "from sklearn.model_selection import train_test_split\n",
    "import torch\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from transformers import ViTForImageClassification, ViTFeatureExtractor\n",
    "from tqdm import tqdm\n",
    "import glob\n",
    "# Custom dataset for the EMG data\n",
    "class EMGDataset(Dataset):\n",
    "    def __init__(self, file_list, target_length, labels):\n",
    "        self.file_list = file_list\n",
    "        self.target_length = target_length\n",
    "        self.labels = labels\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.file_list)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        file_path = self.file_list[idx]\n",
    "        label = self.labels[idx]\n",
    "        emg_image = load_and_process_file(file_path, self.target_length)\n",
    "        return emg_image, label\n",
    "\n",
    "# Path to the root folder where all .mat files are stored\n",
    "root_folder = 's1_s2_s3_matfiles_5gest'  # Update with your folder path\n",
    "\n",
    "# Find all .mat files in the folder\n",
    "all_mat_files = glob.glob(os.path.join(root_folder, '*.mat'))\n",
    "\n",
    "# Collect all corresponding labels\n",
    "labels = [extract_label_from_filename(mat_file) for mat_file in all_mat_files]\n",
    "\n",
    "# Original unique labels\n",
    "unique_labels = np.unique(labels)\n",
    "\n",
    "# Create a mapping from the original labels to the new range 0-4\n",
    "label_mapping = {original_label: new_label for new_label, original_label in enumerate(unique_labels)}\n",
    "\n",
    "# Convert the original labels to the new range using the mapping\n",
    "converted_labels = np.array([label_mapping[label] for label in labels])\n",
    "\n",
    "labels = converted_labels\n",
    "# Target length for EMG signals (adjust based on your data)\n",
    "target_length = 10240  # Modify this as needed\n",
    "\n",
    "# Split the dataset into train and test sets\n",
    "train_files, test_files, train_labels, test_labels = train_test_split(all_mat_files, labels, test_size=0.2, random_state=42)\n",
    "\n",
    "# Create datasets and dataloaders\n",
    "train_dataset = EMGDataset(train_files, target_length, train_labels)\n",
    "test_dataset = EMGDataset(test_files, target_length, test_labels)\n",
    "\n",
    "train_loader = DataLoader(train_dataset, batch_size=32, shuffle=True)\n",
    "test_loader = DataLoader(test_dataset, batch_size=32, shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/data1/George Pap/grabmyo/ptixiaki/.venv/lib/python3.10/site-packages/transformers/models/vit/feature_extraction_vit.py:28: FutureWarning: The class ViTFeatureExtractor is deprecated and will be removed in version 5 of Transformers. Please use ViTImageProcessor instead.\n",
      "  warnings.warn(\n",
      "Some weights of ViTForImageClassification were not initialized from the model checkpoint at google/vit-base-patch16-224-in21k and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    }
   ],
   "source": [
    "# Load a pre-trained ViT model from Hugging Face\n",
    "feature_extractor = ViTFeatureExtractor.from_pretrained('google/vit-base-patch16-224-in21k')\n",
    "model = ViTForImageClassification.from_pretrained('google/vit-base-patch16-224-in21k', num_labels=5)  # Adjust num_labels as needed\n",
    "\n",
    "# Move model to GPU if available\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "model.to(device)\n",
    "\n",
    "# Define optimizer and loss function\n",
    "optimizer = torch.optim.AdamW(model.parameters(), lr=1e-4)\n",
    "criterion = torch.nn.CrossEntropyLoss()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 1/20: 100%|██████████| 113/113 [03:05<00:00,  1.64s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1, Loss: 1.0156, Accuracy: 0.5933\n",
      "Test accuracy: 0.6951\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 2/20: 100%|██████████| 113/113 [01:29<00:00,  1.27it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2, Loss: 0.6677, Accuracy: 0.7506\n",
      "Test accuracy: 0.7816\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 3/20: 100%|██████████| 113/113 [01:28<00:00,  1.27it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 3, Loss: 0.4857, Accuracy: 0.8227\n",
      "Test accuracy: 0.7627\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 4/20: 100%|██████████| 113/113 [01:29<00:00,  1.27it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 4, Loss: 0.3735, Accuracy: 0.8713\n",
      "Test accuracy: 0.8104\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 5/20: 100%|██████████| 113/113 [01:29<00:00,  1.27it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 5, Loss: 0.2388, Accuracy: 0.9223\n",
      "Test accuracy: 0.7938\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 6/20: 100%|██████████| 113/113 [01:28<00:00,  1.27it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 6, Loss: 0.1578, Accuracy: 0.9503\n",
      "Test accuracy: 0.7993\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 7/20: 100%|██████████| 113/113 [01:29<00:00,  1.27it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 7, Loss: 0.1318, Accuracy: 0.9603\n",
      "Test accuracy: 0.7860\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 8/20: 100%|██████████| 113/113 [01:28<00:00,  1.27it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 8, Loss: 0.0938, Accuracy: 0.9734\n",
      "Test accuracy: 0.8226\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 9/20: 100%|██████████| 113/113 [01:29<00:00,  1.27it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 9, Loss: 0.0645, Accuracy: 0.9803\n",
      "Test accuracy: 0.7672\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 10/20: 100%|██████████| 113/113 [01:28<00:00,  1.27it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 10, Loss: 0.0746, Accuracy: 0.9761\n",
      "Test accuracy: 0.7960\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 11/20: 100%|██████████| 113/113 [01:29<00:00,  1.26it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 11, Loss: 0.0330, Accuracy: 0.9917\n",
      "Test accuracy: 0.8149\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 12/20: 100%|██████████| 113/113 [01:28<00:00,  1.27it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 12, Loss: 0.0445, Accuracy: 0.9889\n",
      "Test accuracy: 0.8104\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 13/20: 100%|██████████| 113/113 [01:29<00:00,  1.27it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 13, Loss: 0.0661, Accuracy: 0.9792\n",
      "Test accuracy: 0.8115\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 14/20: 100%|██████████| 113/113 [01:28<00:00,  1.27it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 14, Loss: 0.0471, Accuracy: 0.9850\n",
      "Test accuracy: 0.8259\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 15/20: 100%|██████████| 113/113 [01:29<00:00,  1.27it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 15, Loss: 0.0220, Accuracy: 0.9945\n",
      "Test accuracy: 0.8082\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 16/20: 100%|██████████| 113/113 [01:28<00:00,  1.27it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 16, Loss: 0.0149, Accuracy: 0.9969\n",
      "Test accuracy: 0.8193\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 17/20: 100%|██████████| 113/113 [01:29<00:00,  1.27it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 17, Loss: 0.0469, Accuracy: 0.9859\n",
      "Test accuracy: 0.7971\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 18/20: 100%|██████████| 113/113 [01:29<00:00,  1.27it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 18, Loss: 0.0401, Accuracy: 0.9870\n",
      "Test accuracy: 0.7716\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 19/20: 100%|██████████| 113/113 [01:29<00:00,  1.27it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 19, Loss: 0.0242, Accuracy: 0.9931\n",
      "Test accuracy: 0.8049\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 20/20: 100%|██████████| 113/113 [01:29<00:00,  1.27it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 20, Loss: 0.0091, Accuracy: 0.9978\n",
      "Test accuracy: 0.8060\n"
     ]
    }
   ],
   "source": [
    "# --- Training loop for 20 epochs ---\n",
    "num_epochs = 20\n",
    "\n",
    "for epoch in range(num_epochs):\n",
    "    model.train()\n",
    "    total_loss = 0\n",
    "    correct = 0\n",
    "    total = 0\n",
    "\n",
    "    for emg_data, labels in tqdm(train_loader, desc=f'Epoch {epoch+1}/{num_epochs}'):\n",
    "        # emg_data = torch.tensor(emg_data).float().to(device)  # Convert to PyTorch tensor and move to device\n",
    "        # labels = torch.tensor(labels).long().to(device)  # Convert labels to tensor and move to device\n",
    "        emg_data = emg_data.to(device)  # Convert to PyTorch tensor and move to device\n",
    "        labels = labels.to(device)  # Convert labels to tensor and move to device\n",
    "        # Prepare input for ViT by treating EMG data as image-like input\n",
    "        inputs = feature_extractor(emg_data, return_tensors=\"pt\", do_rescale=False)['pixel_values'].to(device)\n",
    "\n",
    "        \n",
    "        # Forward pass\n",
    "        outputs = model(pixel_values=inputs)\n",
    "        loss = criterion(outputs.logits, labels)\n",
    "        \n",
    "        # Backward pass\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        \n",
    "        # Compute accuracy\n",
    "        _, predicted = torch.max(outputs.logits, 1)\n",
    "        total += labels.size(0)\n",
    "        correct += (predicted == labels).sum().item()\n",
    "        total_loss += loss.item()\n",
    "\n",
    "    print(f'Epoch {epoch+1}, Loss: {total_loss/len(train_loader):.4f}, Accuracy: {correct/total:.4f}')\n",
    "\n",
    "    # --- Testing loop ---\n",
    "    model.eval()\n",
    "    correct = 0\n",
    "    total = 0\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for emg_data, labels in test_loader:\n",
    "            emg_data = emg_data.to(device)  # Convert to PyTorch tensor and move to device\n",
    "            labels = labels.to(device)  # Convert labels to tensor and move to device\n",
    "\n",
    "            inputs = feature_extractor(emg_data, return_tensors=\"pt\", do_rescale=False)['pixel_values'].to(device)\n",
    "            outputs = model(pixel_values=inputs)\n",
    "            _, predicted = torch.max(outputs.logits, 1)\n",
    "\n",
    "            total += labels.size(0)\n",
    "            correct += (predicted == labels).sum().item()\n",
    "        test_accuracy = correct / total\n",
    "        print(f'Test accuracy: {test_accuracy:.4f}')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import scipy.io as sio\n",
    "from sklearn.model_selection import train_test_split\n",
    "import torch\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from transformers import ViTForImageClassification, ViTFeatureExtractor\n",
    "from tqdm import tqdm\n",
    "import glob\n",
    "# Custom dataset for the EMG data\n",
    "class EMGDataset(Dataset):\n",
    "    def __init__(self, file_list, target_length, labels):\n",
    "        self.file_list = file_list\n",
    "        self.target_length = target_length\n",
    "        self.labels = labels\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.file_list)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        file_path = self.file_list[idx]\n",
    "        label = self.labels[idx]\n",
    "        emg_image = load_and_process_file(file_path, self.target_length)\n",
    "        return emg_image, label\n",
    "\n",
    "# Path to the root folder where all .mat files are stored\n",
    "root_folder = 's1_s2_s3_matfiles_10gest'  # Update with your folder path\n",
    "\n",
    "# Find all .mat files in the folder\n",
    "all_mat_files = glob.glob(os.path.join(root_folder, '*.mat'))\n",
    "\n",
    "# Collect all corresponding labels\n",
    "labels = [extract_label_from_filename(mat_file) for mat_file in all_mat_files]\n",
    "\n",
    "# Original unique labels\n",
    "unique_labels = np.unique(labels)\n",
    "\n",
    "# Create a mapping from the original labels to the new range 0-4\n",
    "label_mapping = {original_label: new_label for new_label, original_label in enumerate(unique_labels)}\n",
    "\n",
    "# Convert the original labels to the new range using the mapping\n",
    "converted_labels = np.array([label_mapping[label] for label in labels])\n",
    "\n",
    "labels = converted_labels\n",
    "# Target length for EMG signals (adjust based on your data)\n",
    "target_length = 10240  # Modify this as needed\n",
    "\n",
    "# Split the dataset into train and test sets\n",
    "train_files, test_files, train_labels, test_labels = train_test_split(all_mat_files, labels, test_size=0.2, random_state=42)\n",
    "\n",
    "# Create datasets and dataloaders\n",
    "train_dataset = EMGDataset(train_files, target_length, train_labels)\n",
    "test_dataset = EMGDataset(test_files, target_length, test_labels)\n",
    "\n",
    "train_loader = DataLoader(train_dataset, batch_size=32, shuffle=True)\n",
    "test_loader = DataLoader(test_dataset, batch_size=32, shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/data1/George Pap/grabmyo/ptixiaki/.venv/lib/python3.10/site-packages/transformers/models/vit/feature_extraction_vit.py:28: FutureWarning: The class ViTFeatureExtractor is deprecated and will be removed in version 5 of Transformers. Please use ViTImageProcessor instead.\n",
      "  warnings.warn(\n",
      "Some weights of ViTForImageClassification were not initialized from the model checkpoint at google/vit-base-patch16-224-in21k and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    }
   ],
   "source": [
    "# Load a pre-trained ViT model from Hugging Face\n",
    "feature_extractor = ViTFeatureExtractor.from_pretrained('google/vit-base-patch16-224-in21k')\n",
    "model = ViTForImageClassification.from_pretrained('google/vit-base-patch16-224-in21k', num_labels=10)  # Adjust num_labels as needed\n",
    "\n",
    "# Move model to GPU if available\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "model.to(device)\n",
    "\n",
    "# Define optimizer and loss function\n",
    "optimizer = torch.optim.AdamW(model.parameters(), lr=1e-4)\n",
    "criterion = torch.nn.CrossEntropyLoss()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 1/20: 100%|██████████| 226/226 [06:29<00:00,  1.72s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1, Loss: 1.6487, Accuracy: 0.4242\n",
      "Test accuracy: 0.5774\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 2/20: 100%|██████████| 226/226 [02:59<00:00,  1.26it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2, Loss: 1.1021, Accuracy: 0.6264\n",
      "Test accuracy: 0.6051\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 3/20: 100%|██████████| 226/226 [02:59<00:00,  1.26it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 3, Loss: 0.8969, Accuracy: 0.6896\n",
      "Test accuracy: 0.6794\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 4/20: 100%|██████████| 226/226 [02:59<00:00,  1.26it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 4, Loss: 0.6698, Accuracy: 0.7712\n",
      "Test accuracy: 0.6589\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 5/20: 100%|██████████| 226/226 [02:58<00:00,  1.26it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 5, Loss: 0.5011, Accuracy: 0.8303\n",
      "Test accuracy: 0.6744\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 6/20: 100%|██████████| 226/226 [02:58<00:00,  1.27it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 6, Loss: 0.3302, Accuracy: 0.8935\n",
      "Test accuracy: 0.6384\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 7/20:  92%|█████████▏| 208/226 [02:45<00:14,  1.26it/s]\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[5], line 10\u001b[0m\n\u001b[1;32m      7\u001b[0m correct \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m0\u001b[39m\n\u001b[1;32m      8\u001b[0m total \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m0\u001b[39m\n\u001b[0;32m---> 10\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m emg_data, labels \u001b[38;5;129;01min\u001b[39;00m tqdm(train_loader, desc\u001b[38;5;241m=\u001b[39m\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mEpoch \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mepoch\u001b[38;5;241m+\u001b[39m\u001b[38;5;241m1\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m/\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mnum_epochs\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m'\u001b[39m):\n\u001b[1;32m     11\u001b[0m     \u001b[38;5;66;03m# emg_data = torch.tensor(emg_data).float().to(device)  # Convert to PyTorch tensor and move to device\u001b[39;00m\n\u001b[1;32m     12\u001b[0m     \u001b[38;5;66;03m# labels = torch.tensor(labels).long().to(device)  # Convert labels to tensor and move to device\u001b[39;00m\n\u001b[1;32m     13\u001b[0m     emg_data \u001b[38;5;241m=\u001b[39m emg_data\u001b[38;5;241m.\u001b[39mto(device)  \u001b[38;5;66;03m# Convert to PyTorch tensor and move to device\u001b[39;00m\n\u001b[1;32m     14\u001b[0m     labels \u001b[38;5;241m=\u001b[39m labels\u001b[38;5;241m.\u001b[39mto(device)  \u001b[38;5;66;03m# Convert labels to tensor and move to device\u001b[39;00m\n",
      "File \u001b[0;32m/data1/George Pap/grabmyo/ptixiaki/.venv/lib/python3.10/site-packages/tqdm/std.py:1181\u001b[0m, in \u001b[0;36mtqdm.__iter__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1178\u001b[0m time \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_time\n\u001b[1;32m   1180\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m-> 1181\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m obj \u001b[38;5;129;01min\u001b[39;00m iterable:\n\u001b[1;32m   1182\u001b[0m         \u001b[38;5;28;01myield\u001b[39;00m obj\n\u001b[1;32m   1183\u001b[0m         \u001b[38;5;66;03m# Update and possibly print the progressbar.\u001b[39;00m\n\u001b[1;32m   1184\u001b[0m         \u001b[38;5;66;03m# Note: does not call self.update(1) for speed optimisation.\u001b[39;00m\n",
      "File \u001b[0;32m/data1/George Pap/grabmyo/ptixiaki/.venv/lib/python3.10/site-packages/torch/utils/data/dataloader.py:630\u001b[0m, in \u001b[0;36m_BaseDataLoaderIter.__next__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    627\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_sampler_iter \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m    628\u001b[0m     \u001b[38;5;66;03m# TODO(https://github.com/pytorch/pytorch/issues/76750)\u001b[39;00m\n\u001b[1;32m    629\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_reset()  \u001b[38;5;66;03m# type: ignore[call-arg]\u001b[39;00m\n\u001b[0;32m--> 630\u001b[0m data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_next_data\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    631\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_num_yielded \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m\n\u001b[1;32m    632\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_dataset_kind \u001b[38;5;241m==\u001b[39m _DatasetKind\u001b[38;5;241m.\u001b[39mIterable \u001b[38;5;129;01mand\u001b[39;00m \\\n\u001b[1;32m    633\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_IterableDataset_len_called \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m \\\n\u001b[1;32m    634\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_num_yielded \u001b[38;5;241m>\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_IterableDataset_len_called:\n",
      "File \u001b[0;32m/data1/George Pap/grabmyo/ptixiaki/.venv/lib/python3.10/site-packages/torch/utils/data/dataloader.py:673\u001b[0m, in \u001b[0;36m_SingleProcessDataLoaderIter._next_data\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    671\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_next_data\u001b[39m(\u001b[38;5;28mself\u001b[39m):\n\u001b[1;32m    672\u001b[0m     index \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_next_index()  \u001b[38;5;66;03m# may raise StopIteration\u001b[39;00m\n\u001b[0;32m--> 673\u001b[0m     data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_dataset_fetcher\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfetch\u001b[49m\u001b[43m(\u001b[49m\u001b[43mindex\u001b[49m\u001b[43m)\u001b[49m  \u001b[38;5;66;03m# may raise StopIteration\u001b[39;00m\n\u001b[1;32m    674\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_pin_memory:\n\u001b[1;32m    675\u001b[0m         data \u001b[38;5;241m=\u001b[39m _utils\u001b[38;5;241m.\u001b[39mpin_memory\u001b[38;5;241m.\u001b[39mpin_memory(data, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_pin_memory_device)\n",
      "File \u001b[0;32m/data1/George Pap/grabmyo/ptixiaki/.venv/lib/python3.10/site-packages/torch/utils/data/_utils/fetch.py:52\u001b[0m, in \u001b[0;36m_MapDatasetFetcher.fetch\u001b[0;34m(self, possibly_batched_index)\u001b[0m\n\u001b[1;32m     50\u001b[0m         data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdataset\u001b[38;5;241m.\u001b[39m__getitems__(possibly_batched_index)\n\u001b[1;32m     51\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m---> 52\u001b[0m         data \u001b[38;5;241m=\u001b[39m [\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdataset[idx] \u001b[38;5;28;01mfor\u001b[39;00m idx \u001b[38;5;129;01min\u001b[39;00m possibly_batched_index]\n\u001b[1;32m     53\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m     54\u001b[0m     data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdataset[possibly_batched_index]\n",
      "File \u001b[0;32m/data1/George Pap/grabmyo/ptixiaki/.venv/lib/python3.10/site-packages/torch/utils/data/_utils/fetch.py:52\u001b[0m, in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m     50\u001b[0m         data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdataset\u001b[38;5;241m.\u001b[39m__getitems__(possibly_batched_index)\n\u001b[1;32m     51\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m---> 52\u001b[0m         data \u001b[38;5;241m=\u001b[39m [\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdataset\u001b[49m\u001b[43m[\u001b[49m\u001b[43midx\u001b[49m\u001b[43m]\u001b[49m \u001b[38;5;28;01mfor\u001b[39;00m idx \u001b[38;5;129;01min\u001b[39;00m possibly_batched_index]\n\u001b[1;32m     53\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m     54\u001b[0m     data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdataset[possibly_batched_index]\n",
      "Cell \u001b[0;32mIn[3], line 23\u001b[0m, in \u001b[0;36mEMGDataset.__getitem__\u001b[0;34m(self, idx)\u001b[0m\n\u001b[1;32m     21\u001b[0m file_path \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mfile_list[idx]\n\u001b[1;32m     22\u001b[0m label \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mlabels[idx]\n\u001b[0;32m---> 23\u001b[0m emg_image \u001b[38;5;241m=\u001b[39m \u001b[43mload_and_process_file\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfile_path\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtarget_length\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     24\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m emg_image, label\n",
      "Cell \u001b[0;32mIn[2], line 10\u001b[0m, in \u001b[0;36mload_and_process_file\u001b[0;34m(filepath, target_length)\u001b[0m\n\u001b[1;32m      9\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mload_and_process_file\u001b[39m(filepath, target_length):\n\u001b[0;32m---> 10\u001b[0m     mat_data \u001b[38;5;241m=\u001b[39m \u001b[43msio\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mloadmat\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfilepath\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     11\u001b[0m     data_emg \u001b[38;5;241m=\u001b[39m mat_data[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mdata_emg\u001b[39m\u001b[38;5;124m'\u001b[39m]\n\u001b[1;32m     13\u001b[0m     \u001b[38;5;66;03m# Handle NaNs and Infinities\u001b[39;00m\n",
      "File \u001b[0;32m/data1/George Pap/grabmyo/ptixiaki/.venv/lib/python3.10/site-packages/scipy/io/matlab/_mio.py:227\u001b[0m, in \u001b[0;36mloadmat\u001b[0;34m(file_name, mdict, appendmat, **kwargs)\u001b[0m\n\u001b[1;32m    225\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m _open_file_context(file_name, appendmat) \u001b[38;5;28;01mas\u001b[39;00m f:\n\u001b[1;32m    226\u001b[0m     MR, _ \u001b[38;5;241m=\u001b[39m mat_reader_factory(f, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m--> 227\u001b[0m     matfile_dict \u001b[38;5;241m=\u001b[39m \u001b[43mMR\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget_variables\u001b[49m\u001b[43m(\u001b[49m\u001b[43mvariable_names\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    229\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m mdict \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m    230\u001b[0m     mdict\u001b[38;5;241m.\u001b[39mupdate(matfile_dict)\n",
      "File \u001b[0;32m/data1/George Pap/grabmyo/ptixiaki/.venv/lib/python3.10/site-packages/scipy/io/matlab/_mio5.py:333\u001b[0m, in \u001b[0;36mMatFile5Reader.get_variables\u001b[0;34m(self, variable_names)\u001b[0m\n\u001b[1;32m    331\u001b[0m     \u001b[38;5;28;01mcontinue\u001b[39;00m\n\u001b[1;32m    332\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 333\u001b[0m     res \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mread_var_array\u001b[49m\u001b[43m(\u001b[49m\u001b[43mhdr\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mprocess\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    334\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m MatReadError \u001b[38;5;28;01mas\u001b[39;00m err:\n\u001b[1;32m    335\u001b[0m     warnings\u001b[38;5;241m.\u001b[39mwarn(\n\u001b[1;32m    336\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mUnreadable variable \u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mname\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m, because \u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00merr\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m'\u001b[39m,\n\u001b[1;32m    337\u001b[0m         \u001b[38;5;167;01mWarning\u001b[39;00m, stacklevel\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m2\u001b[39m)\n",
      "File \u001b[0;32m/data1/George Pap/grabmyo/ptixiaki/.venv/lib/python3.10/site-packages/scipy/io/matlab/_mio5.py:291\u001b[0m, in \u001b[0;36mMatFile5Reader.read_var_array\u001b[0;34m(self, header, process)\u001b[0m\n\u001b[1;32m    274\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mread_var_array\u001b[39m(\u001b[38;5;28mself\u001b[39m, header, process\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m):\n\u001b[1;32m    275\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m''' Read array, given `header`\u001b[39;00m\n\u001b[1;32m    276\u001b[0m \n\u001b[1;32m    277\u001b[0m \u001b[38;5;124;03m    Parameters\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    289\u001b[0m \u001b[38;5;124;03m       `process`.\u001b[39;00m\n\u001b[1;32m    290\u001b[0m \u001b[38;5;124;03m    '''\u001b[39;00m\n\u001b[0;32m--> 291\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_matrix_reader\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43marray_from_header\u001b[49m\u001b[43m(\u001b[49m\u001b[43mheader\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mprocess\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# --- Training loop for 20 epochs ---\n",
    "num_epochs = 20\n",
    "\n",
    "for epoch in range(num_epochs):\n",
    "    model.train()\n",
    "    total_loss = 0\n",
    "    correct = 0\n",
    "    total = 0\n",
    "\n",
    "    for emg_data, labels in tqdm(train_loader, desc=f'Epoch {epoch+1}/{num_epochs}'):\n",
    "        # emg_data = torch.tensor(emg_data).float().to(device)  # Convert to PyTorch tensor and move to device\n",
    "        # labels = torch.tensor(labels).long().to(device)  # Convert labels to tensor and move to device\n",
    "        emg_data = emg_data.to(device)  # Convert to PyTorch tensor and move to device\n",
    "        labels = labels.to(device)  # Convert labels to tensor and move to device\n",
    "        # Prepare input for ViT by treating EMG data as image-like input\n",
    "        inputs = feature_extractor(emg_data, return_tensors=\"pt\", do_rescale=False)['pixel_values'].to(device)\n",
    "\n",
    "        \n",
    "        # Forward pass\n",
    "        outputs = model(pixel_values=inputs)\n",
    "        loss = criterion(outputs.logits, labels)\n",
    "        \n",
    "        # Backward pass\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        \n",
    "        # Compute accuracy\n",
    "        _, predicted = torch.max(outputs.logits, 1)\n",
    "        total += labels.size(0)\n",
    "        correct += (predicted == labels).sum().item()\n",
    "        total_loss += loss.item()\n",
    "\n",
    "    print(f'Epoch {epoch+1}, Loss: {total_loss/len(train_loader):.4f}, Accuracy: {correct/total:.4f}')\n",
    "\n",
    "    # --- Testing loop ---\n",
    "    model.eval()\n",
    "    correct = 0\n",
    "    total = 0\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for emg_data, labels in test_loader:\n",
    "            emg_data = emg_data.to(device)  # Convert to PyTorch tensor and move to device\n",
    "            labels = labels.to(device)  # Convert labels to tensor and move to device\n",
    "\n",
    "            inputs = feature_extractor(emg_data, return_tensors=\"pt\", do_rescale=False)['pixel_values'].to(device)\n",
    "            outputs = model(pixel_values=inputs)\n",
    "            _, predicted = torch.max(outputs.logits, 1)\n",
    "\n",
    "            total += labels.size(0)\n",
    "            correct += (predicted == labels).sum().item()\n",
    "        test_accuracy = correct / total\n",
    "        print(f'Test accuracy: {test_accuracy:.4f}')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import scipy.io as sio\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score\n",
    "import numpy as np\n",
    "import glob\n",
    "\n",
    "# Function to extract gesture label from the filename\n",
    "def extract_label_from_filename(filepath):\n",
    "    filename = os.path.basename(filepath)\n",
    "    parts = filename.split('_')\n",
    "    for part in parts:\n",
    "        if 'gesture' in part:\n",
    "            return int(part.replace('gesture', ''))\n",
    "    return None\n",
    "\n",
    "# Function to load and process a single .mat file\n",
    "def load_and_process_file(filepath, target_length):\n",
    "    mat_data = sio.loadmat(filepath)\n",
    "    data_emg = mat_data['data_emg']\n",
    "    \n",
    "    # Handle NaNs and Infinities\n",
    "    data_emg = np.nan_to_num(data_emg, nan=0.0, posinf=0.0, neginf=0.0)\n",
    "    \n",
    "    # Pad or truncate the data to the target length\n",
    "    if data_emg.shape[0] < target_length:\n",
    "        padded_data = np.pad(data_emg, ((0, target_length - data_emg.shape[0]), (0, 0)), 'constant', constant_values=0)\n",
    "    else:\n",
    "        padded_data = data_emg[:target_length]\n",
    "    \n",
    "    # Flatten the data for SVM input\n",
    "    return padded_data.flatten()\n",
    "\n",
    "# Process a list of files and return processed data and labels\n",
    "def process_files(file_list, target_length):\n",
    "    X = []\n",
    "    y = []\n",
    "    \n",
    "    for filepath in file_list:\n",
    "        X.append(load_and_process_file(filepath, target_length))\n",
    "        y.append(extract_label_from_filename(filepath))\n",
    "    \n",
    "    return np.array(X), np.array(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape of X_train: (5701, 327680)\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# Path to the root folder where all .mat files are stored\n",
    "root_folder = 's1_s2_s3_matfiles_20part'  # Update with your folder path\n",
    "\n",
    "# Find all .mat files in the folder\n",
    "all_mat_files = glob.glob(os.path.join(root_folder, '*.mat'))\n",
    "\n",
    "# Collect all corresponding labels\n",
    "all_labels = [extract_label_from_filename(mat_file) for mat_file in all_mat_files]\n",
    "\n",
    "# Target length for EMG signals (adjust based on your data)\n",
    "target_length = 10240  # Modify this as needed\n",
    "\n",
    "# Split the dataset into train and test sets\n",
    "train_files, test_files, train_labels, test_labels = train_test_split(all_mat_files, all_labels, test_size=0.2, random_state=42)\n",
    "\n",
    "# Process training and test data\n",
    "X_train, y_train = process_files(train_files, target_length)\n",
    "X_test, y_test = process_files(test_files, target_length)\n",
    "print(f\"Shape of X_train: {X_train.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of components to retain 95% of variance: 1\n",
      "Explained variance by each component: [0.02734777 0.02461403 0.00818816 0.0069905  0.00584958 0.00445974\n",
      " 0.00403911 0.00369412 0.00349787 0.00316976 0.00300401 0.00289899\n",
      " 0.00279481 0.00275903 0.00264407 0.00261821 0.00259447 0.00257349\n",
      " 0.00248961 0.00239943 0.0023721  0.00232195 0.00227801 0.00223757\n",
      " 0.0022159  0.00220089 0.00212229 0.00206722 0.00201354 0.00198255\n",
      " 0.00194987 0.00192753 0.00191069 0.00189586 0.00187392 0.00184805\n",
      " 0.00183598 0.00181051 0.00178506 0.00175982 0.0017539  0.00172137\n",
      " 0.00170902 0.00169332 0.00167088 0.00165842 0.00165174 0.0016362\n",
      " 0.00163023 0.00160764 0.00159447 0.00155964 0.00155086 0.00152713\n",
      " 0.00146956 0.00145834 0.00141764 0.00141322 0.00140813 0.00138163\n",
      " 0.00136974 0.00136623 0.00134497 0.00133781 0.00131482 0.00130781\n",
      " 0.00129883 0.00128668 0.00127945 0.00126588 0.00125526 0.00123351\n",
      " 0.00122743 0.00121431 0.00120742 0.00119956 0.00119493 0.00118896\n",
      " 0.0011854  0.00117166 0.00116383 0.00115497 0.00114766 0.00114137\n",
      " 0.00112922 0.00112553 0.00111753 0.00111065 0.00110787 0.00109368\n",
      " 0.00109204 0.00108524 0.00108344 0.0010761  0.00107166 0.00106689\n",
      " 0.00105693 0.00105255 0.001048   0.00104655 0.00103966 0.00103683\n",
      " 0.00103233 0.00103065 0.00102595 0.00102042 0.00101879 0.00101187\n",
      " 0.00100623 0.00100556 0.00099991 0.00099757 0.0009967  0.00098891\n",
      " 0.0009854  0.00098423 0.00097592 0.0009745  0.0009714  0.00096899\n",
      " 0.00096472 0.00096003 0.00095313 0.00094789 0.00094547 0.00094383\n",
      " 0.00093735 0.000934   0.00093266 0.0009226  0.00092148 0.00091818\n",
      " 0.00091208 0.00091    0.00090463 0.00090079 0.00089952 0.00089662\n",
      " 0.00089107 0.00088877 0.00088556 0.00088012 0.0008749  0.0008741\n",
      " 0.00087054 0.00086425 0.00086241 0.00085923 0.00085852 0.0008529\n",
      " 0.00085074 0.00084969 0.00084564 0.00084297 0.00083794 0.00083652\n",
      " 0.00083081 0.00082667 0.00082529 0.00082357 0.00081757 0.00081614\n",
      " 0.00081334 0.00081227 0.00081031 0.00080737 0.00080409 0.00080281\n",
      " 0.00080076 0.0007988  0.00079682 0.00079418 0.00079143 0.00078906\n",
      " 0.00078788 0.00078545 0.00078259 0.00078027 0.00077713 0.000776\n",
      " 0.00077046 0.00076854 0.00076761 0.00076312 0.00076124 0.00075814\n",
      " 0.00075742 0.00075208 0.00074989 0.00074846 0.00074672 0.00074616\n",
      " 0.0007428  0.00074167 0.00073863 0.00073657 0.00073456 0.00073235\n",
      " 0.00073175 0.0007308  0.00073002 0.00072842 0.00072678 0.00072428\n",
      " 0.00072082 0.00071928 0.0007183  0.00071564 0.00071296 0.00071108\n",
      " 0.00070882 0.00070826 0.00070658 0.00070415 0.00070195 0.00070021\n",
      " 0.00069791 0.00069709 0.00069701 0.00069499 0.00069059 0.0006883\n",
      " 0.00068717 0.00068358 0.00068305 0.0006804  0.00067699 0.0006762\n",
      " 0.00067376 0.00067271 0.00067054 0.00066965 0.00066775 0.00066632\n",
      " 0.00066439 0.00066248 0.00066152 0.00065926 0.00065521 0.00065453\n",
      " 0.00065189 0.00065079 0.00064862 0.0006458  0.00064434 0.0006423\n",
      " 0.00063867 0.00063595 0.00063548 0.00063362 0.00063119 0.00063015\n",
      " 0.00062808 0.00062613 0.00062369 0.00062221 0.00062102 0.00061642\n",
      " 0.00061453 0.00061299 0.00061052 0.00061033 0.00060866 0.00060632\n",
      " 0.00060345 0.00060163 0.00059983 0.00059748 0.00059495 0.00059342\n",
      " 0.00059234 0.00059098 0.00059018 0.00058839 0.00058691 0.00058459\n",
      " 0.00058293 0.0005813  0.00058075 0.00057834 0.00057736 0.00057492\n",
      " 0.00057363 0.00057193 0.00057089 0.00056926 0.00056747 0.00056443\n",
      " 0.00056298 0.00056129 0.00055963 0.00055953 0.00055813 0.00055686\n",
      " 0.0005543  0.00055316 0.0005502  0.00054973 0.00054882 0.00054644\n",
      " 0.00054547 0.00054448 0.00054197 0.00054154 0.00054119 0.00054058\n",
      " 0.00053843 0.00053681 0.00053512 0.00053349 0.00053233 0.00053109\n",
      " 0.0005302  0.0005297  0.00052948 0.00052767 0.00052638 0.0005258\n",
      " 0.00052438 0.00052258 0.0005215  0.0005205  0.00051932 0.00051792\n",
      " 0.00051725 0.00051601 0.00051372 0.00051323 0.00051302 0.00051039\n",
      " 0.00050929 0.00050826 0.00050624 0.00050534 0.00050445 0.00050317\n",
      " 0.00049991 0.00049946 0.00049873 0.00049753 0.00049631 0.00049606\n",
      " 0.00049577 0.00049498 0.00049326 0.00049187 0.00049037 0.00048872\n",
      " 0.00048653 0.0004849  0.00048415 0.00048298 0.00048048 0.00047985\n",
      " 0.00047895 0.0004783  0.00047708 0.0004768  0.00047558 0.00047436\n",
      " 0.000474   0.00047306 0.0004717  0.00046959 0.00046898 0.00046817\n",
      " 0.00046796 0.00046614 0.0004659  0.00046474 0.00046391 0.00046323\n",
      " 0.00046278 0.00046076 0.00045967 0.00045875 0.0004582  0.00045666\n",
      " 0.00045551 0.00045475 0.00045443 0.00045365 0.00045207 0.00045065\n",
      " 0.00044923 0.00044825 0.00044718 0.00044603 0.00044472 0.00044302\n",
      " 0.00044257 0.0004422  0.00044087 0.00044037 0.00043943 0.00043884\n",
      " 0.00043743 0.00043653 0.00043626 0.00043432 0.00043399 0.00043286\n",
      " 0.00043197 0.000431   0.00043089 0.00042998 0.00042859 0.0004277\n",
      " 0.00042728 0.00042658 0.00042613 0.00042564 0.00042515 0.00042403\n",
      " 0.00042374 0.00042235 0.00042176 0.00042013 0.00041976 0.00041766\n",
      " 0.00041719 0.00041612 0.00041606 0.00041462 0.0004143  0.00041379\n",
      " 0.00041351 0.00041162 0.00041059 0.00041049 0.00040968 0.00040928\n",
      " 0.00040813 0.00040782 0.00040748 0.00040653 0.00040525 0.00040496\n",
      " 0.00040359 0.00040307 0.00040242 0.00040175 0.00040111 0.0004004\n",
      " 0.00039969 0.00039926 0.00039868 0.00039729 0.00039642 0.00039555\n",
      " 0.00039539 0.00039513 0.00039354 0.00039339 0.00039307 0.00039191\n",
      " 0.00039186 0.00039079 0.00038962 0.00038908 0.00038831 0.00038785\n",
      " 0.00038776 0.00038711 0.00038628 0.00038574 0.00038535 0.00038485\n",
      " 0.00038414 0.00038379 0.00038238 0.00038213 0.00038178 0.00038118\n",
      " 0.00038066 0.00038005 0.00037928 0.00037899 0.00037825 0.00037743\n",
      " 0.00037702 0.00037662 0.00037594 0.00037479 0.00037428 0.00037419\n",
      " 0.00037382 0.00037325 0.00037266 0.000372   0.00037199 0.0003711\n",
      " 0.00037061 0.00037008 0.00036994 0.00036942 0.00036933 0.0003684\n",
      " 0.0003677  0.00036704 0.00036687 0.00036602 0.00036552 0.00036515\n",
      " 0.00036493 0.00036393 0.00036359 0.0003627  0.00036239 0.0003615\n",
      " 0.00036089 0.00036042 0.00036018 0.00035952 0.0003584  0.00035805\n",
      " 0.0003579  0.00035727 0.00035713 0.00035643 0.00035562 0.00035516\n",
      " 0.0003549  0.00035387 0.00035372 0.00035325 0.00035293 0.0003525\n",
      " 0.00035231 0.00035176 0.00035124 0.0003502  0.00035011 0.00034935\n",
      " 0.00034911 0.00034873 0.0003487  0.00034784 0.00034746 0.00034706\n",
      " 0.00034608 0.00034597 0.00034551 0.00034508 0.00034449 0.00034435\n",
      " 0.00034427 0.00034347 0.00034286 0.0003426  0.00034199 0.00034178\n",
      " 0.00034156 0.00034138 0.00034063 0.00034045 0.00033966 0.0003395\n",
      " 0.00033941 0.00033898 0.00033864 0.000338   0.00033745 0.00033672\n",
      " 0.00033623 0.00033575 0.0003357  0.00033493 0.00033478 0.00033431\n",
      " 0.0003334  0.00033326 0.00033297 0.00033267 0.00033246 0.00033209\n",
      " 0.00033158 0.0003313  0.00033102 0.00033032 0.00032992 0.00032957\n",
      " 0.00032944 0.00032899 0.00032866 0.00032818 0.00032775 0.00032745\n",
      " 0.00032693 0.00032656 0.00032615 0.00032547 0.00032506 0.00032475\n",
      " 0.0003245  0.00032432 0.00032357 0.00032322 0.00032294 0.00032248\n",
      " 0.000322   0.00032168 0.00032116 0.00032094 0.00032089 0.00032004\n",
      " 0.00031985 0.00031939 0.00031871 0.00031843 0.00031811 0.00031776\n",
      " 0.0003177  0.0003171  0.00031687 0.00031673 0.00031603 0.00031594\n",
      " 0.00031556 0.00031499 0.00031468 0.00031425 0.00031396 0.00031364\n",
      " 0.00031346 0.00031275 0.00031256 0.00031237 0.00031178 0.00031129\n",
      " 0.00031112 0.00031075 0.00031068 0.00031013 0.00030964 0.00030951\n",
      " 0.0003092  0.00030892 0.00030837 0.00030761 0.00030737 0.00030694\n",
      " 0.00030667 0.00030626 0.00030607 0.00030557 0.00030538 0.00030493\n",
      " 0.00030422 0.0003041  0.00030392 0.00030337 0.00030297 0.00030245\n",
      " 0.00030227 0.00030169 0.00030105 0.00030086 0.00030044 0.00030013\n",
      " 0.00029995 0.0002995  0.00029913 0.00029869 0.00029836 0.00029803\n",
      " 0.00029776 0.00029745 0.00029675 0.00029615 0.00029608 0.00029598\n",
      " 0.00029556 0.00029501 0.00029443 0.0002942  0.00029337 0.00029291\n",
      " 0.00029254 0.00029229 0.00029182 0.00029151 0.00029147 0.00029106\n",
      " 0.00029062 0.00029022 0.00028968 0.00028947 0.00028908 0.00028884\n",
      " 0.00028805 0.00028788 0.00028755 0.0002873  0.00028686 0.00028647\n",
      " 0.00028634 0.00028582 0.00028546 0.00028513 0.00028495 0.00028421\n",
      " 0.00028412 0.00028334 0.00028278 0.00028269 0.00028227 0.00028206\n",
      " 0.0002819  0.00028106 0.00028064 0.00028057 0.00028024 0.00027997\n",
      " 0.00027922 0.00027895 0.00027854 0.00027838 0.00027789 0.00027776\n",
      " 0.0002774  0.00027723 0.00027664 0.00027645 0.00027593 0.00027574\n",
      " 0.00027519 0.00027499 0.00027456 0.00027423 0.00027402 0.00027372\n",
      " 0.00027333 0.00027298 0.00027259 0.00027232 0.00027203 0.00027182\n",
      " 0.00027144 0.00027071 0.00027052 0.00026985 0.00026953 0.00026941\n",
      " 0.00026915 0.00026888 0.00026845 0.00026796 0.00026773 0.00026768\n",
      " 0.0002672  0.00026716 0.00026649 0.00026585 0.00026568 0.00026549\n",
      " 0.00026524 0.00026512 0.00026487 0.00026453 0.00026394 0.0002638\n",
      " 0.00026329 0.00026313 0.00026256 0.00026227 0.00026176 0.00026157\n",
      " 0.0002613  0.00026117 0.00026075 0.00026043 0.00026012 0.00025974\n",
      " 0.00025955 0.00025897 0.00025855 0.00025837 0.0002581  0.00025767\n",
      " 0.00025744 0.00025727 0.00025687 0.00025669 0.00025659 0.00025635\n",
      " 0.00025621 0.00025581 0.00025548 0.00025523 0.00025508 0.00025489\n",
      " 0.00025465 0.00025419 0.00025393 0.00025361 0.00025349 0.00025329\n",
      " 0.0002526  0.00025206 0.00025196 0.00025174 0.0002517  0.00025125\n",
      " 0.00025094 0.00025053 0.0002504  0.00024999 0.00024965 0.00024946\n",
      " 0.00024929 0.0002491  0.00024856 0.00024826 0.00024815 0.00024767\n",
      " 0.00024746 0.00024711 0.00024696 0.00024675 0.00024647 0.00024616\n",
      " 0.00024603 0.00024556 0.00024551 0.00024534 0.00024509 0.00024457\n",
      " 0.00024407 0.00024393 0.00024356 0.00024318 0.00024292 0.00024275\n",
      " 0.00024227 0.00024193 0.00024189 0.00024175 0.00024118 0.00024102\n",
      " 0.00024081 0.00024053 0.00024043 0.00023995 0.00023963 0.00023932\n",
      " 0.00023894 0.00023882 0.00023824 0.00023823 0.00023783 0.00023779\n",
      " 0.00023748 0.00023716 0.000237   0.00023666 0.00023628 0.00023597\n",
      " 0.00023587 0.00023567 0.00023514 0.00023496 0.00023475 0.00023437\n",
      " 0.00023419 0.00023397 0.00023378 0.00023364 0.00023313 0.00023295\n",
      " 0.00023291 0.00023236 0.00023234 0.00023175 0.00023149 0.00023109\n",
      " 0.00023094 0.00023081 0.00023053 0.00022991 0.00022974 0.00022955\n",
      " 0.00022909 0.00022887 0.00022873 0.00022855 0.0002282  0.00022808\n",
      " 0.00022794 0.00022784 0.00022758 0.00022698 0.00022661 0.00022659\n",
      " 0.00022602 0.00022585 0.00022561 0.00022527 0.00022511 0.00022488\n",
      " 0.00022464 0.00022447 0.00022402 0.00022399 0.00022368 0.00022311\n",
      " 0.00022303 0.00022294 0.00022265 0.00022242 0.00022211 0.00022201\n",
      " 0.00022136 0.00022106 0.00022044 0.0002202  0.00022011 0.00021984\n",
      " 0.00021951 0.00021923 0.00021901 0.00021874 0.00021865 0.00021848\n",
      " 0.00021828 0.00021812 0.00021767 0.00021732 0.00021708 0.00021676\n",
      " 0.0002165  0.00021627 0.00021605 0.00021575 0.00021538 0.00021533\n",
      " 0.00021486 0.00021469 0.00021455 0.00021446 0.00021401 0.00021381\n",
      " 0.00021343 0.00021306 0.00021295 0.0002125  0.00021209 0.00021193\n",
      " 0.00021184 0.00021126 0.00021099 0.00021069 0.00021031 0.00021024\n",
      " 0.00020975 0.00020946 0.00020914 0.00020894 0.00020866 0.00020856\n",
      " 0.00020825 0.000208   0.00020762 0.0002071  0.00020701 0.00020678\n",
      " 0.00020635 0.00020616 0.00020583 0.00020575 0.00020506 0.00020442\n",
      " 0.00020419 0.00020391 0.00020374 0.00020341 0.00020326 0.00020291\n",
      " 0.00020258 0.00020242 0.00020206 0.00020191 0.00020139 0.00020089\n",
      " 0.00020045 0.00020022 0.00019988 0.00019933 0.00019925 0.00019914\n",
      " 0.00019878 0.00019816 0.00019797 0.00019751 0.00019667 0.00019633\n",
      " 0.00019613 0.00019591 0.00019528 0.00019455]\n",
      "Cumulative explained variance: [0.02734777 0.0519618  0.06014996 0.06714046 0.07299004 0.07744978\n",
      " 0.08148889 0.08518301 0.08868088 0.09185065 0.09485466 0.09775365\n",
      " 0.10054846 0.10330749 0.10595155 0.10856976 0.11116423 0.11373773\n",
      " 0.11622734 0.11862676 0.12099886 0.12332082 0.12559883 0.1278364\n",
      " 0.1300523  0.13225318 0.13437547 0.13644269 0.13845623 0.14043878\n",
      " 0.14238865 0.14431618 0.14622687 0.14812273 0.14999665 0.1518447\n",
      " 0.15368068 0.15549119 0.15727625 0.15903607 0.16078997 0.16251134\n",
      " 0.16422035 0.16591368 0.16758456 0.16924298 0.17089471 0.17253091\n",
      " 0.17416114 0.17576878 0.17736324 0.17892288 0.18047374 0.18200087\n",
      " 0.18347043 0.18492877 0.18634641 0.18775963 0.18916777 0.19054939\n",
      " 0.19191914 0.19328537 0.19463034 0.19596814 0.19728296 0.19859077\n",
      " 0.1998896  0.20117628 0.20245574 0.20372161 0.20497687 0.20621039\n",
      " 0.20743782 0.20865213 0.20985955 0.2110591  0.21225403 0.21344299\n",
      " 0.2146284  0.21580006 0.21696389 0.21811885 0.21926651 0.22040788\n",
      " 0.2215371  0.22266264 0.22378017 0.22489082 0.22599869 0.22709238\n",
      " 0.22818442 0.22926965 0.2303531  0.23142919 0.23250085 0.23356774\n",
      " 0.23462467 0.23567723 0.23672522 0.23777178 0.23881143 0.23984827\n",
      " 0.24088059 0.24191124 0.2429372  0.24395761 0.2449764  0.24598827\n",
      " 0.2469945  0.24800006 0.24899997 0.24999754 0.25099424 0.25198315\n",
      " 0.25296855 0.25395278 0.25492871 0.2559032  0.25687461 0.2578436\n",
      " 0.25880832 0.25976834 0.26072147 0.26166936 0.26261483 0.26355866\n",
      " 0.26449602 0.26543002 0.26636267 0.26728527 0.26820675 0.26912493\n",
      " 0.27003701 0.27094701 0.27185163 0.27275243 0.27365195 0.27454856\n",
      " 0.27543963 0.2763284  0.27721396 0.27809409 0.27896898 0.27984309\n",
      " 0.28071363 0.28157787 0.28244028 0.28329951 0.28415803 0.28501094\n",
      " 0.28586167 0.28671137 0.28755701 0.28839998 0.28923791 0.29007444\n",
      " 0.29090524 0.29173191 0.29255721 0.29338077 0.29419835 0.29501449\n",
      " 0.29582783 0.2966401  0.2974504  0.29825777 0.29906186 0.29986467\n",
      " 0.30066543 0.30146423 0.30226105 0.30305523 0.30384666 0.30463571\n",
      " 0.30542359 0.30620904 0.30699163 0.3077719  0.30854903 0.30932503\n",
      " 0.31009549 0.31086403 0.31163164 0.31239475 0.31315599 0.31391413\n",
      " 0.31467156 0.31542363 0.31617352 0.31692199 0.31766871 0.31841487\n",
      " 0.31915767 0.31989934 0.32063797 0.32137454 0.3221091  0.32284145\n",
      " 0.32357319 0.32430399 0.32503402 0.32576243 0.32648921 0.3272135\n",
      " 0.32793432 0.3286536  0.3293719  0.33008755 0.33080051 0.33151159\n",
      " 0.33222041 0.33292868 0.33363526 0.33433941 0.33504136 0.33574156\n",
      " 0.33643948 0.33713657 0.33783357 0.33852856 0.33921916 0.33990745\n",
      " 0.34059462 0.3412782  0.34196125 0.34264165 0.34331864 0.34399484\n",
      " 0.3446686  0.34534131 0.34601185 0.3466815  0.34734926 0.34801557\n",
      " 0.34867997 0.34934244 0.35000396 0.35066322 0.35131843 0.35197296\n",
      " 0.35262485 0.35327563 0.35392425 0.35457005 0.35521439 0.35585668\n",
      " 0.35649535 0.3571313  0.35776678 0.3584004  0.35903159 0.35966174\n",
      " 0.36028982 0.36091595 0.36153964 0.36216185 0.36278287 0.36339929\n",
      " 0.36401382 0.36462681 0.36523732 0.36584765 0.36645631 0.36706262\n",
      " 0.36766607 0.3682677  0.36886754 0.36946502 0.37005997 0.3706534\n",
      " 0.37124574 0.37183672 0.3724269  0.37301529 0.3736022  0.37418679\n",
      " 0.37476973 0.37535102 0.37593177 0.37651011 0.37708747 0.37766239\n",
      " 0.37823602 0.37880794 0.37937883 0.3799481  0.38051557 0.38108\n",
      " 0.38164298 0.38220428 0.3827639  0.38332343 0.38388156 0.38443842\n",
      " 0.38499272 0.38554588 0.38609608 0.38664581 0.38719463 0.38774107\n",
      " 0.38828654 0.38883102 0.38937299 0.38991453 0.39045572 0.3909963\n",
      " 0.39153473 0.39207154 0.39260666 0.39314015 0.39367248 0.39420357\n",
      " 0.39473377 0.39526347 0.39579295 0.39632062 0.396847   0.3973728\n",
      " 0.39789718 0.39841976 0.39894126 0.39946176 0.39998108 0.400499\n",
      " 0.40101625 0.40153226 0.40204598 0.40255921 0.40307223 0.40358262\n",
      " 0.40409191 0.40460017 0.40510641 0.40561174 0.4061162  0.40661937\n",
      " 0.40711928 0.40761874 0.40811747 0.408615   0.40911131 0.40960736\n",
      " 0.41010314 0.41059811 0.41109137 0.41158325 0.41207362 0.41256234\n",
      " 0.41304887 0.41353376 0.41401791 0.4145009  0.41498137 0.41546123\n",
      " 0.41594017 0.41641847 0.41689555 0.41737235 0.41784793 0.41832229\n",
      " 0.4187963  0.41926936 0.41974105 0.42021065 0.42067963 0.4211478\n",
      " 0.42161577 0.4220819  0.4225478  0.42301254 0.42347645 0.42393968\n",
      " 0.42440246 0.42486322 0.42532289 0.42578164 0.42623984 0.4266965\n",
      " 0.427152   0.42760676 0.42806118 0.42851484 0.42896691 0.42941756\n",
      " 0.42986679 0.43031504 0.43076223 0.43120826 0.43165298 0.432096\n",
      " 0.43253857 0.43298078 0.43342165 0.43386202 0.43430145 0.43474029\n",
      " 0.43517771 0.43561425 0.43605051 0.43648483 0.43691882 0.43735168\n",
      " 0.43778365 0.43821465 0.43864553 0.43907552 0.43950411 0.43993181\n",
      " 0.44035909 0.44078567 0.4412118  0.44163745 0.44206259 0.44248662\n",
      " 0.44291037 0.44333272 0.44375448 0.4441746  0.44459437 0.44501202\n",
      " 0.44542921 0.44584533 0.44626139 0.44667601 0.44709031 0.4475041\n",
      " 0.44791761 0.44832923 0.44873982 0.44915031 0.44956    0.44996927\n",
      " 0.4503774  0.45078522 0.45119269 0.45159922 0.45200447 0.45240942\n",
      " 0.45281301 0.45321608 0.45361851 0.45402026 0.45442137 0.45482177\n",
      " 0.45522146 0.45562072 0.4560194  0.45641669 0.45681311 0.45720866\n",
      " 0.45760405 0.45799918 0.45839272 0.4587861  0.45917918 0.45957108\n",
      " 0.45996294 0.46035373 0.46074335 0.46113243 0.46152074 0.46190859\n",
      " 0.46229636 0.46268347 0.46306974 0.46345548 0.46384082 0.46422567\n",
      " 0.46460981 0.4649936  0.46537598 0.46575811 0.46613989 0.46652108\n",
      " 0.46690174 0.46728179 0.46766106 0.46804005 0.4684183  0.46879573\n",
      " 0.46917276 0.46954938 0.46992532 0.47030011 0.47067439 0.47104857\n",
      " 0.47142239 0.47179565 0.47216831 0.47254031 0.4729123  0.4732834\n",
      " 0.473654   0.47402408 0.47439402 0.47476344 0.47513278 0.47550117\n",
      " 0.47586888 0.47623591 0.47660278 0.4769688  0.47733432 0.47769947\n",
      " 0.4780644  0.47842833 0.47879193 0.47915463 0.47951702 0.47987852\n",
      " 0.48023941 0.48059983 0.48096002 0.48131954 0.48167794 0.48203599\n",
      " 0.48239389 0.48275115 0.48310829 0.48346472 0.48382034 0.4841755\n",
      " 0.4845304  0.48488427 0.48523799 0.48559124 0.48594417 0.48629667\n",
      " 0.48664898 0.48700074 0.48735198 0.48770218 0.48805229 0.48840165\n",
      " 0.48875076 0.48909948 0.48944818 0.48979602 0.49014348 0.49049054\n",
      " 0.49083662 0.49118258 0.4915281  0.49187318 0.49221766 0.49256201\n",
      " 0.49290629 0.49324976 0.49359262 0.49393522 0.4942772  0.49461898\n",
      " 0.49496054 0.49530192 0.49564254 0.49598299 0.49632265 0.49666215\n",
      " 0.49700156 0.49734054 0.49767918 0.49801717 0.49835462 0.49869135\n",
      " 0.49902758 0.49936333 0.49969903 0.50003396 0.50036875 0.50070306\n",
      " 0.50103646 0.50136972 0.50170269 0.50203536 0.50236782 0.50269991\n",
      " 0.5030315  0.5033628  0.50369382 0.50402413 0.50435405 0.50468362\n",
      " 0.50501306 0.50534206 0.50567072 0.5059989  0.50632665 0.5066541\n",
      " 0.50698102 0.50730759 0.50763374 0.50795921 0.50828426 0.50860901\n",
      " 0.50893351 0.50925783 0.50958141 0.50990462 0.51022756 0.51055004\n",
      " 0.51087204 0.51119373 0.51151489 0.51183583 0.51215672 0.51247675\n",
      " 0.51279661 0.51311599 0.5134347  0.51375314 0.51407125 0.51438901\n",
      " 0.51470671 0.5150238  0.51534068 0.5156574  0.51597343 0.51628937\n",
      " 0.51660493 0.51691992 0.5172346  0.51754885 0.51786282 0.51817645\n",
      " 0.51848991 0.51880266 0.51911522 0.5194276  0.51973937 0.52005067\n",
      " 0.52036178 0.52067253 0.52098321 0.52129333 0.52160298 0.52191248\n",
      " 0.52222168 0.52253059 0.52283897 0.52314657 0.52345395 0.52376089\n",
      " 0.52406755 0.52437381 0.52467988 0.52498544 0.52529083 0.52559576\n",
      " 0.52589998 0.52620408 0.52650801 0.52681138 0.52711435 0.5274168\n",
      " 0.52771908 0.52802077 0.52832182 0.52862268 0.52892312 0.52922324\n",
      " 0.5295232  0.5298227  0.53012183 0.53042052 0.53071889 0.53101692\n",
      " 0.53131468 0.53161213 0.53190888 0.53220503 0.53250111 0.53279708\n",
      " 0.53309265 0.53338765 0.53368208 0.53397628 0.53426965 0.53456255\n",
      " 0.53485509 0.53514738 0.5354392  0.53573071 0.53602218 0.53631324\n",
      " 0.53660386 0.53689408 0.53718376 0.53747323 0.53776232 0.53805115\n",
      " 0.5383392  0.53862708 0.53891463 0.53920194 0.53948879 0.53977526\n",
      " 0.5400616  0.54034741 0.54063287 0.540918   0.54120295 0.54148716\n",
      " 0.54177128 0.54205462 0.5423374  0.54262009 0.54290236 0.54318442\n",
      " 0.54346632 0.54374738 0.54402802 0.54430859 0.54458883 0.5448688\n",
      " 0.54514802 0.54542697 0.54570551 0.54598388 0.54626178 0.54653954\n",
      " 0.54681694 0.54709417 0.54737081 0.54764726 0.54792319 0.54819893\n",
      " 0.54847411 0.5487491  0.54902365 0.54929789 0.5495719  0.54984563\n",
      " 0.55011896 0.55039194 0.55066453 0.55093685 0.55120888 0.5514807\n",
      " 0.55175215 0.55202285 0.55229337 0.55256322 0.55283275 0.55310217\n",
      " 0.55337132 0.5536402  0.55390865 0.55417661 0.55444434 0.55471202\n",
      " 0.55497922 0.55524639 0.55551288 0.55577873 0.55604441 0.5563099\n",
      " 0.55657514 0.55684026 0.55710513 0.55736966 0.55763361 0.5578974\n",
      " 0.55816069 0.55842382 0.55868638 0.55894864 0.55921041 0.55947197\n",
      " 0.55973327 0.55999444 0.56025519 0.56051563 0.56077574 0.56103548\n",
      " 0.56129504 0.561554   0.56181255 0.56207092 0.56232903 0.56258669\n",
      " 0.56284414 0.5631014  0.56335827 0.56361496 0.56387155 0.56412791\n",
      " 0.56438412 0.56463993 0.5648954  0.56515064 0.56540571 0.5656606\n",
      " 0.56591525 0.56616944 0.56642337 0.56667698 0.56693048 0.56718377\n",
      " 0.56743637 0.56768844 0.5679404  0.56819214 0.56844384 0.56869509\n",
      " 0.56894604 0.56919657 0.56944697 0.56969695 0.56994661 0.57019606\n",
      " 0.57044535 0.57069445 0.57094301 0.57119127 0.57143942 0.57168708\n",
      " 0.57193454 0.57218165 0.57242861 0.57267536 0.57292183 0.57316799\n",
      " 0.57341402 0.57365958 0.57390509 0.57415043 0.57439551 0.57464009\n",
      " 0.57488415 0.57512808 0.57537164 0.57561482 0.57585774 0.5761005\n",
      " 0.57634277 0.5765847  0.57682659 0.57706833 0.57730951 0.57755054\n",
      " 0.57779135 0.57803188 0.57827231 0.57851226 0.5787519  0.57899121\n",
      " 0.57923015 0.57946897 0.57970722 0.57994545 0.58018327 0.58042107\n",
      " 0.58065855 0.58089571 0.58113271 0.58136937 0.58160565 0.58184162\n",
      " 0.58207749 0.58231316 0.5825483  0.58278326 0.58301801 0.58325237\n",
      " 0.58348657 0.58372054 0.58395432 0.58418796 0.58442109 0.58465404\n",
      " 0.58488695 0.58511931 0.58535165 0.5855834  0.5858149  0.58604598\n",
      " 0.58627692 0.58650773 0.58673826 0.58696817 0.5871979  0.58742745\n",
      " 0.58765654 0.58788541 0.58811414 0.5883427  0.58857089 0.58879897\n",
      " 0.58902691 0.58925474 0.58948232 0.5897093  0.58993592 0.59016251\n",
      " 0.59038853 0.59061438 0.59083999 0.59106525 0.59129037 0.59151525\n",
      " 0.59173989 0.59196435 0.59218838 0.59241237 0.59263605 0.59285916\n",
      " 0.59308219 0.59330513 0.59352778 0.59375021 0.59397231 0.59419432\n",
      " 0.59441568 0.59463674 0.59485718 0.59507738 0.59529749 0.59551733\n",
      " 0.59573684 0.59595606 0.59617507 0.59639381 0.59661246 0.59683094\n",
      " 0.59704922 0.59726734 0.59748502 0.59770233 0.59791941 0.59813617\n",
      " 0.59835267 0.59856894 0.59878499 0.59900074 0.59921613 0.59943145\n",
      " 0.59964631 0.599861   0.60007555 0.60029001 0.60050402 0.60071783\n",
      " 0.60093126 0.60114432 0.60135726 0.60156976 0.60178185 0.60199378\n",
      " 0.60220563 0.60241688 0.60262787 0.60283856 0.60304887 0.60325911\n",
      " 0.60346886 0.60367833 0.60388747 0.60409641 0.60430506 0.60451362\n",
      " 0.60472187 0.60492987 0.60513749 0.60534459 0.6055516  0.60575839\n",
      " 0.60596474 0.6061709  0.60637673 0.60658247 0.60678753 0.60699196\n",
      " 0.60719614 0.60740006 0.6076038  0.60780721 0.60801047 0.60821338\n",
      " 0.60841596 0.60861838 0.60882044 0.60902235 0.60922374 0.60942464\n",
      " 0.60962508 0.6098253  0.61002519 0.61022452 0.61042377 0.61062291\n",
      " 0.61082169 0.61101985 0.61121783 0.61141534 0.61161201 0.61180834\n",
      " 0.61200447 0.61220039 0.61239567 0.61259021]\n"
     ]
    }
   ],
   "source": [
    "pca = PCA(n_components = 2000)\n",
    "# Step 2: Fit PCA on the dataset\n",
    "pca.fit(X_train)\n",
    "# Step 3: Calculate the cumulative variance explained by the components\n",
    "cumulative_variance = np.cumsum(pca.explained_variance_ratio_)\n",
    "# Step 4: Find the number of components that explain at least 95% variance\n",
    "n_components_95 = np.argmax(cumulative_variance >= 0.95) + 1\n",
    "\n",
    "print(f\"Number of components to retain 95% of variance: {n_components_95}\")\n",
    "\n",
    "# Print explained variance for each component\n",
    "explained_variance = pca.explained_variance_ratio_\n",
    "print(f\"Explained variance by each component: {explained_variance}\")\n",
    "\n",
    "# Calculate cumulative explained variance\n",
    "cumulative_variance = np.cumsum(explained_variance)\n",
    "print(f\"Cumulative explained variance: {cumulative_variance}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test accuracy: 0.3065\n"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "# Initialize PCA for dimensionality reduction\n",
    "#pca = PCA(n_components=4)  # Adjust the number of components as needed\n",
    "\n",
    "# Apply PCA to the training and test sets\n",
    "X_train_pca = pca.fit_transform(X_train)\n",
    "X_test_pca = pca.transform(X_test)\n",
    "\n",
    "# --- Initialize the SVC model ---\n",
    "svc_model = SVC()\n",
    "\n",
    "# Fit the model on the training set\n",
    "svc_model.fit(X_train_pca, y_train)\n",
    "\n",
    "# Predict on the test set\n",
    "y_pred = svc_model.predict(X_test_pca)\n",
    "\n",
    "# Calculate the accuracy\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "print(f\"Test accuracy: {accuracy:.4f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test accuracy: 0.4065\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import scipy.io as sio\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score\n",
    "import numpy as np\n",
    "\n",
    "# Function to extract gesture label from the filename\n",
    "def extract_label_from_filename(filepath):\n",
    "    filename = os.path.basename(filepath)\n",
    "    parts = filename.split('_')\n",
    "    for part in parts:\n",
    "        if 'gesture' in part:\n",
    "            return int(part.replace('gesture', ''))\n",
    "    return None\n",
    "\n",
    "# Function to load and process a single .mat file\n",
    "def load_and_process_file(filepath, target_length):\n",
    "    mat_data = sio.loadmat(filepath)\n",
    "    data_emg = mat_data['data_emg']\n",
    "    \n",
    "    # Handle NaNs and Infinities\n",
    "    data_emg = np.nan_to_num(data_emg, nan=0.0, posinf=0.0, neginf=0.0)\n",
    "    \n",
    "    # Pad or truncate the data to the target length\n",
    "    if data_emg.shape[0] < target_length:\n",
    "        padded_data = np.pad(data_emg, ((0, target_length - data_emg.shape[0]), (0, 0)), 'constant', constant_values=0)\n",
    "    else:\n",
    "        padded_data = data_emg[:target_length]\n",
    "    \n",
    "    # Flatten the data for SVM input\n",
    "    return padded_data.flatten()\n",
    "\n",
    "# Process a list of files and return processed data and labels\n",
    "def process_files(file_list, target_length):\n",
    "    X = []\n",
    "    y = []\n",
    "    \n",
    "    for filepath in file_list:\n",
    "        X.append(load_and_process_file(filepath, target_length))\n",
    "        y.append(extract_label_from_filename(filepath))\n",
    "    \n",
    "    return np.array(X), np.array(y)\n",
    "\n",
    "# Specify session folders\n",
    "session_folders = ['Session1_matfiles', 'Session2_matfiles', 'Session3_matfiles']\n",
    "\n",
    "# Target length for EMG signals (adjust based on your data)\n",
    "target_length = 10240\n",
    "\n",
    "# Collect all .mat files and their corresponding labels\n",
    "all_mat_files = []\n",
    "all_labels = []\n",
    "\n",
    "for session_folder in session_folders:\n",
    "    mat_files = sorted(os.listdir(session_folder))\n",
    "    all_mat_files += [os.path.join(session_folder, mat_file) for mat_file in mat_files if mat_file.endswith('.mat')]\n",
    "    all_labels += [extract_label_from_filename(mat_file) for mat_file in mat_files if mat_file.endswith('.mat')]\n",
    "\n",
    "# Split the dataset into train and test sets\n",
    "train_files, test_files, train_labels, test_labels = train_test_split(all_mat_files, all_labels, test_size=0.2, random_state=42)\n",
    "\n",
    "# Process training and test data\n",
    "X_train, y_train = process_files(train_files, target_length)\n",
    "X_test, y_test = process_files(test_files, target_length)\n",
    "\n",
    "# Initialize PCA for dimensionality reduction\n",
    "pca = PCA(n_components=100)  # Adjust the number of components as needed\n",
    "\n",
    "# Apply PCA to the training and test sets\n",
    "X_train_pca = pca.fit_transform(X_train)\n",
    "X_test_pca = pca.transform(X_test)\n",
    "\n",
    "# --- Initialize the SVC model ---\n",
    "svc_model = SVC()\n",
    "\n",
    "# Fit the model on the training set\n",
    "svc_model.fit(X_train_pca, y_train)\n",
    "\n",
    "# Predict on the test set\n",
    "y_pred = svc_model.predict(X_test_pca)\n",
    "\n",
    "# Calculate the accuracy\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "print(f\"Test accuracy: {accuracy:.4f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing Batch: 100%|██████████| 50/50 [00:00<00:00, 69.33it/s]\n",
      "Processing Batch: 100%|██████████| 50/50 [00:00<00:00, 72.05it/s]\n",
      "Processing Batch: 100%|██████████| 50/50 [00:00<00:00, 73.20it/s]\n",
      "Processing Batch: 100%|██████████| 50/50 [00:00<00:00, 71.33it/s]\n",
      "Processing Batch: 100%|██████████| 50/50 [00:00<00:00, 73.20it/s]\n",
      "Processing Batch: 100%|██████████| 50/50 [00:00<00:00, 70.17it/s]\n",
      "Processing Batch: 100%|██████████| 50/50 [00:00<00:00, 70.94it/s]\n",
      "Processing Batch: 100%|██████████| 50/50 [00:00<00:00, 71.18it/s]\n",
      "Processing Batch: 100%|██████████| 50/50 [00:00<00:00, 70.02it/s]\n",
      "Processing Batch: 100%|██████████| 50/50 [00:00<00:00, 68.53it/s]\n",
      "Processing Batch: 100%|██████████| 50/50 [00:00<00:00, 68.70it/s]\n",
      "Processing Batch: 100%|██████████| 50/50 [00:00<00:00, 72.16it/s]\n",
      "Processing Batch: 100%|██████████| 50/50 [00:00<00:00, 69.64it/s]\n",
      "Processing Batch: 100%|██████████| 50/50 [00:00<00:00, 69.94it/s]\n",
      "Processing Batch: 100%|██████████| 50/50 [00:00<00:00, 71.37it/s]\n",
      "Processing Batch: 100%|██████████| 50/50 [00:00<00:00, 69.99it/s]\n",
      "Processing Batch: 100%|██████████| 50/50 [00:00<00:00, 68.26it/s]\n",
      "Processing Batch: 100%|██████████| 50/50 [00:00<00:00, 66.77it/s]\n",
      "Processing Batch: 100%|██████████| 50/50 [00:00<00:00, 69.45it/s]\n",
      "Processing Batch: 100%|██████████| 50/50 [00:00<00:00, 70.02it/s]\n",
      "Processing Batch: 100%|██████████| 50/50 [00:00<00:00, 68.96it/s]\n",
      "Processing Batch: 100%|██████████| 50/50 [00:00<00:00, 70.68it/s]\n",
      "Processing Batch: 100%|██████████| 50/50 [00:00<00:00, 72.06it/s]\n",
      "Processing Batch: 100%|██████████| 50/50 [00:00<00:00, 69.79it/s]\n",
      "Processing Batch: 100%|██████████| 50/50 [00:00<00:00, 69.50it/s]\n",
      "Processing Batch: 100%|██████████| 50/50 [00:00<00:00, 71.33it/s]\n",
      "Processing Batch: 100%|██████████| 50/50 [00:00<00:00, 72.17it/s]\n",
      "Processing Batch: 100%|██████████| 50/50 [00:00<00:00, 68.63it/s]\n",
      "Processing Batch: 100%|██████████| 50/50 [00:00<00:00, 71.02it/s]\n",
      "Processing Batch: 100%|██████████| 50/50 [00:00<00:00, 69.65it/s]\n",
      "Processing Batch: 100%|██████████| 50/50 [00:00<00:00, 71.56it/s]\n",
      "Processing Batch: 100%|██████████| 50/50 [00:00<00:00, 73.13it/s]\n",
      "Processing Batch: 100%|██████████| 50/50 [00:00<00:00, 70.59it/s]\n",
      "Processing Batch: 100%|██████████| 50/50 [00:00<00:00, 74.42it/s]\n",
      "Processing Batch: 100%|██████████| 50/50 [00:00<00:00, 69.61it/s]\n",
      "Processing Batch: 100%|██████████| 50/50 [00:00<00:00, 69.92it/s]\n",
      "Processing Batch: 100%|██████████| 50/50 [00:00<00:00, 71.61it/s]\n",
      "Processing Batch: 100%|██████████| 50/50 [00:00<00:00, 71.40it/s]\n",
      "Processing Batch: 100%|██████████| 50/50 [00:00<00:00, 72.56it/s]\n",
      "Processing Batch: 100%|██████████| 50/50 [00:00<00:00, 69.64it/s]\n",
      "Processing Batch: 100%|██████████| 50/50 [00:00<00:00, 67.66it/s]\n",
      "Processing Batch: 100%|██████████| 50/50 [00:00<00:00, 70.48it/s]\n",
      "Processing Batch: 100%|██████████| 50/50 [00:00<00:00, 70.83it/s]\n",
      "Processing Batch: 100%|██████████| 50/50 [00:00<00:00, 72.63it/s]\n",
      "Processing Batch: 100%|██████████| 50/50 [00:00<00:00, 70.85it/s]\n",
      "Processing Batch: 100%|██████████| 50/50 [00:00<00:00, 68.44it/s]\n",
      "Processing Batch: 100%|██████████| 50/50 [00:00<00:00, 67.05it/s]\n",
      "Processing Batch: 100%|██████████| 50/50 [00:00<00:00, 71.65it/s]\n",
      "Processing Batch: 100%|██████████| 50/50 [00:00<00:00, 69.76it/s]\n",
      "Processing Batch: 100%|██████████| 50/50 [00:00<00:00, 70.42it/s]\n",
      "Processing Batch: 100%|██████████| 50/50 [00:00<00:00, 70.84it/s]\n",
      "Processing Batch: 100%|██████████| 50/50 [00:00<00:00, 69.07it/s]\n",
      "Processing Batch: 100%|██████████| 50/50 [00:00<00:00, 71.99it/s]\n",
      "Processing Batch: 100%|██████████| 50/50 [00:00<00:00, 69.96it/s]\n",
      "Processing Batch: 100%|██████████| 50/50 [00:00<00:00, 72.40it/s]\n",
      "Processing Batch: 100%|██████████| 50/50 [00:00<00:00, 70.78it/s]\n",
      "Processing Batch: 100%|██████████| 50/50 [00:00<00:00, 73.39it/s]\n",
      "Processing Batch: 100%|██████████| 50/50 [00:00<00:00, 70.12it/s]\n",
      "Processing Batch: 100%|██████████| 50/50 [00:00<00:00, 71.49it/s]\n",
      "Processing Batch: 100%|██████████| 50/50 [00:00<00:00, 70.50it/s]\n",
      "Processing Batch: 100%|██████████| 50/50 [00:00<00:00, 70.60it/s]\n",
      "Processing Batch: 100%|██████████| 50/50 [00:00<00:00, 71.08it/s]\n",
      "Processing Batch: 100%|██████████| 50/50 [00:00<00:00, 72.96it/s]\n",
      "Processing Batch: 100%|██████████| 50/50 [00:00<00:00, 70.56it/s]\n",
      "Processing Batch: 100%|██████████| 50/50 [00:00<00:00, 71.23it/s]\n",
      "Processing Batch: 100%|██████████| 50/50 [00:00<00:00, 71.13it/s]\n",
      "Processing Batch: 100%|██████████| 50/50 [00:00<00:00, 70.59it/s]\n",
      "Processing Batch: 100%|██████████| 50/50 [00:00<00:00, 70.95it/s]\n",
      "Processing Batch: 100%|██████████| 50/50 [00:00<00:00, 71.19it/s]\n",
      "Processing Batch: 100%|██████████| 50/50 [00:00<00:00, 69.47it/s]\n",
      "Processing Batch: 100%|██████████| 50/50 [00:00<00:00, 70.41it/s]\n",
      "Processing Batch: 100%|██████████| 50/50 [00:00<00:00, 69.65it/s]\n",
      "Processing Batch: 100%|██████████| 50/50 [00:00<00:00, 72.74it/s]\n",
      "Processing Batch: 100%|██████████| 50/50 [00:00<00:00, 66.93it/s]\n",
      "Processing Batch: 100%|██████████| 50/50 [00:00<00:00, 73.42it/s]\n",
      "Processing Batch: 100%|██████████| 50/50 [00:00<00:00, 68.45it/s]\n",
      "Processing Batch: 100%|██████████| 50/50 [00:00<00:00, 71.28it/s]\n",
      "Processing Batch: 100%|██████████| 50/50 [00:00<00:00, 70.30it/s]\n",
      "Processing Batch: 100%|██████████| 50/50 [00:00<00:00, 74.11it/s]\n",
      "Processing Batch: 100%|██████████| 50/50 [00:00<00:00, 68.15it/s]\n",
      "Processing Batch: 100%|██████████| 50/50 [00:00<00:00, 68.76it/s]\n",
      "Processing Batch: 100%|██████████| 50/50 [00:00<00:00, 70.08it/s]\n",
      "Processing Batch: 100%|██████████| 50/50 [00:00<00:00, 70.71it/s]\n",
      "Processing Batch: 100%|██████████| 50/50 [00:00<00:00, 70.39it/s]\n",
      "Processing Batch: 100%|██████████| 50/50 [00:00<00:00, 68.90it/s]\n",
      "Processing Batch: 100%|██████████| 50/50 [00:00<00:00, 71.29it/s]\n",
      "Processing Batch: 100%|██████████| 50/50 [00:00<00:00, 68.80it/s]\n",
      "Processing Batch: 100%|██████████| 50/50 [00:00<00:00, 70.78it/s]\n",
      "Processing Batch: 100%|██████████| 50/50 [00:00<00:00, 70.18it/s]\n",
      "Processing Batch: 100%|██████████| 50/50 [00:00<00:00, 71.76it/s]\n",
      "Processing Batch: 100%|██████████| 50/50 [00:00<00:00, 69.30it/s]\n",
      "Processing Batch: 100%|██████████| 50/50 [00:00<00:00, 71.37it/s]\n",
      "Processing Batch: 100%|██████████| 50/50 [00:00<00:00, 67.81it/s]\n",
      "Processing Batch: 100%|██████████| 50/50 [00:00<00:00, 70.55it/s]\n",
      "Processing Batch: 100%|██████████| 50/50 [00:00<00:00, 71.79it/s]\n",
      "Processing Batch: 100%|██████████| 50/50 [00:00<00:00, 70.94it/s]\n",
      "Processing Batch: 100%|██████████| 50/50 [00:00<00:00, 70.13it/s]\n",
      "Processing Batch: 100%|██████████| 50/50 [00:00<00:00, 70.15it/s]\n",
      "Processing Batch: 100%|██████████| 50/50 [00:00<00:00, 74.11it/s]\n",
      "Processing Batch: 100%|██████████| 50/50 [00:00<00:00, 69.73it/s]\n",
      "Processing Batch: 100%|██████████| 50/50 [00:00<00:00, 67.15it/s]\n",
      "Processing Batch: 100%|██████████| 50/50 [00:00<00:00, 66.90it/s]\n",
      "Processing Batch: 100%|██████████| 50/50 [00:00<00:00, 70.13it/s]\n",
      "Processing Batch: 100%|██████████| 50/50 [00:00<00:00, 72.40it/s]\n",
      "Processing Batch: 100%|██████████| 50/50 [00:00<00:00, 71.24it/s]\n",
      "Processing Batch: 100%|██████████| 50/50 [00:00<00:00, 72.92it/s]\n",
      "Processing Batch: 100%|██████████| 50/50 [00:00<00:00, 71.61it/s]\n",
      "Processing Batch: 100%|██████████| 50/50 [00:00<00:00, 72.75it/s]\n",
      "Processing Batch: 100%|██████████| 50/50 [00:00<00:00, 73.54it/s]\n",
      "Processing Batch: 100%|██████████| 50/50 [00:00<00:00, 71.24it/s]\n",
      "Processing Batch: 100%|██████████| 50/50 [00:00<00:00, 72.99it/s]\n",
      "Processing Batch: 100%|██████████| 50/50 [00:00<00:00, 69.03it/s]\n",
      "Processing Batch: 100%|██████████| 50/50 [00:00<00:00, 70.21it/s]\n",
      "Processing Batch: 100%|██████████| 50/50 [00:00<00:00, 69.26it/s]\n",
      "Processing Batch: 100%|██████████| 50/50 [00:00<00:00, 69.81it/s]\n",
      "Processing Batch: 100%|██████████| 50/50 [00:00<00:00, 73.25it/s]\n",
      "Processing Batch: 100%|██████████| 50/50 [00:00<00:00, 71.42it/s]\n",
      "Processing Batch: 100%|██████████| 50/50 [00:00<00:00, 71.65it/s]\n",
      "Processing Batch: 100%|██████████| 50/50 [00:00<00:00, 70.81it/s]\n",
      "Processing Batch: 100%|██████████| 50/50 [00:00<00:00, 72.55it/s]\n",
      "Processing Batch: 100%|██████████| 50/50 [00:00<00:00, 68.52it/s]\n",
      "Processing Batch: 100%|██████████| 50/50 [00:00<00:00, 71.01it/s]\n",
      "Processing Batch: 100%|██████████| 50/50 [00:00<00:00, 72.85it/s]\n",
      "Processing Batch: 100%|██████████| 50/50 [00:00<00:00, 72.72it/s]\n",
      "Processing Batch: 100%|██████████| 50/50 [00:00<00:00, 70.77it/s]\n",
      "Processing Batch: 100%|██████████| 50/50 [00:00<00:00, 70.43it/s]\n",
      "Processing Batch: 100%|██████████| 50/50 [00:00<00:00, 74.45it/s]\n",
      "Processing Batch: 100%|██████████| 50/50 [00:00<00:00, 73.04it/s]\n",
      "Processing Batch: 100%|██████████| 50/50 [00:00<00:00, 70.79it/s]\n",
      "Processing Batch: 100%|██████████| 50/50 [00:00<00:00, 71.82it/s]\n",
      "Processing Batch: 100%|██████████| 50/50 [00:00<00:00, 69.55it/s]\n",
      "Processing Batch: 100%|██████████| 50/50 [00:00<00:00, 71.49it/s]\n",
      "Processing Batch: 100%|██████████| 50/50 [00:00<00:00, 70.94it/s]\n",
      "Processing Batch: 100%|██████████| 50/50 [00:00<00:00, 69.58it/s]\n",
      "Processing Batch: 100%|██████████| 50/50 [00:00<00:00, 70.50it/s]\n",
      "Processing Batch: 100%|██████████| 50/50 [00:00<00:00, 71.17it/s]\n",
      "Processing Batch: 100%|██████████| 50/50 [00:00<00:00, 72.89it/s]\n",
      "Processing Batch: 100%|██████████| 50/50 [00:00<00:00, 71.33it/s]\n",
      "Processing Batch: 100%|██████████| 50/50 [00:00<00:00, 69.70it/s]\n",
      "Processing Batch: 100%|██████████| 50/50 [00:00<00:00, 70.78it/s]\n",
      "Processing Batch: 100%|██████████| 50/50 [00:00<00:00, 74.07it/s]\n",
      "Processing Batch: 100%|██████████| 50/50 [00:00<00:00, 71.22it/s]\n",
      "Processing Batch: 100%|██████████| 50/50 [00:00<00:00, 71.05it/s]\n",
      "Processing Batch: 100%|██████████| 50/50 [00:00<00:00, 68.47it/s]\n",
      "Processing Batch: 100%|██████████| 50/50 [00:00<00:00, 71.49it/s]\n",
      "Processing Batch: 100%|██████████| 50/50 [00:00<00:00, 73.02it/s]\n",
      "Processing Batch: 100%|██████████| 50/50 [00:00<00:00, 70.29it/s]\n",
      "Processing Batch: 100%|██████████| 50/50 [00:00<00:00, 71.61it/s]\n",
      "Processing Batch: 100%|██████████| 50/50 [00:00<00:00, 68.39it/s]\n",
      "Processing Batch: 100%|██████████| 50/50 [00:00<00:00, 72.28it/s]\n",
      "Processing Batch: 100%|██████████| 50/50 [00:00<00:00, 72.55it/s]\n",
      "Processing Batch: 100%|██████████| 50/50 [00:00<00:00, 70.97it/s]\n",
      "Processing Batch: 100%|██████████| 50/50 [00:00<00:00, 68.66it/s]\n",
      "Processing Batch: 100%|██████████| 50/50 [00:00<00:00, 73.13it/s]\n",
      "Processing Batch: 100%|██████████| 50/50 [00:00<00:00, 70.86it/s]\n",
      "Processing Batch: 100%|██████████| 50/50 [00:00<00:00, 73.35it/s]\n",
      "Processing Batch: 100%|██████████| 50/50 [00:00<00:00, 71.76it/s]\n",
      "Processing Batch: 100%|██████████| 50/50 [00:00<00:00, 70.29it/s]\n",
      "Processing Batch: 100%|██████████| 50/50 [00:00<00:00, 71.74it/s]\n",
      "Processing Batch: 100%|██████████| 50/50 [00:00<00:00, 69.37it/s]\n",
      "Processing Batch: 100%|██████████| 50/50 [00:00<00:00, 71.51it/s]\n",
      "Processing Batch: 100%|██████████| 50/50 [00:00<00:00, 72.79it/s]\n",
      "Processing Batch: 100%|██████████| 50/50 [00:00<00:00, 73.66it/s]\n",
      "Processing Batch: 100%|██████████| 50/50 [00:00<00:00, 72.13it/s]\n",
      "Processing Batch: 100%|██████████| 50/50 [00:00<00:00, 72.23it/s]\n",
      "Processing Batch: 100%|██████████| 50/50 [00:00<00:00, 72.67it/s]\n",
      "Processing Batch: 100%|██████████| 50/50 [00:00<00:00, 71.84it/s]\n",
      "Processing Batch: 100%|██████████| 50/50 [00:00<00:00, 69.71it/s]\n",
      "Processing Batch: 100%|██████████| 50/50 [00:00<00:00, 72.00it/s]\n",
      "Processing Batch: 100%|██████████| 50/50 [00:00<00:00, 72.40it/s]\n",
      "Processing Batch: 100%|██████████| 50/50 [00:00<00:00, 70.64it/s]\n",
      "Processing Batch: 100%|██████████| 50/50 [00:00<00:00, 68.86it/s]\n",
      "Processing Batch: 100%|██████████| 50/50 [00:00<00:00, 69.43it/s]\n",
      "Processing Batch: 100%|██████████| 50/50 [00:00<00:00, 70.26it/s]\n",
      "Processing Batch: 100%|██████████| 50/50 [00:00<00:00, 70.28it/s]\n",
      "Processing Batch: 100%|██████████| 50/50 [00:00<00:00, 69.40it/s]\n",
      "Processing Batch: 100%|██████████| 50/50 [00:00<00:00, 70.88it/s]\n",
      "Processing Batch: 100%|██████████| 50/50 [00:00<00:00, 70.31it/s]\n",
      "Processing Batch: 100%|██████████| 50/50 [00:00<00:00, 70.04it/s]\n",
      "Processing Batch: 100%|██████████| 50/50 [00:00<00:00, 72.87it/s]\n",
      "Processing Batch: 100%|██████████| 50/50 [00:00<00:00, 69.04it/s]\n",
      "Processing Batch: 100%|██████████| 50/50 [00:00<00:00, 69.08it/s]\n",
      "Processing Batch: 100%|██████████| 50/50 [00:00<00:00, 71.57it/s]\n",
      "Processing Batch: 100%|██████████| 50/50 [00:00<00:00, 72.28it/s]\n",
      "Processing Batch: 100%|██████████| 50/50 [00:00<00:00, 70.30it/s]\n",
      "Processing Batch: 100%|██████████| 50/50 [00:00<00:00, 68.89it/s]\n",
      "Processing Batch: 100%|██████████| 50/50 [00:00<00:00, 70.86it/s]\n",
      "Processing Batch: 100%|██████████| 50/50 [00:00<00:00, 70.21it/s]\n",
      "Processing Batch: 100%|██████████| 50/50 [00:00<00:00, 70.88it/s]\n",
      "Processing Batch: 100%|██████████| 50/50 [00:00<00:00, 70.96it/s]\n",
      "Processing Batch: 100%|██████████| 50/50 [00:00<00:00, 69.68it/s]\n",
      "Processing Batch: 100%|██████████| 50/50 [00:00<00:00, 71.46it/s]\n",
      "Processing Batch: 100%|██████████| 50/50 [00:00<00:00, 71.41it/s]\n",
      "Processing Batch: 100%|██████████| 50/50 [00:00<00:00, 71.81it/s]\n",
      "Processing Batch: 100%|██████████| 50/50 [00:00<00:00, 70.80it/s]\n",
      "Processing Batch: 100%|██████████| 50/50 [00:00<00:00, 69.65it/s]\n",
      "Processing Batch: 100%|██████████| 50/50 [00:00<00:00, 72.63it/s]\n",
      "Processing Batch: 100%|██████████| 50/50 [00:00<00:00, 71.26it/s]\n",
      "Processing Batch: 100%|██████████| 50/50 [00:00<00:00, 70.04it/s]\n",
      "Processing Batch: 100%|██████████| 50/50 [00:00<00:00, 70.28it/s]\n",
      "Processing Batch: 100%|██████████| 50/50 [00:00<00:00, 72.96it/s]\n",
      "Processing Batch: 100%|██████████| 50/50 [00:00<00:00, 70.46it/s]\n",
      "Processing Batch: 100%|██████████| 50/50 [00:00<00:00, 71.59it/s]\n",
      "Processing Batch: 100%|██████████| 50/50 [00:00<00:00, 68.74it/s]\n",
      "Processing Batch: 100%|██████████| 50/50 [00:00<00:00, 70.92it/s]\n",
      "Processing Batch: 100%|██████████| 50/50 [00:00<00:00, 67.93it/s]\n",
      "Processing Batch: 100%|██████████| 50/50 [00:00<00:00, 67.74it/s]\n",
      "Processing Batch: 100%|██████████| 50/50 [00:00<00:00, 73.59it/s]\n",
      "Processing Batch: 100%|██████████| 50/50 [00:00<00:00, 70.77it/s]\n",
      "Processing Batch: 100%|██████████| 50/50 [00:00<00:00, 71.18it/s]\n",
      "Processing Batch: 100%|██████████| 50/50 [00:00<00:00, 72.33it/s]\n",
      "Processing Batch: 100%|██████████| 50/50 [00:00<00:00, 70.69it/s]\n",
      "Processing Batch: 100%|██████████| 50/50 [00:00<00:00, 73.21it/s]\n",
      "Processing Batch: 100%|██████████| 50/50 [00:00<00:00, 72.35it/s]\n",
      "Processing Batch: 100%|██████████| 50/50 [00:00<00:00, 71.99it/s]\n",
      "Processing Batch: 100%|██████████| 50/50 [00:00<00:00, 70.00it/s]\n",
      "Processing Batch: 100%|██████████| 50/50 [00:00<00:00, 70.34it/s]\n",
      "Processing Batch: 100%|██████████| 50/50 [00:00<00:00, 68.93it/s]\n",
      "Processing Batch: 100%|██████████| 50/50 [00:00<00:00, 72.08it/s]\n",
      "Processing Batch: 100%|██████████| 50/50 [00:00<00:00, 72.43it/s]\n",
      "Processing Batch: 100%|██████████| 50/50 [00:00<00:00, 68.88it/s]\n",
      "Processing Batch: 100%|██████████| 50/50 [00:00<00:00, 73.45it/s]\n",
      "Processing Batch: 100%|██████████| 50/50 [00:00<00:00, 71.13it/s]\n",
      "Processing Batch: 100%|██████████| 50/50 [00:00<00:00, 72.78it/s]\n",
      "Processing Batch: 100%|██████████| 50/50 [00:00<00:00, 70.88it/s]\n",
      "Processing Batch: 100%|██████████| 50/50 [00:00<00:00, 72.99it/s]\n",
      "Processing Batch: 100%|██████████| 50/50 [00:00<00:00, 72.90it/s]\n",
      "Processing Batch: 100%|██████████| 50/50 [00:00<00:00, 70.39it/s]\n",
      "Processing Batch: 100%|██████████| 50/50 [00:00<00:00, 73.49it/s]\n",
      "Processing Batch: 100%|██████████| 50/50 [00:00<00:00, 72.32it/s]\n",
      "Processing Batch: 100%|██████████| 50/50 [00:00<00:00, 72.68it/s]\n",
      "Processing Batch: 100%|██████████| 50/50 [00:00<00:00, 70.51it/s]\n",
      "Processing Batch: 100%|██████████| 50/50 [00:00<00:00, 73.28it/s]\n",
      "Processing Batch: 100%|██████████| 50/50 [00:00<00:00, 70.75it/s]\n",
      "Processing Batch: 100%|██████████| 50/50 [00:00<00:00, 70.20it/s]\n",
      "Processing Batch: 100%|██████████| 50/50 [00:00<00:00, 71.93it/s]\n",
      "Processing Batch: 100%|██████████| 50/50 [00:00<00:00, 69.88it/s]\n",
      "Processing Batch: 100%|██████████| 50/50 [00:00<00:00, 70.47it/s]\n",
      "Processing Batch: 100%|██████████| 50/50 [00:00<00:00, 73.82it/s]\n",
      "Processing Batch: 100%|██████████| 50/50 [00:00<00:00, 70.78it/s]\n",
      "Processing Batch: 100%|██████████| 50/50 [00:00<00:00, 71.99it/s]\n",
      "Processing Batch: 100%|██████████| 50/50 [00:00<00:00, 71.78it/s]\n",
      "Processing Batch: 100%|██████████| 50/50 [00:00<00:00, 71.99it/s]\n",
      "Processing Batch: 100%|██████████| 50/50 [00:00<00:00, 69.51it/s]\n",
      "Processing Batch: 100%|██████████| 50/50 [00:00<00:00, 69.29it/s]\n",
      "Processing Batch: 100%|██████████| 8/8 [00:00<00:00, 70.55it/s]\n",
      "Processing Batch: 100%|██████████| 3065/3065 [00:44<00:00, 68.13it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Accuracy: 5.94%\n",
      "Fitting 5 folds for each of 54 candidates, totalling 270 fits\n",
      "Best parameters found: {'alpha': 0.01, 'loss': 'hinge', 'max_iter': 3000, 'penalty': 'l2'}\n",
      "Best cross-validation accuracy: 11.03%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/data1/George Pap/grabmyo/ptixiaki/.venv/lib/python3.10/site-packages/sklearn/model_selection/_validation.py:540: FitFailedWarning: \n",
      "135 fits failed out of a total of 270.\n",
      "The score on these train-test partitions for these parameters will be set to nan.\n",
      "If these failures are not expected, you can try to debug them by setting error_score='raise'.\n",
      "\n",
      "Below are more details about the failures:\n",
      "--------------------------------------------------------------------------------\n",
      "7 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"/data1/George Pap/grabmyo/ptixiaki/.venv/lib/python3.10/site-packages/sklearn/model_selection/_validation.py\", line 888, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"/data1/George Pap/grabmyo/ptixiaki/.venv/lib/python3.10/site-packages/sklearn/base.py\", line 1466, in wrapper\n",
      "    estimator._validate_params()\n",
      "  File \"/data1/George Pap/grabmyo/ptixiaki/.venv/lib/python3.10/site-packages/sklearn/base.py\", line 666, in _validate_params\n",
      "    validate_parameter_constraints(\n",
      "  File \"/data1/George Pap/grabmyo/ptixiaki/.venv/lib/python3.10/site-packages/sklearn/utils/_param_validation.py\", line 95, in validate_parameter_constraints\n",
      "    raise InvalidParameterError(\n",
      "sklearn.utils._param_validation.InvalidParameterError: The 'loss' parameter of SGDClassifier must be a str among {'squared_error', 'modified_huber', 'hinge', 'epsilon_insensitive', 'squared_epsilon_insensitive', 'squared_hinge', 'huber', 'perceptron', 'log_loss'}. Got 'log' instead.\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "6 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"/data1/George Pap/grabmyo/ptixiaki/.venv/lib/python3.10/site-packages/sklearn/model_selection/_validation.py\", line 888, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"/data1/George Pap/grabmyo/ptixiaki/.venv/lib/python3.10/site-packages/sklearn/base.py\", line 1466, in wrapper\n",
      "    estimator._validate_params()\n",
      "  File \"/data1/George Pap/grabmyo/ptixiaki/.venv/lib/python3.10/site-packages/sklearn/base.py\", line 666, in _validate_params\n",
      "    validate_parameter_constraints(\n",
      "  File \"/data1/George Pap/grabmyo/ptixiaki/.venv/lib/python3.10/site-packages/sklearn/utils/_param_validation.py\", line 95, in validate_parameter_constraints\n",
      "    raise InvalidParameterError(\n",
      "sklearn.utils._param_validation.InvalidParameterError: The 'loss' parameter of SGDClassifier must be a str among {'perceptron', 'squared_epsilon_insensitive', 'epsilon_insensitive', 'log_loss', 'squared_error', 'squared_hinge', 'huber', 'modified_huber', 'hinge'}. Got 'log' instead.\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "6 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"/data1/George Pap/grabmyo/ptixiaki/.venv/lib/python3.10/site-packages/sklearn/model_selection/_validation.py\", line 888, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"/data1/George Pap/grabmyo/ptixiaki/.venv/lib/python3.10/site-packages/sklearn/base.py\", line 1466, in wrapper\n",
      "    estimator._validate_params()\n",
      "  File \"/data1/George Pap/grabmyo/ptixiaki/.venv/lib/python3.10/site-packages/sklearn/base.py\", line 666, in _validate_params\n",
      "    validate_parameter_constraints(\n",
      "  File \"/data1/George Pap/grabmyo/ptixiaki/.venv/lib/python3.10/site-packages/sklearn/utils/_param_validation.py\", line 95, in validate_parameter_constraints\n",
      "    raise InvalidParameterError(\n",
      "sklearn.utils._param_validation.InvalidParameterError: The 'loss' parameter of SGDClassifier must be a str among {'epsilon_insensitive', 'huber', 'log_loss', 'modified_huber', 'hinge', 'squared_error', 'squared_epsilon_insensitive', 'perceptron', 'squared_hinge'}. Got 'log' instead.\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "5 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"/data1/George Pap/grabmyo/ptixiaki/.venv/lib/python3.10/site-packages/sklearn/model_selection/_validation.py\", line 888, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"/data1/George Pap/grabmyo/ptixiaki/.venv/lib/python3.10/site-packages/sklearn/base.py\", line 1466, in wrapper\n",
      "    estimator._validate_params()\n",
      "  File \"/data1/George Pap/grabmyo/ptixiaki/.venv/lib/python3.10/site-packages/sklearn/base.py\", line 666, in _validate_params\n",
      "    validate_parameter_constraints(\n",
      "  File \"/data1/George Pap/grabmyo/ptixiaki/.venv/lib/python3.10/site-packages/sklearn/utils/_param_validation.py\", line 95, in validate_parameter_constraints\n",
      "    raise InvalidParameterError(\n",
      "sklearn.utils._param_validation.InvalidParameterError: The 'loss' parameter of SGDClassifier must be a str among {'perceptron', 'epsilon_insensitive', 'modified_huber', 'hinge', 'log_loss', 'squared_hinge', 'huber', 'squared_error', 'squared_epsilon_insensitive'}. Got 'log' instead.\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "4 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"/data1/George Pap/grabmyo/ptixiaki/.venv/lib/python3.10/site-packages/sklearn/model_selection/_validation.py\", line 888, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"/data1/George Pap/grabmyo/ptixiaki/.venv/lib/python3.10/site-packages/sklearn/base.py\", line 1466, in wrapper\n",
      "    estimator._validate_params()\n",
      "  File \"/data1/George Pap/grabmyo/ptixiaki/.venv/lib/python3.10/site-packages/sklearn/base.py\", line 666, in _validate_params\n",
      "    validate_parameter_constraints(\n",
      "  File \"/data1/George Pap/grabmyo/ptixiaki/.venv/lib/python3.10/site-packages/sklearn/utils/_param_validation.py\", line 95, in validate_parameter_constraints\n",
      "    raise InvalidParameterError(\n",
      "sklearn.utils._param_validation.InvalidParameterError: The 'loss' parameter of SGDClassifier must be a str among {'squared_epsilon_insensitive', 'hinge', 'log_loss', 'modified_huber', 'perceptron', 'epsilon_insensitive', 'squared_hinge', 'squared_error', 'huber'}. Got 'log' instead.\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "7 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"/data1/George Pap/grabmyo/ptixiaki/.venv/lib/python3.10/site-packages/sklearn/model_selection/_validation.py\", line 888, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"/data1/George Pap/grabmyo/ptixiaki/.venv/lib/python3.10/site-packages/sklearn/base.py\", line 1466, in wrapper\n",
      "    estimator._validate_params()\n",
      "  File \"/data1/George Pap/grabmyo/ptixiaki/.venv/lib/python3.10/site-packages/sklearn/base.py\", line 666, in _validate_params\n",
      "    validate_parameter_constraints(\n",
      "  File \"/data1/George Pap/grabmyo/ptixiaki/.venv/lib/python3.10/site-packages/sklearn/utils/_param_validation.py\", line 95, in validate_parameter_constraints\n",
      "    raise InvalidParameterError(\n",
      "sklearn.utils._param_validation.InvalidParameterError: The 'loss' parameter of SGDClassifier must be a str among {'huber', 'hinge', 'epsilon_insensitive', 'squared_error', 'perceptron', 'modified_huber', 'squared_epsilon_insensitive', 'log_loss', 'squared_hinge'}. Got 'log' instead.\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "16 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"/data1/George Pap/grabmyo/ptixiaki/.venv/lib/python3.10/site-packages/sklearn/model_selection/_validation.py\", line 888, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"/data1/George Pap/grabmyo/ptixiaki/.venv/lib/python3.10/site-packages/sklearn/base.py\", line 1466, in wrapper\n",
      "    estimator._validate_params()\n",
      "  File \"/data1/George Pap/grabmyo/ptixiaki/.venv/lib/python3.10/site-packages/sklearn/base.py\", line 666, in _validate_params\n",
      "    validate_parameter_constraints(\n",
      "  File \"/data1/George Pap/grabmyo/ptixiaki/.venv/lib/python3.10/site-packages/sklearn/utils/_param_validation.py\", line 95, in validate_parameter_constraints\n",
      "    raise InvalidParameterError(\n",
      "sklearn.utils._param_validation.InvalidParameterError: The 'loss' parameter of SGDClassifier must be a str among {'hinge', 'huber', 'squared_epsilon_insensitive', 'modified_huber', 'perceptron', 'squared_error', 'squared_hinge', 'epsilon_insensitive', 'log_loss'}. Got 'log' instead.\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "5 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"/data1/George Pap/grabmyo/ptixiaki/.venv/lib/python3.10/site-packages/sklearn/model_selection/_validation.py\", line 888, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"/data1/George Pap/grabmyo/ptixiaki/.venv/lib/python3.10/site-packages/sklearn/base.py\", line 1466, in wrapper\n",
      "    estimator._validate_params()\n",
      "  File \"/data1/George Pap/grabmyo/ptixiaki/.venv/lib/python3.10/site-packages/sklearn/base.py\", line 666, in _validate_params\n",
      "    validate_parameter_constraints(\n",
      "  File \"/data1/George Pap/grabmyo/ptixiaki/.venv/lib/python3.10/site-packages/sklearn/utils/_param_validation.py\", line 95, in validate_parameter_constraints\n",
      "    raise InvalidParameterError(\n",
      "sklearn.utils._param_validation.InvalidParameterError: The 'loss' parameter of SGDClassifier must be a str among {'squared_epsilon_insensitive', 'perceptron', 'log_loss', 'epsilon_insensitive', 'modified_huber', 'squared_error', 'huber', 'hinge', 'squared_hinge'}. Got 'log' instead.\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "2 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"/data1/George Pap/grabmyo/ptixiaki/.venv/lib/python3.10/site-packages/sklearn/model_selection/_validation.py\", line 888, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"/data1/George Pap/grabmyo/ptixiaki/.venv/lib/python3.10/site-packages/sklearn/base.py\", line 1466, in wrapper\n",
      "    estimator._validate_params()\n",
      "  File \"/data1/George Pap/grabmyo/ptixiaki/.venv/lib/python3.10/site-packages/sklearn/base.py\", line 666, in _validate_params\n",
      "    validate_parameter_constraints(\n",
      "  File \"/data1/George Pap/grabmyo/ptixiaki/.venv/lib/python3.10/site-packages/sklearn/utils/_param_validation.py\", line 95, in validate_parameter_constraints\n",
      "    raise InvalidParameterError(\n",
      "sklearn.utils._param_validation.InvalidParameterError: The 'loss' parameter of SGDClassifier must be a str among {'epsilon_insensitive', 'huber', 'hinge', 'squared_error', 'log_loss', 'squared_epsilon_insensitive', 'squared_hinge', 'modified_huber', 'perceptron'}. Got 'log' instead.\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "19 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"/data1/George Pap/grabmyo/ptixiaki/.venv/lib/python3.10/site-packages/sklearn/model_selection/_validation.py\", line 888, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"/data1/George Pap/grabmyo/ptixiaki/.venv/lib/python3.10/site-packages/sklearn/base.py\", line 1466, in wrapper\n",
      "    estimator._validate_params()\n",
      "  File \"/data1/George Pap/grabmyo/ptixiaki/.venv/lib/python3.10/site-packages/sklearn/base.py\", line 666, in _validate_params\n",
      "    validate_parameter_constraints(\n",
      "  File \"/data1/George Pap/grabmyo/ptixiaki/.venv/lib/python3.10/site-packages/sklearn/utils/_param_validation.py\", line 95, in validate_parameter_constraints\n",
      "    raise InvalidParameterError(\n",
      "sklearn.utils._param_validation.InvalidParameterError: The 'loss' parameter of SGDClassifier must be a str among {'modified_huber', 'squared_error', 'log_loss', 'squared_hinge', 'perceptron', 'hinge', 'epsilon_insensitive', 'huber', 'squared_epsilon_insensitive'}. Got 'log' instead.\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "1 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"/data1/George Pap/grabmyo/ptixiaki/.venv/lib/python3.10/site-packages/sklearn/model_selection/_validation.py\", line 888, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"/data1/George Pap/grabmyo/ptixiaki/.venv/lib/python3.10/site-packages/sklearn/base.py\", line 1466, in wrapper\n",
      "    estimator._validate_params()\n",
      "  File \"/data1/George Pap/grabmyo/ptixiaki/.venv/lib/python3.10/site-packages/sklearn/base.py\", line 666, in _validate_params\n",
      "    validate_parameter_constraints(\n",
      "  File \"/data1/George Pap/grabmyo/ptixiaki/.venv/lib/python3.10/site-packages/sklearn/utils/_param_validation.py\", line 95, in validate_parameter_constraints\n",
      "    raise InvalidParameterError(\n",
      "sklearn.utils._param_validation.InvalidParameterError: The 'loss' parameter of SGDClassifier must be a str among {'huber', 'log_loss', 'modified_huber', 'squared_hinge', 'squared_epsilon_insensitive', 'epsilon_insensitive', 'squared_error', 'perceptron', 'hinge'}. Got 'log' instead.\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "3 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"/data1/George Pap/grabmyo/ptixiaki/.venv/lib/python3.10/site-packages/sklearn/model_selection/_validation.py\", line 888, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"/data1/George Pap/grabmyo/ptixiaki/.venv/lib/python3.10/site-packages/sklearn/base.py\", line 1466, in wrapper\n",
      "    estimator._validate_params()\n",
      "  File \"/data1/George Pap/grabmyo/ptixiaki/.venv/lib/python3.10/site-packages/sklearn/base.py\", line 666, in _validate_params\n",
      "    validate_parameter_constraints(\n",
      "  File \"/data1/George Pap/grabmyo/ptixiaki/.venv/lib/python3.10/site-packages/sklearn/utils/_param_validation.py\", line 95, in validate_parameter_constraints\n",
      "    raise InvalidParameterError(\n",
      "sklearn.utils._param_validation.InvalidParameterError: The 'loss' parameter of SGDClassifier must be a str among {'epsilon_insensitive', 'perceptron', 'modified_huber', 'log_loss', 'hinge', 'squared_hinge', 'huber', 'squared_epsilon_insensitive', 'squared_error'}. Got 'log' instead.\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "9 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"/data1/George Pap/grabmyo/ptixiaki/.venv/lib/python3.10/site-packages/sklearn/model_selection/_validation.py\", line 888, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"/data1/George Pap/grabmyo/ptixiaki/.venv/lib/python3.10/site-packages/sklearn/base.py\", line 1466, in wrapper\n",
      "    estimator._validate_params()\n",
      "  File \"/data1/George Pap/grabmyo/ptixiaki/.venv/lib/python3.10/site-packages/sklearn/base.py\", line 666, in _validate_params\n",
      "    validate_parameter_constraints(\n",
      "  File \"/data1/George Pap/grabmyo/ptixiaki/.venv/lib/python3.10/site-packages/sklearn/utils/_param_validation.py\", line 95, in validate_parameter_constraints\n",
      "    raise InvalidParameterError(\n",
      "sklearn.utils._param_validation.InvalidParameterError: The 'loss' parameter of SGDClassifier must be a str among {'squared_error', 'huber', 'epsilon_insensitive', 'squared_hinge', 'perceptron', 'modified_huber', 'squared_epsilon_insensitive', 'hinge', 'log_loss'}. Got 'log' instead.\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "1 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"/data1/George Pap/grabmyo/ptixiaki/.venv/lib/python3.10/site-packages/sklearn/model_selection/_validation.py\", line 888, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"/data1/George Pap/grabmyo/ptixiaki/.venv/lib/python3.10/site-packages/sklearn/base.py\", line 1466, in wrapper\n",
      "    estimator._validate_params()\n",
      "  File \"/data1/George Pap/grabmyo/ptixiaki/.venv/lib/python3.10/site-packages/sklearn/base.py\", line 666, in _validate_params\n",
      "    validate_parameter_constraints(\n",
      "  File \"/data1/George Pap/grabmyo/ptixiaki/.venv/lib/python3.10/site-packages/sklearn/utils/_param_validation.py\", line 95, in validate_parameter_constraints\n",
      "    raise InvalidParameterError(\n",
      "sklearn.utils._param_validation.InvalidParameterError: The 'loss' parameter of SGDClassifier must be a str among {'huber', 'epsilon_insensitive', 'perceptron', 'log_loss', 'modified_huber', 'hinge', 'squared_error', 'squared_epsilon_insensitive', 'squared_hinge'}. Got 'log' instead.\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "12 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"/data1/George Pap/grabmyo/ptixiaki/.venv/lib/python3.10/site-packages/sklearn/model_selection/_validation.py\", line 888, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"/data1/George Pap/grabmyo/ptixiaki/.venv/lib/python3.10/site-packages/sklearn/base.py\", line 1466, in wrapper\n",
      "    estimator._validate_params()\n",
      "  File \"/data1/George Pap/grabmyo/ptixiaki/.venv/lib/python3.10/site-packages/sklearn/base.py\", line 666, in _validate_params\n",
      "    validate_parameter_constraints(\n",
      "  File \"/data1/George Pap/grabmyo/ptixiaki/.venv/lib/python3.10/site-packages/sklearn/utils/_param_validation.py\", line 95, in validate_parameter_constraints\n",
      "    raise InvalidParameterError(\n",
      "sklearn.utils._param_validation.InvalidParameterError: The 'loss' parameter of SGDClassifier must be a str among {'epsilon_insensitive', 'huber', 'squared_hinge', 'squared_error', 'hinge', 'log_loss', 'perceptron', 'modified_huber', 'squared_epsilon_insensitive'}. Got 'log' instead.\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "16 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"/data1/George Pap/grabmyo/ptixiaki/.venv/lib/python3.10/site-packages/sklearn/model_selection/_validation.py\", line 888, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"/data1/George Pap/grabmyo/ptixiaki/.venv/lib/python3.10/site-packages/sklearn/base.py\", line 1466, in wrapper\n",
      "    estimator._validate_params()\n",
      "  File \"/data1/George Pap/grabmyo/ptixiaki/.venv/lib/python3.10/site-packages/sklearn/base.py\", line 666, in _validate_params\n",
      "    validate_parameter_constraints(\n",
      "  File \"/data1/George Pap/grabmyo/ptixiaki/.venv/lib/python3.10/site-packages/sklearn/utils/_param_validation.py\", line 95, in validate_parameter_constraints\n",
      "    raise InvalidParameterError(\n",
      "sklearn.utils._param_validation.InvalidParameterError: The 'loss' parameter of SGDClassifier must be a str among {'squared_hinge', 'modified_huber', 'squared_error', 'perceptron', 'squared_epsilon_insensitive', 'epsilon_insensitive', 'huber', 'log_loss', 'hinge'}. Got 'log' instead.\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "6 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"/data1/George Pap/grabmyo/ptixiaki/.venv/lib/python3.10/site-packages/sklearn/model_selection/_validation.py\", line 888, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"/data1/George Pap/grabmyo/ptixiaki/.venv/lib/python3.10/site-packages/sklearn/base.py\", line 1466, in wrapper\n",
      "    estimator._validate_params()\n",
      "  File \"/data1/George Pap/grabmyo/ptixiaki/.venv/lib/python3.10/site-packages/sklearn/base.py\", line 666, in _validate_params\n",
      "    validate_parameter_constraints(\n",
      "  File \"/data1/George Pap/grabmyo/ptixiaki/.venv/lib/python3.10/site-packages/sklearn/utils/_param_validation.py\", line 95, in validate_parameter_constraints\n",
      "    raise InvalidParameterError(\n",
      "sklearn.utils._param_validation.InvalidParameterError: The 'loss' parameter of SGDClassifier must be a str among {'squared_epsilon_insensitive', 'squared_hinge', 'log_loss', 'hinge', 'huber', 'squared_error', 'perceptron', 'modified_huber', 'epsilon_insensitive'}. Got 'log' instead.\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "4 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"/data1/George Pap/grabmyo/ptixiaki/.venv/lib/python3.10/site-packages/sklearn/model_selection/_validation.py\", line 888, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"/data1/George Pap/grabmyo/ptixiaki/.venv/lib/python3.10/site-packages/sklearn/base.py\", line 1466, in wrapper\n",
      "    estimator._validate_params()\n",
      "  File \"/data1/George Pap/grabmyo/ptixiaki/.venv/lib/python3.10/site-packages/sklearn/base.py\", line 666, in _validate_params\n",
      "    validate_parameter_constraints(\n",
      "  File \"/data1/George Pap/grabmyo/ptixiaki/.venv/lib/python3.10/site-packages/sklearn/utils/_param_validation.py\", line 95, in validate_parameter_constraints\n",
      "    raise InvalidParameterError(\n",
      "sklearn.utils._param_validation.InvalidParameterError: The 'loss' parameter of SGDClassifier must be a str among {'perceptron', 'squared_hinge', 'log_loss', 'huber', 'squared_error', 'epsilon_insensitive', 'hinge', 'modified_huber', 'squared_epsilon_insensitive'}. Got 'log' instead.\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "6 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"/data1/George Pap/grabmyo/ptixiaki/.venv/lib/python3.10/site-packages/sklearn/model_selection/_validation.py\", line 888, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"/data1/George Pap/grabmyo/ptixiaki/.venv/lib/python3.10/site-packages/sklearn/base.py\", line 1466, in wrapper\n",
      "    estimator._validate_params()\n",
      "  File \"/data1/George Pap/grabmyo/ptixiaki/.venv/lib/python3.10/site-packages/sklearn/base.py\", line 666, in _validate_params\n",
      "    validate_parameter_constraints(\n",
      "  File \"/data1/George Pap/grabmyo/ptixiaki/.venv/lib/python3.10/site-packages/sklearn/utils/_param_validation.py\", line 95, in validate_parameter_constraints\n",
      "    raise InvalidParameterError(\n",
      "sklearn.utils._param_validation.InvalidParameterError: The 'loss' parameter of SGDClassifier must be a str among {'epsilon_insensitive', 'squared_epsilon_insensitive', 'log_loss', 'modified_huber', 'hinge', 'perceptron', 'huber', 'squared_error', 'squared_hinge'}. Got 'log' instead.\n",
      "\n",
      "  warnings.warn(some_fits_failed_message, FitFailedWarning)\n",
      "/data1/George Pap/grabmyo/ptixiaki/.venv/lib/python3.10/site-packages/numpy/ma/core.py:2846: RuntimeWarning: invalid value encountered in cast\n",
      "  _data = np.array(data, dtype=dtype, copy=copy,\n",
      "/data1/George Pap/grabmyo/ptixiaki/.venv/lib/python3.10/site-packages/sklearn/model_selection/_search.py:1102: UserWarning: One or more of the test scores are non-finite: [0.09526917 0.09983687 0.10668842 0.08809135 0.09722675 0.09004894\n",
      " 0.091354   0.08189233 0.10244698        nan        nan        nan\n",
      "        nan        nan        nan        nan        nan        nan\n",
      " 0.10995106 0.09298532 0.07797716 0.10831974 0.08352365 0.09363785\n",
      " 0.08384992 0.07732463 0.07634584        nan        nan        nan\n",
      "        nan        nan        nan        nan        nan        nan\n",
      " 0.10212072 0.09657423 0.07928222 0.09983687 0.10603589 0.10766721\n",
      " 0.11027732 0.10701468 0.0822186         nan        nan        nan\n",
      "        nan        nan        nan        nan        nan        nan]\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import scipy.io as sio\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.linear_model import SGDClassifier\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.model_selection import train_test_split, GridSearchCV\n",
    "from tqdm import tqdm\n",
    "\n",
    "# Function to extract label from filename\n",
    "def extract_label_from_filename(filename):\n",
    "    basename = os.path.basename(filename)\n",
    "    return int(basename.split('_')[2].replace('gesture', ''))\n",
    "\n",
    "# Function to process a batch of files\n",
    "def process_batch(batch_files, target_length):\n",
    "    data_emg_list = []\n",
    "    labels_list = []\n",
    "    for mat_file in tqdm(batch_files, desc=\"Processing Batch\"):\n",
    "        if mat_file.endswith('.mat'):\n",
    "            # Load the .mat file\n",
    "            mat_data = sio.loadmat(mat_file)\n",
    "            data_emg = mat_data['data_emg']\n",
    "            label = extract_label_from_filename(mat_file)\n",
    "\n",
    "            # Handle NaNs and Infinities\n",
    "            data = np.nan_to_num(data_emg, nan=0.0, posinf=0.0, neginf=0.0)\n",
    "            \n",
    "            # Pad or truncate the data to the target length\n",
    "            if data.shape[0] < target_length:\n",
    "                padded_data = np.pad(data, ((0, target_length - data.shape[0]), (0, 0)), 'constant', constant_values=0)\n",
    "            else:\n",
    "                padded_data = data[:target_length]\n",
    "            \n",
    "            # Append to lists\n",
    "            data_emg_list.append(padded_data)\n",
    "            labels_list.append(label)\n",
    "    \n",
    "    # Convert to numpy arrays\n",
    "    X_batch = np.array(data_emg_list)\n",
    "    y_batch = np.array(labels_list)\n",
    "    \n",
    "    # Reshape the data\n",
    "    X_batch_flat = X_batch.reshape(X_batch.shape[0], -1)\n",
    "    \n",
    "    return X_batch_flat, y_batch\n",
    "\n",
    "# Path to the data\n",
    "target_length = 10240  # Desired length for each EMG signal\n",
    "session_folders = ['Session1_matfiles', 'Session2_matfiles', 'Session3_matfiles']\n",
    "all_mat_files = []\n",
    "all_labels = []\n",
    "\n",
    "# Collect all .mat files and their corresponding labels\n",
    "for session_folder in session_folders:\n",
    "    mat_files = sorted(os.listdir(session_folder))\n",
    "    all_mat_files += [os.path.join(session_folder, mat_file) for mat_file in mat_files if mat_file.endswith('.mat')]\n",
    "    all_labels += [extract_label_from_filename(mat_file) for mat_file in mat_files if mat_file.endswith('.mat')]\n",
    "\n",
    "# Split the dataset into train and test sets\n",
    "train_files, test_files, train_labels, test_labels = train_test_split(all_mat_files, all_labels, test_size=0.2, random_state=42)\n",
    "\n",
    "# Initialize PCA for dimensionality reduction\n",
    "pca = PCA(n_components=4)  # Reduce to 100 components, adjust as needed\n",
    "\n",
    "# Initialize an SVM with stochastic gradient descent (SGD)\n",
    "svm_model = SGDClassifier(loss='hinge', penalty='l2', max_iter=1000)\n",
    "\n",
    "# Process training data in batches\n",
    "batch_size = 50\n",
    "\n",
    "for i in range(0, len(train_files), batch_size):\n",
    "    batch_files = train_files[i:i+batch_size]\n",
    "    X_batch, y_batch = process_batch(batch_files, target_length)\n",
    "    \n",
    "    # Apply PCA\n",
    "    X_batch_pca = pca.fit_transform(X_batch)\n",
    "    \n",
    "    # Incrementally fit the SVM model, passing the complete set of classes every time\n",
    "    svm_model.partial_fit(X_batch_pca, y_batch, classes=np.unique(train_labels))\n",
    "\n",
    "# Process and test the model on test data\n",
    "X_test, y_test = process_batch(test_files, target_length)\n",
    "X_test_pca = pca.transform(X_test)\n",
    "\n",
    "# Inference on test data\n",
    "y_pred = svm_model.predict(X_test_pca)\n",
    "\n",
    "# Calculate accuracy\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "print(f\"Test Accuracy: {accuracy * 100:.2f}%\")\n",
    "\n",
    "# --- Hyperparameter Tuning with GridSearchCV ---\n",
    "\n",
    "# Define the parameter grid for tuning\n",
    "param_grid = {\n",
    "    'alpha': [0.0001, 0.001, 0.01],\n",
    "    'loss': ['hinge', 'log'],\n",
    "    'penalty': ['l2', 'l1', 'elasticnet'],\n",
    "    'max_iter': [1000, 2000, 3000]\n",
    "}\n",
    "\n",
    "# Initialize GridSearchCV with SGDClassifier\n",
    "grid_search = GridSearchCV(SGDClassifier(), param_grid, cv=5, n_jobs=-1, verbose=1)\n",
    "\n",
    "# Fit grid search\n",
    "grid_search.fit(X_test_pca, y_test)\n",
    "\n",
    "# Print best parameters and score\n",
    "print(f\"Best parameters found: {grid_search.best_params_}\")\n",
    "print(f\"Best cross-validation accuracy: {grid_search.best_score_ * 100:.2f}%\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "def extract_label_from_filename(filepath):\n",
    "    # Get the base name of the file (e.g., 'session1_participant1_gesture10_trial1.dat')\n",
    "    filename = os.path.basename(filepath)\n",
    "    \n",
    "    # Split the filename by underscores\n",
    "    parts = filename.split('_')\n",
    "    \n",
    "    # Find the part that contains 'gesture' and extract the gesture number\n",
    "    for part in parts:\n",
    "        if 'gesture' in part:\n",
    "            # Assuming the format is 'gesture<number>', we can remove 'gesture' and get the number\n",
    "            gesture_number = part.replace('gesture', '')\n",
    "            return int(gesture_number)  # Convert to integer if needed\n",
    "    \n",
    "    return None  # If no gesture label found\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing Session 1: 100%|██████████| 5107/5107 [02:12<00:00, 38.46it/s]\n",
      "Processing Session 2: 100%|██████████| 5109/5109 [02:24<00:00, 35.36it/s]\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import scipy.io as sio\n",
    "import numpy as np\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score\n",
    "from tqdm import tqdm  # Import tqdm for progress bars\n",
    "\n",
    "# Path where the .mat files are stored\n",
    "#data_folder = 'Session1'\n",
    "\n",
    "# Initialize lists to hold data\n",
    "data_emg_list = []\n",
    "labels_list = []  # Assuming you have labels corresponding to the gestures\n",
    "\n",
    "# Loop through each .mat file in the folder with a progress bar\n",
    "for session_num in range(1, 3):  # Looping through sessions (1 to 3)\n",
    "    session_folder = os.path.join(f'Session{session_num}_matfiles')\n",
    "    \n",
    "    # Get all .mat files in the current session folder\n",
    "    mat_files = sorted(os.listdir(session_folder))\n",
    "    \n",
    "    # Use tqdm to show progress\n",
    "    for mat_file in tqdm(mat_files, desc=f\"Processing Session {session_num}\"):\n",
    "        if mat_file.endswith('.mat'):\n",
    "            # Load the .mat file\n",
    "            mat_data = sio.loadmat(os.path.join(session_folder, mat_file))\n",
    "            \n",
    "            # Extract the EMG data (you may need to adjust variable names if different)\n",
    "            data_emg = mat_data['data_emg']  # This should match the name in your .mat files\n",
    "            label = extract_label_from_filename(mat_file)  # You would need to define this function\n",
    "            # Check for NaNs and infinities in the loaded data\n",
    "            data = np.nan_to_num(data_emg, nan=0.0, posinf=0.0, neginf=0.0)\n",
    "            # Append the data and label to lists\n",
    "            data_emg_list.append(data)\n",
    "            labels_list.append(label)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "target_length = 10240  # The desired length for all samples\n",
    "padded_data_emg_list = [\n",
    "    np.pad(emg_data, ((0, target_length - emg_data.shape[0]), (0, 0)), 'constant', constant_values=0)\n",
    "    if emg_data.shape[0] < target_length else emg_data\n",
    "    for emg_data in data_emg_list\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Applying PCA...\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# Convert lists to numpy arrays\n",
    "X = np.array(padded_data_emg_list)  # Data (e.g., EMG signals)\n",
    "y = np.array(labels_list)  # Labels (e.g., gesture IDs)\n",
    "\n",
    "# Flatten the data if needed (depends on the structure of your data)\n",
    "X_flat = X.reshape(X.shape[0], -1)\n",
    "\n",
    "# Split the data into training and testing sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X_flat, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Apply PCA\n",
    "print(\"Applying PCA...\")\n",
    "pca = PCA(n_components=50)  # Adjust the number of components as needed\n",
    "X_train_pca = pca.fit_transform(X_train)\n",
    "X_test_pca = pca.transform(X_test)\n",
    "\n",
    "# Train an SVM model with progress tracking\n",
    "print(\"Training SVM...\")\n",
    "svm_model = SVC(kernel='linear')\n",
    "\n",
    "# You can wrap the fitting process with tqdm to monitor the training as well\n",
    "svm_model.fit(X_train_pca, y_train)\n",
    "\n",
    "# Make predictions and evaluate the model\n",
    "y_pred = svm_model.predict(X_test_pca)\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "print(f'PCA + SVM Accuracy: {accuracy:.4f}')\n",
    "\n",
    "# Optionally: Use X_train_pca as input to a Vision Transformer model\n",
    "# You can now use the X_train_pca for further processing or to feed into a Vision Transformer model.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# nan_count = np.isnan(data_emg).sum()\n",
    "# inf_count = np.isinf(data_emg).sum()\n",
    "# print(f\"NaNs found: {nan_count}, Infinities found: {inf_count}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
